# TP2
## Concevoir les scripts de crawling et de scraping
Après avoir appris les moyens de récupérer les données depuis les pages Web, j'ai créé les scripts de crawling et scraping pour obtenir les données sur Internet et les enregistrer dans les fichiers locaux. 
J'ai aussi essayé à faire le nettoyage pour ne conserver que les données utiles.
Cependant, quand j'ai essayé à accéder au documents pour lire ou enregistrer mes données, j'ai rencontré beaucoups de problèmes. Et j'ai ajouté plusieurs façons afin d'eviter les erreurs dans mon script.
Maintenant mes données brut sont bien enregistré dans data/raw, et le corpus nettoyé dans data/clean.
J'ai utilisé les moyens différentes pour traiter l'ensemble des données ou juste un fichier.
J'utiliserai le fichier nettoyé comme le corpus de test. Et je vais evaluer les performances de modèle entrainé avec ce corpus.