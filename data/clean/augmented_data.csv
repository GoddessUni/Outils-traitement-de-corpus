text,labels
"The binary T Tauri system JW 566 in the Orion Molecular Cloud underwent an energetic, short-lived flare observed at submillimetre wavelengths by the SCUBA-2 instrument on 26 November 2016 (UT). The emission faded by nearly 50% during the 31 minute integration. The simultaneous source fluxes averaged over the observation are 500 +/- 107 mJy/beam at 450 microns and 466 +/- 47 mJy/beam at 850 microns. The 850 micron flux corresponds to a radio luminosity of $L_{\nu}=8\times10^{19}$ erg/s/Hz, approximately one order of magnitude brighter (in terms of $\nu L_{\nu}$) than that of a flare of the young star GMR-A, detected in Orion in 2003 at 3mm. The event may be the most luminous known flare associated with a young stellar object and is also the first coronal flare discovered at sub-mm wavelengths. The spectral index between 450 microns and 850 microns of $\alpha = 0.11$ is broadly consistent with non-thermal emission. The brightness temperature was in excess of $6\times10^{4}$ K. We interpret this event to be a magnetic reconnection that energised charged particles to emit gyrosynchrotron/synchrotron radiation.",astro-ph.SR
"The binary T Tauri system JW 566 in the Orion Molecular Cloud underwent an energetic, short-lived flare observed at submillimetre wavelengths by the SCUBA-2 instrument on 26 November 2016 (UT). The emission faded by nearly 50% during the 31 minute integration. The simultaneous source fluxes averaged over the observation are 500 +/- 107 mJy/beam at 450 microns and 466 +/- 47 mJy/beam at 850 microns. The 850 micron flux corresponds to a radio brightness of $L_{\nu}=8\times10^{19}$ erg/s/Hz, approximately one order of magnitude brilliant (in terms of $\nu L_{\nu}$) than that of a flare of the young star GMR-A, detected in Orion in 2003 at 3mm. The event may be the most luminous known flare associated with a young stellar object and is also the first coronal flare discovered at sub-mm wavelengths. The spectral index between 450 microns and 850 microns of $\alpha = 0.11$ is broadly consistent with non-thermal emission. The brightness temperature was in excess of $6\times10^{4}$ K. We interpret this event to be a magnetic reconnection that energised charged particles to emit gyrosynchrotron/synchrotron radiation.",astro-ph.SR
"We work out the low-energy expansion of the anomalous $f_1(1285)\to\rho\gamma$ decay amplitude by using the Nambu--Jona-Lasinio model with $U(2)\times U(2)$ chiral symmetric four-quark interactions in the one-quark-loop approximation. The related processes $f_1(1285)\to\omega\gamma$, $a_1(1260)\to\omega\gamma$, and $a_1(1260)\to\rho\gamma$, are also considered. An effective meson Lagrangian responsible for $f_1\rho\gamma$, $f_1\omega\gamma$, $a_1\rho\gamma$ and $a_1\omega\gamma$ interactions is found. The predicted radiative decay widths, $\Gamma_{f_1\to\rho^0\gamma}=311\ \mbox{keV}$, $\Gamma_{f_1\to\omega\gamma}=34.3\ \mbox{keV}$, $\Gamma_{a_1\to\rho^0\gamma}=26.8\ \mbox{keV}$, $\Gamma_{a_1\to\omega\gamma}=238\ \mbox{keV}$, allow an experimental test of the hypothesis that $f_1(1285)$ and $a_1(1260)$-mesons have a quark-antiquark nature. At present, only the $f_1(1285)\to\rho\gamma$ decay has been measured. Our result is in remarkably good agreement with the recent data of CLAS Collaboration $\Gamma_{f_1\to\rho^0\gamma}=453\pm 177\ \mbox{keV}$, but disagrees with the PDG-based estimate of $\Gamma_{f_1\to\rho^0\gamma}=1326\pm 313\ \mbox{keV}$. The calculations presented require a minimum of theoretical input, and are shown to be consistent with the non-renormalization theorems of QCD.",hep-ph
"We work out the low-energy expansion of the anomalous $f_1(1285)\to\rho\gamma$ decay amplitude by practice the Nambu--Jona-Lasinio model with $U(2)\times U(2)$ chiral symmetric four-quark interactions in the one-quark-loop approximation. The related processes $f_1(1285)\to\omega\gamma$, $a_1(1260)\to\omega\gamma$, and $a_1(1260)\to\rho\gamma$, are also considered. An effective meson Lagrangian responsible for $f_1\rho\gamma$, $f_1\omega\gamma$, $a_1\rho\gamma$ and $a_1\omega\gamma$ interactions is found. The predicted radiative decay widths, $\Gamma_{f_1\to\rho^0\gamma}=311\ \mbox{keV}$, $\Gamma_{f_1\to\omega\gamma}=34.3\ \mbox{keV}$, $\Gamma_{a_1\to\rho^0\gamma}=26.8\ \mbox{keV}$, $\Gamma_{a_1\to\omega\gamma}=238\ \mbox{keV}$, allow an experimental test of the hypothesis that $f_1(1285)$ and $a_1(1260)$-mesons have a quark-antiquark nature. At present, only the $f_1(1285)\to\rho\gamma$ decay has been measured. Our result is in remarkably good agreement with the recent data of CLAS Collaboration $\Gamma_{f_1\to\rho^0\gamma}=453\pm 177\ \mbox{keV}$, but disagrees with the PDG-based estimate of $\Gamma_{f_1\to\rho^0\gamma}=1326\pm 313\ \mbox{keV}$. The calculations presented require a minimum of theoretical input, and are shown to be logical with the non-renormalization theorems of QCD.",hep-ph
"The beam aperture of a particle accelerator defines the clearance available for the circulating beams and is a parameter of paramount importance for the accelerator performance. At the CERN Large Hadron Collider (LHC), the knowledge and control of the available aperture is crucial because the nominal proton beams carry an energy of 362 MJ stored in a superconducting environment. Even a tiny fraction of beam losses could quench the superconducting magnets or cause severe material damage. Furthermore, in a circular collider, the performance in terms of peak luminosity depends to a large extent on the aperture of the inner triplet quadrupoles, which are used to focus the beams at the interaction points. In the LHC, this aperture represents the smallest aperture at top-energy with squeezed beams and determines the maximum potential reach of the peak luminosity. Beam-based aperture measurements in these conditions are difficult and challenging. In this paper, we present different methods that have been developed over the years for precise beam-based aperture measurements in the LHC, highlighting applications and results that contributed to boost the operational LHC performance in Run 1 (2010-2013) and Run 2 (2015-2018).",physics.acc-ph
"The beam aperture of a particle accelerator defines the clearance available for the disseminate beams and is a parameter of paramount importance for the accelerator performance. At the CERN Large Hadron Collider (LHC), the knowledge and control of the available aperture is crucial because the nominal proton beams carry an energy of 362 MJ stored in a superconducting environment. Even a tiny fraction of beam losses could quench the superconducting magnets or cause severe material damage. Furthermore, in a circular collider, the performance in terms of peak luminosity depends to a large extent on the aperture of the inner triplet quadrupoles, which are used to focus the beams at the interaction points. In the LHC, this aperture represents the smallest aperture at top-energy with squeezed beams and determines the maximum potential reach of the peak luminosity. Beam-based aperture measurements in these conditions are difficult and challenging. In this paper, we present different methods that have been developed over the years for precise beam-based aperture measurements in the LHC, highlighting coating and results that contributed to boost the operational LHC performance in Run 1 (2010-2013) and Run 2 (2015-2018).",physics.acc-ph
"We investigate the phase diagram of dipolar fermions with aligned dipole moments in a two-dimensional (2D) bilayer. Using a version of the Singwi-Tosi-Land-Sjolander scheme recently adapted to dipolar fermions in a single layer [M. M. Parish and F. M. Marchetti, Phys. Rev. Lett. 108, 145304 (2012)], we determine the density-wave instabilities of the bilayer system within linear response theory. We find that the bilayer geometry can stabilize the collapse of the 2D dipolar Fermi gas with intralayer attraction to form a new density wave phase that has an orientation perpendicular to the density wave expected for strong intralayer repulsion. We thus obtain a quantum phase transition between stripe phases that is driven by the interplay between strong correlations and the architecture of the low dimensional system.",cond-mat.quant-gas cond-mat.str-el
"We investigate the phase diagram of dipolar fermions with aligned dipole moments in a two-dimensional (2D) bilayer. Using a version of the Singwi-Tosi-Land-Sjolander scheme recently adapted to dipolar fermions in a single layer [M. M. Parish and F. M. Marchetti, Phys. Rev. Lett. 108, 145304 (2012)], we determine the density-wave instabilities of the bilayer system within linear response theory. We find that the bilayer geometry can stabilise the collapse of the 2D dipolar Fermi gas with intralayer attraction to form a new compactness wave phase that has an orientation perpendicular to the compactness wave expected for strong intralayer repulsion. We thus obtain a quantum phase transition between stripe phases that is driven by the interplay between strong correlations and the architecture of the low dimensional system.",cond-mat.quant-gas cond-mat.str-el
"Using the Wide Field Camera for the United Kingdom Infrared Telescope, we measure the near-infrared colors of near-Earth objects (NEOs) in order to put constraints on their taxonomic classifications. The rapid-response character of our observations allows us to observe NEOs when they are close to the Earth and bright. Here we present near-infrared color measurements of 86 NEOs, most of which were observed within a few days of their discovery, allowing us to characterize NEOs with diameters of only a few meters. Using machine-learning methods, we compare our measurements to existing asteroid spectral data and provide probabilistic taxonomic classifications for our targets. Our observations allow us to distinguish between S-complex, C/X-complex, D-type, and V-type asteroids. Our results suggest that the fraction of S-complex asteroids in the whole NEO population is lower than the fraction of ordinary chondrites in the meteorite fall statistics. Future data obtained with UKIRT will be used to investigate the significance of this discrepancy.",astro-ph.EP
"Using the Wide Field Camera for the United Kingdom Infrared Telescope, we measure the near-infrared colors of near-Earth objects (NEOs) in order to put constraints on their taxonomic classifications. The rapid-response character of our observations allows us to detect NEOs when they are close to the Earth and bright. Here we present near-infrared color measurements of 86 NEOs, most of which were observed within a few days of their discovery, allowing us to characterize NEOs with diameters of only a few meters. Using machine-learning methods, we compare our measurements to subsist asteroid spectral data and provide probabilistic taxonomic classifications for our targets. Our observations allow us to distinguish between S-complex, C/X-complex, D-type, and V-type asteroids. Our results suggest that the fraction of S-complex asteroids in the whole NEO population is lower than the fraction of ordinary chondrites in the meteorite fall statistics. Future data obtained with UKIRT will be used to investigate the significance of this discrepancy.",astro-ph.EP
"We present a context-preserving text simplification (TS) approach that recursively splits and rephrases complex English sentences into a semantic hierarchy of simplified sentences. Using a set of linguistically principled transformation patterns, input sentences are converted into a hierarchical representation in the form of core sentences and accompanying contexts that are linked via rhetorical relations. Hence, as opposed to previously proposed sentence splitting approaches, which commonly do not take into account discourse-level aspects, our TS approach preserves the semantic relationship of the decomposed constituents in the output. A comparative analysis with the annotations contained in the RST-DT shows that we are able to capture the contextual hierarchy between the split sentences with a precision of 89% and reach an average precision of 69% for the classification of the rhetorical relations that hold between them.",cs.CL
"We present a context-preserving text simplification (TS) approach that recursively splits and rephrases complex English sentences into a semantic hierarchy of simplified sentences. Using a set of linguistically principled transformation patterns, input sentences are converted into a hierarchical histrionics in the form of core sentences and accompanying contexts that are linked via rhetorical relations. Hence, as opposed to previously proposed sentence splitting approaches, which commonly do not take into account discourse-level aspects, our TS approach preserves the semantic relationship of the decomposed constituents in the output. A comparative analysis with the annotations contained in the RST-DT shows that we are able to get the contextual hierarchy between the split sentences with a precision of 89% and reach an average precision of 69% for the classification of the rhetorical relations that hold between them.",cs.CL
"We prove that the long term distribution of the queue length process in an ergodic generalised Jackson network obeys the Large Deviation Principle with a deviation function given by the quasipotential. The latter is related to the unique long term idempotent distribution, which is also a stationary idempotent distribution, of the large deviation limit of the queue length processes. The proof draws on developments in queueing network stability and idempotent probability.",math.PR
"We prove that the long terminus distribution of the queue length process in an ergodic generalised Jackson network obeys the Large Deviation Principle with a deviation function devote by the quasipotential. The latter is related to the unique long terminus idempotent distribution, which is also a stationary idempotent distribution, of the large deviation limit of the queue length processes. The proof draws on developments in queueing network stability and idempotent probability.",math.PR
"Recent studies of the distribution and kinematics of the Milky Way and Andromeda satellite galaxy systems have confirmed the existence of coplanar, corotating structures of galaxies. In addition to the 'missing satellite problem', these structures pose a major challenge to the standard $\Lambda$CDM scenario of structure formation. We complement the efforts made by the dwarf galaxy community to extend these studies to other nearby galaxy groups by systematically searching for faint, unresolved dwarf members with a low surface brightness in the Southern Centaurus group of galaxies. The aim is to determine whether these coplanar, corotating structures are a universal phenomenon. We imaged an area of 60 square degrees (0.3 Mpc$^2$) around the M83 subgroup with the wide-field Dark Energy Camera (DECam) at the CTIO 4 m Blanco telescope in $g$ and $r$ down to a limiting surface brightness of $\mu_r\approx 30$ mag arcsec$^{-2}$. Various image-filtering techniques were applied to the DECam data to enhance the visibility of extremely low-surface brightness objects. We report the discovery of 16 new dwarf galaxy candidates in the direction of the M83 subgroup, roughly doubling the number of known dwarfs in that region. The photometric properties of the candidates, when compared to those of the Local Group, suggest membership in the M83 subgroup. The faintest objects have a central star density of $\approx1.3 L_\odot$ pc$^{-2}$ and a total magnitude of $g = 20.25$, corresponding to $M_g = -9.55$ at the nominal distance of 4.9 Mpc. The sky distribution of the new objects is significantly prolonged toward Cen A, suggesting that many of them belong to the Cen A subgroup or a common halo. We also provide updated surface photometry for the brighter, known dwarf members in the surveyed area.",astro-ph.GA
"Recent studies of the distribution and kinematics of the Milky Way and Andromeda satellite galaxy systems have confirmed the existence of coplanar, corotating structures of galaxies. In addition to the 'missing satellite problem', these structures pose a major challenge to the standard $\Lambda$CDM scenario of body structure formation. We complement the efforts made by the dwarf galaxy community to extend these studies to other nearby galaxy groups by systematically searching for faint, unresolved dwarf members with a low surface brightness in the Southern centaur group of galaxies. The aim is to determine whether these coplanar, corotating structures are a universal phenomenon. We imaged an area of 60 square degrees (0.3 Mpc$^2$) around the M83 subgroup with the wide-field Dark Energy Camera (DECam) at the CTIO 4 m Blanco telescope in $g$ and $r$ down to a limiting surface brightness of $\mu_r\approx 30$ mag arcsec$^{-2}$. Various image-filtering techniques were applied to the DECam data to enhance the visibility of extremely low-surface brightness objects. We report the discovery of 16 new dwarf galaxy candidates in the direction of the M83 subgroup, roughly doubling the number of known dwarfs in that region. The photometric properties of the candidates, when compared to those of the Local Group, suggest membership in the M83 subgroup. The faintest objects have a central star density of $\approx1.3 L_\odot$ pc$^{-2}$ and a total magnitude of $g = 20.25$, corresponding to $M_g = -9.55$ at the nominal distance of 4.9 Mpc. The sky distribution of the new objects is significantly prolonged toward Cen A, suggesting that many of them belong to the Cen A subgroup or a common halo. We also provide updated surface photometry for the brighter, known dwarf members in the surveyed area.",astro-ph.GA
"The adiabatic cristal model is offered. It is shown that springy nuclei oscillations relatively electronic envelops and waves of such oscillations (inherent oscillations and waves) may exist in crystals. The analysis of experimental temperature dependencies of resistivity in semiconductors with electron-vibrational centres has shown that inherent oscillations effectively interact with crystalline phonons as well as with electrons and holes, creating powerful interaction of electrons and holes with phonons. The experimental narrow peaks of phonon-drag thermoelectric power at Debye temperatures from 77K to 700K confirm existence of inherent oscillations waves in crystals. Inherent oscillations and waves gives rise to strong electron-phonon interaction and probably can bring about superconductivity at temperatures as below so and well above room temperature.",cond-mat.dis-nn cond-mat.mes-hall
"The adiabatic cristal model is offered. It is shown that springy nuclei oscillations relatively electronic envelops and waves of such oscillations (inherent oscillations and waves) may exist in crystals. The analysis of experimental temperature dependencies of resistivity in semiconductors with electron-vibrational kernel has shown that inherent oscillations effectively interact with crystalline phonons as well as with electrons and holes, creating powerful interaction of electrons and holes with phonons. The experimental narrow peaks of phonon-drag thermoelectric power at Debye temperatures from 77K to 700K confirm existence of inherent oscillations waves in crystals. implicit in oscillations and waves gives rise to strong electron-phonon interaction and probably can bring about superconductivity at temperatures as below so and well above room temperature.",cond-mat.dis-nn cond-mat.mes-hall
"In an ultrathin topological insulator (TI) film, a hybridization gap opens in the TI surface states, and the system is expected to become either a trivial insulator or a quantum spin Hall insulator when the chemical potential is within the hybridization gap. Here we show, however, that these insulating states are destroyed by the presence of a large and long-range-correlated disorder potential, which converts the expected insulator into a metal. We perform transport measurements in ultrathin, dual-gated topological insulator films as a function of temperature, gate voltage, and magnetic field, and we observe a metallic-like, non-quantized conductivity, which exhibits a weak antilocalization-like cusp at the low magnetic field and gives way to a nonsaturating linear magnetoresistance at large field. We explain these results by considering the disordered network of electron- and hole-type puddles induced by charged impurities. We argue theoretically that such disorder can produce an insulator-to-metal transition as a function of increasing disorder strength, and we derive a condition on the band gap and the impurity concentration necessary to observe the insulating state. We also explain the linear magnetoresistance in terms of strong spatial fluctuations of the local conductivity, using both numerical simulations and a theoretical scaling argument.",cond-mat.mes-hall
"In an ultrathin topological insulator (TI) film, a hybridization gap opens in the TI surface states, and the system is expected to become either a trivial insulator or a quantum spin Hall insulator when the chemical potential is within the hybridization gap. Here we show, however, that these insulating posit are destroyed by the presence of a large and long-range-correlated disorder potential, which win over the expected insulator into a metal. We perform transport measurements in ultrathin, dual-gated topological insulator films as a function of temperature, gate voltage, and magnetic field, and we observe a metallic-like, non-quantized conductivity, which exhibits a weak antilocalization-like cusp at the low magnetic field and gives way to a nonsaturating linear magnetoresistance at large field. We explain these results by considering the disordered network of electron- and hole-type puddles induced by charged impurities. We argue theoretically that such disorder can produce an insulator-to-metal transition as a function of increasing disorder strength, and we derive a condition on the band gap and the impurity concentration necessary to observe the insulating state. We also explain the linear magnetoresistance in terms of strong spatial fluctuations of the local conductivity, using both numerical simulations and a theoretical scaling argument.",cond-mat.mes-hall
"Herein we develop a simple first-principles methodology to determine the modulation that vibrations exert on spin energy levels, a key for the rational design of high-temperature molecular spin qubits and single-molecule magnets. This methodology is demonstrated by applying it to [Cu(mnt)$_2$]$^{2-}$ (mnt$^{2-}$ = 1,2-dicyanoethylene-1,2-dithiolate), a highly coherent complex, using DFT to calculate the normal vibrational modes and wave-function based theory calculations to estimate the spin energy level structure. By theoretically identifying the most relevant vibrational modes, we are able to offer general strategies to chemically design more resilient magnetic molecules, where the qubit energy is not coupled to local vibrations.",cond-mat.mes-hall physics.chem-ph
"Herein we develop a simple first-principles methodology to determine the pitch contour that vibrations exert on spin energy levels, a key for the rational design of high-temperature molecular spin qubits and single-molecule magnets. This methodology is demonstrated by put on it to [Cu(mnt)$_2$]$^{2-}$ (mnt$^{2-}$ = 1,2-dicyanoethylene-1,2-dithiolate), a highly coherent complex, using DFT to calculate the normal vibrational modes and wave-function based theory calculations to estimate the spin energy level structure. By theoretically identifying the most relevant vibrational modes, we are able to offer general strategies to chemically design more resilient magnetic molecules, where the qubit energy is not coupled to local vibrations.",cond-mat.mes-hall physics.chem-ph
Assume that $V$ is a braided vector space with diagonal type. It is shown that a monomial belongs to Nichols braided Lie algebra $\mathfrak L(V)$ if and only if this monomial is connected. A basis of Nichols braided Lie algebra and dimension of Nichols braided Lie algebra of finite Cartan type are obtained.,math.QA
Assume that $V$ is a braided vector space with diagonal type. It is picture that a monomial belongs to Nichols braided Lie algebra $\mathfrak L(V)$ if and exclusively if this monomial is connected. A basis of Nichols braided Lie algebra and dimension of Nichols braided Lie algebra of finite Cartan type are obtained.,math.QA
"We analyse the kinematics of the entire spectroscopic sample of 99 recently discovered high proper-motion white dwarfs by Oppenheimer et al. using a maximum-likelihood analysis, and discuss the claim that the high-velocity white dwarfs are members of a halo population with a local density at least ten times greater than traditionally assumed. We argue that the observations, as reported, are consistent with the presence of an almost undetected thin disc plus a thick disc, with densities as conventionally assumed. In addition, there is a kinematically distinct, flattened, halo population at the more than 99% confidence level. Surprisingly, the thick disc and halo populations are indistinguishable in terms of luminosity, color and apparent age (1-10 Gyr). Adopting a bimodal, Schwarzschild model for the local velocity ellipsoid, with the ratios sigma_U:sigma_V:sigma_W=1:2/3:1/2, we infer radial velocity dispersions of sigma_U=62(+8/-10) km/s and 150(+80/-40) km/s (90% C.L.) for the local thick disc and halo populations, respectively. The thick disc result agrees with the empirical relation between asymmetric drift and radial velocity dispersion, inferred from local stellar populations. The local thick-disc plus halo density of white dwarfs is n^{td+h}=(1.9+-0.5)x10^-3 pc^-3 (90% C.L.), of which n^{h}=1.1(+2.1/-0.7)x10^-4 pc^-3 (90% C.L.) belongs to the halo, a density about five times higher than previously thought. (Abridged)",astro-ph
"We analyse the kinematics of the entire spectroscopic sample of 99 recently discovered high proper-motion white dwarfs by Oppenheimer et al. using a maximum-likelihood analysis, and discuss the claim that the high-velocity white dwarfs are members of a anchor ring population with a local density at least ten times greater than traditionally assumed. We argue that the observations, as reported, are reproducible with the presence of an almost undetected thin disc plus a thick disc, with densities as conventionally assumed. In addition, there is a kinematically distinct, flattened, anchor ring population at the more than 99% confidence level. Surprisingly, the thick disc and anchor ring populations are indistinguishable in terms of luminosity, color and apparent age (1-10 Gyr). Adopting a bimodal, Schwarzschild model for the local velocity ellipsoid, with the ratios sigma_U:sigma_V:sigma_W=1:2/3:1/2, we infer radial velocity dispersions of sigma_U=62(+8/-10) km/s and 150(+80/-40) km/s (90% C.L.) for the local thick disc and anchor ring populations, respectively. The thick disc result agrees with the empirical relation between asymmetric drift and radial velocity dispersion, inferred from local stellar populations. The local thick-disc plus anchor ring density of white dwarfs is n^{td+h}=(1.9+-0.5)x10^-3 pc^-3 (90% C.L.), of which n^{h}=1.1(+2.1/-0.7)x10^-4 pc^-3 (90% C.L.) belongs to the halo, a density about five times higher than previously thought. (Abridged)",astro-ph
"We consider periodic arrays of M2-branes in the ABJM model in the spirit of a circle compactification to D2-branes in type IIA string theory. The result is a curious formulation of three-dimensional maximally supersymmetric Yang-Mills theory in terms of fermions, seven transverse scalars, a non-dynamical gauge field and an additional scalar `dual gluon'. Upon further T-duality on a transverse torus we obtain a non-manifest-Lorentz-invariant description of five-dimensional maximally supersymmetric Yang-Mills. Here the additional scalar field can be thought of as the components of a two-form along the torus. This action can be viewed as an M-theory description of M5-branes on ${\mathbb T}^3$.",hep-th
"We consider periodic arrays of M2-branes in the ABJM model in the spirit of a circle compactification to D2-branes in type IIA string theory. The result is a curious formulation of three-dimensional maximally supersymmetric Yang-Mills theory in terms of fermions, seven transverse scalars, a non-dynamical gauge field and an additional scalar `dual gluon'. Upon further T-duality on a transverse torus we obtain a non-manifest-Lorentz-invariant description of five-dimensional maximally supersymmetric Yang-Mills. Here the additional scalar field can be thought of as the component part of a two-form on the torus. This action can be viewed as an M-theory description of M5-branes on ${\mathbb T}^3$.",hep-th
"Phase retrieval (PR) aims to recover a signal from the magnitudes of a set of inner products. This problem arises in many audio signal processing applications which operate on a short-time Fourier transform magnitude or power spectrogram, and discard the phase information. Recovering the missing phase from the resulting modified spectrogram is indeed necessary in order to synthesize time-domain signals. PR is commonly addressed by considering a minimization problem involving a quadratic loss function. In this paper, we adopt a different standpoint. Indeed, the quadratic loss does not properly account for some perceptual properties of audio, and alternative discrepancy measures such as beta-divergences have been preferred in many settings. Therefore, we formulate PR as a new minimization problem involving Bregman divergences. Since these divergences are not symmetric with respect to their two input arguments in general, they lead to two different formulations of the problem. To optimize the resulting objective, we derive two algorithms based on accelerated gradient descent and alternating direction method of multipliers. Experiments conducted on audio signal recovery from spectrograms that are either exact or estimated from noisy observations highlight the potential of our proposed methods for audio restoration. In particular, leveraging some of these Bregman divergences induce better performance than the quadratic loss when performing PR from spectrograms under very noisy conditions.",cs.SD
"Phase retrieval (PR) aims to recover a signal from the magnitudes of a set of inner products. This problem arises in many audio signal processing applications which operate on a short-time Fourier transform magnitude or power spectrogram, and discard the phase information. Recovering the missing phase from the resulting modified spectrogram is indeed necessary in order to synthesize time-domain signals. PR is commonly addressed by count a minimization problem involving a quadratic loss function. In this paper, we adopt a different standpoint. Indeed, the quadratic loss does not properly account for some perceptual properties of audio, and alternative discrepancy measures such as beta-divergences have been preferred in many settings. Therefore, we formulate PR as a new minimization problem involving Bregman divergences. Since these divergences are not symmetric with respect to their two input arguments in general, they lead to two different formulations of the problem. To optimize the resulting objective, we derive two algorithms based on accelerated gradient descent and alternating direction method of multipliers. Experiments conducted on audio signal recovery from spectrogram that are either exact or estimated from noisy observations highlight the potential of our proposed methods for audio restoration. In particular, leveraging some of these Bregman divergences induce better performance than the quadratic loss when performing PR from spectrogram under very noisy conditions.",cs.SD
"Accurate modeling of the solvent environment for biological molecules is crucial for computational biology and drug design. A popular approach to achieve long simulation time scales for large system sizes is to incorporate the effect of the solvent in a mean-field fashion with implicit solvent models. However, a challenge with existing implicit solvent models is that they often lack accuracy or certain physical properties compared to explicit solvent models, as the many-body effects of the neglected solvent molecules is difficult to model as a mean field. Here, we leverage machine learning (ML) and multi-scale coarse graining (CG) in order to learn implicit solvent models that can approximate the energetic and thermodynamic properties of a given explicit solvent model with arbitrary accuracy, given enough training data. Following the previous ML--CG models CGnet and CGSchnet, we introduce ISSNet, a graph neural network, to model the implicit solvent potential of mean force. ISSNet can learn from explicit solvent simulation data and be readily applied to MD simulations. We compare the solute conformational distributions under different solvation treatments for two peptide systems. The results indicate that ISSNet models can outperform widely-used generalized Born and surface area models in reproducing the thermodynamics of small protein systems with respect to explicit solvent. The success of this novel method demonstrates the potential benefit of applying machine learning methods in accurate modeling of solvent effects for in silico research and biomedical applications.",physics.bio-ph physics.chem-ph physics.comp-ph q-bio.BM stat.ML
"Accurate modeling of the solvent environment for biological molecules is crucial for computational biology and drug design. A popular approach to achieve long simulation time scales for large system sizes is to incorporate the effect of the solvent in a mean-field fashion with implicit solvent models. However, a challenge with existing implicit solvent models is that they often lack accuracy or certain physical properties compared to explicit solvent models, as the many-body effects of the neglected solvent molecules is difficult to model as a average field. Here, we leverage machine erudition (ML) and multi-scale coarse graining (CG) in order to learn implicit solvent models that can approximate the energetic and thermodynamic properties of a given explicit solvent model with arbitrary accuracy, given enough training data. Following the previous ML--CG models CGnet and CGSchnet, we introduce ISSNet, a graph neural network, to model the implicit solvent potential of average force. ISSNet can learn from explicit solvent simulation data and be readily applied to MD simulations. We compare the solute conformational distributions under different solvation treatments for two peptide systems. The results indicate that ISSNet models can outperform widely-used generalized Born and surface area models in reproducing the thermodynamics of small protein systems with respect to explicit solvent. The success of this novel method demonstrates the potential benefit of applying machine erudition methods in accurate modeling of solvent effects for in silico research and biomedical applications.",physics.bio-ph physics.chem-ph physics.comp-ph q-bio.BM stat.ML
"Polycrystalline YMn1-xFexO3 (YMFO_x) (0 <= x <= 0.1) compounds have been prepared in single phase and characterized by synchrotron X-ray diffraction, X-ray absorption near edge spectroscopy, magnetization, and dielectric measurements. Iron-substitution in hexagonal YMnO3 causes intra-lattice changes exceeding those of the lattice cell. XANES provide mixed-valence Mn3+/Mn4+ and Fe4+ charge states in these manganites, consistent with the observed decrease of the effective magnetic moment with Fe-doping. Magnetization M(T) evidence antiferromagnetic (AFM) ordering of the specimens with little weak ferromagnetism, and the metrices of exchange interaction suppress with Fe-doping, attributed to the lengthening of the Mn-O planar bond lengths. Dielectric {\epsilon}'(T) results showing highly doping-dependent anomaly at T_N indicate linear magneto-electric coupling.",cond-mat.mtrl-sci
"Polycrystalline YMn1-xFexO3 (YMFO_x) (0 <= x <= 0.1) compounds have been prepared in single phase and characterized by synchrotron X-ray diffraction, X-ray absorption near edge spectroscopy, magnetization, and dielectric measurements. Iron-substitution in hexagonal YMnO3 causes intra-lattice changes exceeding those of the lattice cell. XANES provide mixed-valence Mn3+/Mn4+ and Fe4+ charge states in these manganites, consistent with the observed diminution of the effective magnetic moment with Fe-doping. magnetic induction M(T) evidence antiferromagnetic (AFM) ordering of the specimens with little weak ferromagnetism, and the metrices of exchange interaction suppress with Fe-doping, attributed to the lengthening of the Mn-O planar bond lengths. Dielectric {\epsilon}'(T) results showing highly doping-dependent anomaly at T_N indicate linear magneto-electric coupling.",cond-mat.mtrl-sci
"We present the Data Release 9 Quasar (DR9Q) catalog from the Baryon Oscillation Spectroscopic Survey (BOSS) of the Sloan Digital Sky Survey III. The catalog includes all BOSS objects that were targeted as quasar candidates during the survey, are spectrocopically confirmed as quasars via visual inspection, have luminosities Mi[z=2]<-20.5 (in a $\Lambda$CDM cosmology with H0 = 70 km/s/Mpc, $\Omega_{\rm M}$ = 0.3, and $\Omega_{\Lambda}$ = 0.7) and either display at least one emission line with full width at half maximum (FWHM) larger than 500 km/s or, if not, have interesting/complex absorption features. It includes as well, known quasars (mostly from SDSS-I and II) that were reobserved by BOSS. This catalog contains 87,822 quasars (78,086 are new discoveries) detected over 3,275 deg$^{2}$ with robust identification and redshift measured by a combination of principal component eigenspectra newly derived from a training set of 8,632 spectra from SDSS-DR7. The number of quasars with $z>2.15$ (61,931) is ~2.8 times larger than the number of z>2.15 quasars previously known. Redshifts and FWHMs are provided for the strongest emission lines (CIV, CIII], MgII). The catalog identifies 7,533 broad absorption line quasars and gives their characteristics. For each object the catalog presents five-band (u,g,r,i,z) CCD-based photometry with typical accuracy of 0.03 mag, and information on the morphology and selection method. The catalog also contains X-ray, ultraviolet, near-infrared, and radio emission properties of the quasars, when available, from other large-area surveys.",astro-ph.CO
"We present the Data Release 9 Quasar (DR9Q) catalog from the Baryon Oscillation Spectroscopic Survey (BOSS) of the Sloan Digital Sky Survey III. The catalog includes all BOSS objects that were targeted as quasar candidates during the survey, are spectrocopically confirmed as quasars via visual inspection, have luminosities Mi[z=2]<-20.5 (in a $\Lambda$CDM cosmology with H0 = 70 km/s/Mpc, $\Omega_{\rm M}$ = 0.3, and $\Omega_{\Lambda}$ = 0.7) and either display at least one emission line with full width at half maximum (FWHM) larger than 500 km/s or, if not, have interesting/complex absorption features. It includes as well, known quasars (mostly from SDSS-I and II) that were reobserved by BOSS. This catalog contains 87,822 quasars (78,086 are new discoveries) detected over 3,275 deg$^{2}$ with robust identification and redshift measured by a combination of principal component eigenspectra newly derived from a training set of 8,632 spectra from SDSS-DR7. The number of quasars with $z>2.15$ (61,931) is ~2.8 times larger than the number of z>2.15 quasars previously known. Redshifts and FWHMs are provided for the strongest emission lines (CIV, CIII], MgII). The catalog identifies 7,533 large-minded absorption line quasars and gives their characteristics. For each object the catalog presents five-band (u,g,r,i,z) CCD-based photometry with distinctive accuracy of 0.03 mag, and information on the morphology and selection method. The catalog also contains X-ray, ultraviolet, near-infrared, and radio emission properties of the quasars, when available, from other large-area surveys.",astro-ph.CO
"In this paper, we prove a generalization of Green's Hyperplane Restriction Theorem to the case of modules over the polynomial ring, providing in particular an upper bound for the Hilbert function of the general linear restriction of a module M in a degree d by the corresponding Hilbert function of a lexicographic module.",math.AC
"In this paper, we prove a generalization of Green's Hyperplane Restriction Theorem to the case of modules over the polynomial ring, offer in particular an upper bound for the Hilbert function of the general linear limitation of a module M in a degree d by the corresponding Hilbert function of a lexicographic module.",math.AC
"The investigation and characterization of topological quantum phase transition between gapless phases is one of the recent interest of research in topological states of matter. We consider transverse field Ising model with three spin interaction in one dimension and observe a topological transition between gapless phases on one of the critical lines of this model. We study the distinct nature of these gapless phases and show that they belong to different universality classes. The topological invariant number (winding number) characterize different topological phases for the different regime of parameter space. We observe the evidence of two multi-critical points, one is topologically trivial and the other one is topologically active. Topological quantum phase transition between the gapless phases on the critical line occurs through the non-trivial multi-critical point in the Lifshitz universality class. We calculate and analyze the behavior of Wannier state correlation function close to the multi-critical point and confirm the topological transition between gapless phases. We show the breakdown of Lorentz invariance at this multi-critical point through the energy dispersion analysis. We also show that the scaling theories and curvature function renormalization group can also be effectively used to understand the topological quantum phase transitions between gapless phases. The model Hamiltonian which we study is more applicable for the system with gapless excitations, where the conventional concept of topological quantum phase transition fails.",cond-mat.str-el
"The investigation and characterization of topological quantum phase transition between gapless phases is one of the recent interest of research in topological states of matter. We consider transverse orbit Ising model with three spin interaction in one dimension and observe a topological transition between gapless phases on one of the critical lines of this model. We study the distinct nature of these gapless phases and show that they belong to different universality classes. The topological invariant number (winding number) characterize different topological phases for the different regime of parameter space. We observe the evidence of two multi-critical points, one is topologically trivial and the other one is topologically active. Topological quantum phase transition between the gapless phases on the critical line occurs through the non-trivial multi-critical point in the Lifshitz universality class. We calculate and analyze the behavior of Wannier state correlation function close to the multi-critical point and confirm the topological transition between gapless phases. We show the breakdown of Lorentz invariance at this multi-critical point through the energy dispersion analysis. We also show that the scaling theories and curvature function renormalization group can also be effectively used to understand the topological quantum phase transition between gapless phases. The model Hamiltonian which we study is more applicable for the system with gapless excitations, where the conventional concept of topological quantum phase transition fails.",cond-mat.str-el
"We report on the first search for top-quark production via flavor-changing neutral-current (FCNC) interactions in the non-standard-model process u(c)+g -> t using ppbar collision data collected by the CDF II detector. The data set corresponds to an integrated luminosity of 2.2/fb. The candidate events feature the signature of semileptonic top-quark decays and are classified as signal-like or background-like by an artificial neural network trained on simulated events. The observed discriminant distribution is in good agreement with the one predicted by the standard model and provides no evidence for FCNC top-quark production, resulting in a Bayesian upper limit on the production cross section sigma (u(c)+g -> t) < 1.8 pb at the 95% confidence level. Using theoretical predictions we convert the cross-section limit to upper limits on FCNC branching ratios: BR (t -> u+g) < 3.9 x 10{-4}$ and BR (t -> c+g) < 5.7 x 10^{-3}.",hep-ex
"We report on the first search for top-quark production via flavor-changing neutral-current (FCNC) interactions in the non-standard-model process u(c)+g -> t using ppbar collision data collected by the CDF II detector. The data set corresponds to an integrated luminosity of 2.2/fb. The candidate events feature the signature of semileptonic top-quark decays and are class as signal-like or background-like by an artificial neural network trained on simulated events. The observed discriminant statistical distribution is in good agreement with the one predicted by the standard model and provides no evidence for FCNC top-quark production, resulting in a Bayesian upper limit on the production cross section sigma (u(c)+g -> t) < 1.8 pb at the 95% confidence level. Using theoretical predictions we convert the cross-section limit to upper limits on FCNC branching ratios: BR (t -> u+g) < 3.9 x 10{-4}$ and BR (t -> c+g) < 5.7 x 10^{-3}.",hep-ex
"Human associated microbial communities exert tremendous influence over human health and disease. With modern metagenomic sequencing methods it is possible to follow the relative abundance of microbes in a community over time. These microbial communities exhibit rich ecological dynamics and an important goal of microbial ecology is to infer the interactions between species from sequence data. Any algorithm for inferring species interactions must overcome three obstacles: 1) a correlation between the abundances of two species does not imply that those species are interacting, 2) the sum constraint on the relative abundances obtained from metagenomic studies makes it difficult to infer the parameters in timeseries models, and 3) errors due to experimental uncertainty, or mis-assignment of sequencing reads into operational taxonomic units, bias inferences of species interactions. Here we introduce an approach, Learning Interactions from MIcrobial Time Series (LIMITS), that overcomes these obstacles. LIMITS uses sparse linear regression with boostrap aggregation to infer a discrete-time Lotka-Volterra model for microbial dynamics. We tested LIMITS on synthetic data and showed that it could reliably infer the topology of the inter-species ecological interactions. We then used LIMITS to characterize the species interactions in the gut microbiomes of two individuals and found that the interaction networks varied significantly between individuals. Furthermore, we found that the interaction networks of the two individuals are dominated by distinct ""keystone species"", Bacteroides fragilis and Bacteroided stercosis, that have a disproportionate influence on the structure of the gut microbiome even though they are only found in moderate abundance. Based on our results, we hypothesize that the abundances of certain keystone species may be responsible for individuality in the human gut microbiome.",q-bio.PE q-bio.QM
"Human associated microbial communities exert tremendous influence over human health and disease. With modern metagenomic sequencing methods it is possible to follow the relative abundance of microbes in a biotic community over time. These microbial communities exhibit rich ecological dynamics and an important goal of microbial ecology is to infer the interactions between species from succession data. Any algorithm for inferring species interactions must overcome three obstacles: 1) a correlation between the abundances of two species does not imply that those species are interacting, 2) the sum constraint on the relative abundances obtained from metagenomic studies makes it difficult to infer the parameters in timeseries models, and 3) errors due to experimental uncertainty, or mis-assignment of sequencing reads into operational taxonomic units, bias inferences of species interactions. Here we introduce an approach, Learning Interactions from MIcrobial Time Series (LIMITS), that overcomes these obstacles. LIMITS uses sparse linear regression with boostrap aggregation to infer a discrete-time Lotka-Volterra model for microbial dynamics. We tested LIMITS on synthetic data and showed that it could reliably infer the topology of the inter-species ecological interactions. We then used LIMITS to characterize the species interactions in the gut microbiomes of two individuals and found that the interaction networks varied significantly between individuals. Furthermore, we found that the interaction networks of the two individuals are dominated by distinct ""keystone species"", Bacteroides fragilis and Bacteroided stercosis, that have a disproportionate influence on the structure of the gut microbiome even though they are only found in moderate abundance. Based on our results, we hypothesize that the abundances of certain keystone species may be responsible for individuality in the human gut microbiome.",q-bio.PE q-bio.QM
"One of the basic motivations of the KLOE-2 and WASA-at-COSY experiments is the test of fundamental symmetries and the search for phenomena beyond the Standard Model in the hadronic and leptonic decays of ground-state mesons and in particular in decays of the $\eta$ meson. At COSY these mesons are produced in collisions of proton or deuteron beam with hydrogen or deuterium pellet target, and at DA$\Phi$NE $\eta$ mesons originate from radiative decays of $\phi$ meson or from the fusion of virtual gamma quanta exchanged between colliding electrons and positrons. This contribution includes brief description of experimental techniques used by KLOE-2 and WASA-at-COSY as well as some of physics aspects motivating investigations of production and decays of $\eta$ mesons.",hep-ex nucl-ex
"One of the canonic motivations of the KLOE-2 and WASA-at-COSY experiments is the test of fundamental symmetries and the search for phenomena beyond the Standard Model in the hadronic and leptonic decays of ground-state mesons and in particular in decays of the $\eta$ meson. At COSY these mesons are produced in collisions of proton or deuteron beam with hydrogen or deuterium pellet target, and at DA$\Phi$NE $\eta$ mesons originate from radiative decays of $\phi$ meson or from the fusion of virtual gamma quantum exchanged between colliding electrons and positrons. This contribution includes brief description of experimental techniques used by KLOE-2 and WASA-at-COSY as well as some of physics aspects motivating investigations of production and decays of $\eta$ mesons.",hep-ex nucl-ex
"Software fault localization is one of the most expensive, tedious, and time-consuming activities in program debugging. This activity becomes even much more challenging in Software Product Line (SPL) systems due to variability of failures. These unexpected behaviors are induced by variability faults which can only be exposed under some combinations of system features. The interaction among these features causes the failures of the system. Although localizing bugs in single-system engineering has been studied in-depth, variability fault localization in SPL systems still remains mostly unexplored. In this article, we present VarCop, a novel and effective variability fault localization approach. For an SPL system failed by variability bugs, VarCop isolates suspicious code statements by analyzing the overall test results of the sampled products and their source code. The isolated suspicious statements are the statements related to the interaction among the features which are necessary for the visibility of the bugs in the system. The suspiciousness of each isolated statement is assessed based on both the overall test results of the products containing the statement as well as the detailed results of the test cases executed by the statement in these products. On a large dataset of buggy SPL systems, empirical evaluation shows that VarCop significantly improves two state-of-the-art fault localization techniques by 33% and 50% in ranking the incorrect statements in the systems containing a single bug each. In about two-thirds of the cases, VarCop ranks the buggy statements at the top-3 positions in the resulting lists. For multiple-bug cases, VarCop outperforms the state-of-the-art approaches 2 times and 10 times in the proportion of bugs localized at the top-1 positions. In 22% and 65% of the buggy versions, VarCop correctly ranks at least one bug in a system at the top-1 and top-5 positions.",cs.SE
"Software fault localization is one of the most expensive, tedious, and time-consuming activities in program debugging. This activity becomes even much more challenging in Software Product Line (SPL) systems due to variability of failures. These unexpected behaviors are induced by variability faults which can only be expose under some combinations of system features. The interaction among these features causes the failures of the system. Although localizing bugs in single-system engineering has been studied in-depth, variability fault localization in SPL systems still remains mostly unexplored. In this article, we present VarCop, a novel and effective variability fault localization approach. For an SPL system failed by variability bugs, VarCop isolates suspicious code statements by analyzing the overall test results of the sampled products and their source code. The isolated suspicious statements are the statements related to the interaction among the features which are necessary for the visibility of the bugs in the system. The suspiciousness of each isolated command is assessed based on both the overall test results of the products containing the command as well as the detailed results of the test cases executed by the command in these products. On a large dataset of buggy SPL systems, empirical evaluation shows that VarCop significantly improves two state-of-the-art fault localization techniques by 33% and 50% in ranking the incorrect statements in the systems containing a single bug each. In about two-thirds of the cases, VarCop ranks the buggy statements at the top-3 positions in the resulting lists. For multiple-bug cases, VarCop outperforms the state-of-the-art approaches 2 times and 10 times in the proportion of bugs localized at the top-1 positions. In 22% and 65% of the buggy versions, VarCop correctly ranks at least one bug in a system at the top-1 and top-5 positions.",cs.SE
"Let a and b be any two elements in the group Zn of integers modulo n. Then a and b are called independent if O(a) not equal to O(b) . In this paper, we introduce and study independent graph of the group Zn, denoted by IG(Zn), is undirected simple graph whose vertex set is Zn and two distinct vertices a and b are adjacent in IG(Zn) if and only if a and b are independent in Zn.",math.CO math.GR
"Let a and b be any two elements in the group Zn of integer modulo n. Then a and b are hollo independent if O(a) not equal to O(b) . In this paper, we introduce and study independent graph of the group Zn, denoted by IG(Zn), is undirected simple graph whose vertex set is Zn and two distinct vertices a and b are adjacent in IG(Zn) if and only if a and b are independent in Zn.",math.CO math.GR
"We make a first geometric study of three varieties in $\mathbb{C}^m \otimes \mathbb{C}^m \otimes \mathbb{C}^m$ (for each $m$), including the Zariski closure of the set of tight tensors, the tensors with continuous regular symmetry. Our motivation is to develop a geometric framework for Strassen's Asymptotic Rank Conjecture that the asymptotic rank of any tight tensor is minimal. In particular, we determine the dimension of the set of tight tensors. We prove that this dimension equals the dimension of the set of oblique tensors, a less restrictive class introduced by Strassen.",cs.CC math.AG
"We make a first geometric study of three varieties in $\mathbb{C}^m \otimes \mathbb{C}^m \otimes \mathbb{C}^m$ (for each $m$), including the Zariski closure of the set of tight tensors, the tensors with continuous regular symmetry. Our motivation is to develop a geometric framework for Strassen's Asymptotic grade Conjecture that the asymptotic rank of any tight tensor is minimal. In particular, we ascertain the dimension of the set of tight tensors. We prove that this dimension equals the dimension of the set of oblique tensors, a less restrictive class introduced by Strassen.",cs.CC math.AG
"Stimulated by the $P_{cs}(4459)$ reported by the LHCb Collaboration, we perform a single $\Xi_c\bar{D}^*$ channel and a coupled $\Xi_c\bar{D}^*/\Xi_c^*\bar{D}/\Xi_c^{\prime}\bar{D}^*/\Xi_c^*\bar{D}^*$ channel analysis by using a one-boson-exchange model. Our results indicate that the newly $P_{cs}(4459)$ cannot be a pure $\Xi_c\bar{D}^*$ molecular state, but a coupled $\Xi_c\bar{D}^*/\Xi_c^*\bar{D}/\Xi_c^{\prime}\bar{D}^*/\Xi_c^*\bar{D}^*$ bound state with $I(J^P)=0(3/2^-)$, where the $\Xi_c\bar{D}^*$ and $\Xi_c^*\bar{D}$ components are dominant. Meanwhile, we find the interactions from the $\Xi_c^{\prime}\bar{D}^*$ system with $0(1/2^-)$, the $\Xi_c^{*}\bar{D}$ system with $1(3/2^-)$, and the $\Xi_c^{*}\bar{D}^*$ system with $1(1/2^-)$ are strongly attractive, where one can expect possible strange hidden-charm molecular or resonant structures near the these thresholds with the assigned quantum numbers.",hep-ph
"Stimulated by the $P_{cs}(4459)$ describe by the LHCb Collaboration, we perform a single $\Xi_c\bar{D}^*$ channel and a coupled $\Xi_c\bar{D}^*/\Xi_c^*\bar{D}/\Xi_c^{\prime}\bar{D}^*/\Xi_c^*\bar{D}^*$ channel analysis by using a one-boson-exchange model. Our results indicate that the newly $P_{cs}(4459)$ cannot be a pure $\Xi_c\bar{D}^*$ molecular state, but a coupled $\Xi_c\bar{D}^*/\Xi_c^*\bar{D}/\Xi_c^{\prime}\bar{D}^*/\Xi_c^*\bar{D}^*$ bound state with $I(J^P)=0(3/2^-)$, where the $\Xi_c\bar{D}^*$ and $\Xi_c^*\bar{D}$ components are dominant. Meanwhile, we find the interactions from the $\Xi_c^{\prime}\bar{D}^*$ system with $0(1/2^-)$, the $\Xi_c^{*}\bar{D}$ system with $1(3/2^-)$, and the $\Xi_c^{*}\bar{D}^*$ system with $1(1/2^-)$ are strongly attractive, where one can expect possible strange hidden-charm molecular or reverberative structures near the these thresholds with the assigned quantum numbers.",hep-ph
"We evaluate the chemical potential of a one-dimensional quantum dot, coupled to an atomic force microscope tip. The dot is described within the Luttinger liquid framework and the conductance peaks positions as a function of the tip location are calculated in the linear and non-linear transport regimes for an arbitrary number of particles. The differences between the chemical potential oscillations induced by Friedel and Wigner terms are carefully analyzed in the whole range of interaction strength. It is shown that Friedel oscillations, differently from the Wigner ones, are sensitive probes to detect excited spin states and collective spin density waves involved in the transport.",cond-mat.mes-hall cond-mat.str-el
"We evaluate the chemical potential of a one-dimensional quantum dot, coupled to an atomic force microscope tip. The dot is described within the Luttinger liquid theoretical account and the conductance peaks positions as a function of the tip location are calculated in the linear and non-linear transport regimes for an arbitrary number of particles. The differences between the chemical potential oscillations induced by Friedel and Wigner terms are carefully analyzed in the whole range of interaction strength. It is shown that Friedel oscillations, differently from the Wigner ones, are sensitive probes to notice excited spin states and collective spin density waves involved in the transport.",cond-mat.mes-hall cond-mat.str-el
"We present a measurement of the branching fraction for the decay of the neutral $B$ meson into the final state $J/\psi\pi^+\pi^-$. The data set contains approximately 56 million $B\bar{B}$ pairs produced at the $\Upsilon(4S)$ resonance and recorded with the BaBar detector at the PEP-II asymmetric-energy $e^+e^-$ storage ring. The result of this analysis is $\mathcal{B}$($B^0\to J/\psi\pi^+\pi^-$) = (4.6 $\pm$ 0.7 $\pm$ 0.6)$\times 10^{-5}$, where the first error is statistical and the second is systematic. In addition we measure $\mathcal{B}(B^0\to J/\psi\rho^0) = (1.6 \pm 0.6 \pm 0.4 )\times 10^{-5}$.",hep-ex
"We present a measurement of the branching fraction for the decay of the neutral $B$ mesotron into the final state $J/\psi\pi^+\pi^-$. The data set contains approximately 56 million $B\bar{B}$ pairs produced at the $\Upsilon(4S)$ resonance and recorded with the BaBar sensing element at the PEP-II asymmetric-energy $e^+e^-$ storage ring. The result of this analysis is $\mathcal{B}$($B^0\to J/\psi\pi^+\pi^-$) = (4.6 $\pm$ 0.7 $\pm$ 0.6)$\times 10^{-5}$, where the first error is statistical and the second is systematic. In addition we measure $\mathcal{B}(B^0\to J/\psi\rho^0) = (1.6 \pm 0.6 \pm 0.4 )\times 10^{-5}$.",hep-ex
"Non-discrimination is a recognized objective in algorithmic decision making. In this paper, we introduce a novel probabilistic formulation of data pre-processing for reducing discrimination. We propose a convex optimization for learning a data transformation with three goals: controlling discrimination, limiting distortion in individual data samples, and preserving utility. We characterize the impact of limited sample size in accomplishing this objective, and apply two instances of the proposed optimization to datasets, including one on real-world criminal recidivism. The results demonstrate that all three criteria can be simultaneously achieved and also reveal interesting patterns of bias in American society.",cs.CY cs.IT math.IT stat.ML
"Non-discrimination is a agnize objective in algorithmic decision making. In this paper, we introduce a novel probabilistic formulation of data pre-processing for reducing discrimination. We propose a convex optimization for learning a data transformation with three goals: controlling discrimination, limiting distortion in individual data samples, and preserving utility. We characterize the impact of limited sample size in accomplishing this objective, and apply two instances of the proposed optimization to datasets, including one on real-world criminal recidivism. The results demonstrate that all three criteria can be simultaneously achieved and also reveal interesting practice of bias in American society.",cs.CY cs.IT math.IT stat.ML
"We report on measurements of single electron tunneling through a quantum dot using a quantum point contact as non-invasive charge detector with fast time response. We elaborate on the unambiguous identification of individual tunneling events and determine the distribution of transferred charges, the so-called full counting statistics. We discuss our data analysis, including the error estimates of the measurement, and show that the quality of our experimental results is sufficiently high to extract cumulants of the distribution up to the 20th order for short times.",cond-mat.mes-hall
"We report on measurements of single electron tunneling through with a quantum dot using a quantum point contact as non-invasive mission detector with fast time response. We elaborate on the unambiguous identification of individual tunneling events and determine the distribution of transferred charges, the so-called full counting statistics. We discuss our data analysis, including the error estimates of the measurement, and show that the quality of our experimental results is sufficiently high to extract cumulants of the distribution up to the 20th order for short times.",cond-mat.mes-hall
"The problem of network coding for multicasting a single source to multiple sinks has first been studied by Ahlswede, Cai, Li and Yeung in 2000, in which they have established the celebrated max-flow mini-cut theorem on non-physical information flow over a network of independent channels. On the other hand, in 1980, Han has studied the case with correlated multiple sources and a single sink from the viewpoint of polymatroidal functions in which a necessary and sufficient condition has been demonstrated for reliable transmission over the network. This paper presents an attempt to unify both cases, which leads to establish a necessary and sufficient condition for reliable transmission over a noisy network for multicasting all the correlated multiple sources to all the multiple sinks. Furthermore, we address also the problem of transmitting ""independent"" sources over a multiple-access-type of network as well as over a broadcast-type of network, which reveals that the (co-) polymatroidal structures are intrinsically involved in these types of network coding.",cs.IT math.IT
"The problem of network coding for multicasting a single source to multiple sinks has first been studied by Ahlswede, Cai, Li and Yeung in 2000, in which they have established the celebrated max-flow mini-cut theorem on non-physical information flow over a network of independent channels. On the other hand, in 1980, Han has studied the case with correlated multiple source and a single sink from the viewpoint of polymatroidal functions in which a necessary and sufficient condition has been demonstrated for dependable transmission over the network. This paper presents an attempt to unify both cases, which leads to establish a necessary and sufficient condition for dependable transmission over a noisy network for multicasting all the correlated multiple source to all the multiple sinks. Furthermore, we address also the problem of transmitting ""independent"" source over a multiple-access-type of network as well as over a broadcast-type of network, which reveals that the (co-) polymatroidal structures are intrinsically involved in these types of network coding.",cs.IT math.IT
"When formulated in twistor space, the D-instanton corrected hypermultiplet moduli space in N=2 string vacua and the Coulomb branch of rigid N=2 gauge theories on $R^3 \times S^1$ are strikingly similar and, to a large extent, dictated by consistency with wall-crossing. We elucidate this similarity by showing that these two spaces are related under a general duality between, on one hand, quaternion-Kahler manifolds with a quaternionic isometry and, on the other hand, hyperkahler manifolds with a rotational isometry, further equipped with a hyperholomorphic circle bundle with a connection. We show that the transition functions of the hyperholomorphic circle bundle relevant for the hypermultiplet moduli space are given by the Rogers dilogarithm function, and that consistency across walls of marginal stability is ensured by the motivic wall-crossing formula of Kontsevich and Soibelman. We illustrate the construction on some simple examples of wall-crossing related to cluster algebras for rank 2 Dynkin quivers. In an appendix we also provide a detailed discussion on the general relation between wall-crossing and the theory of cluster algebras.",hep-th math-ph math.AG math.DG math.MP math.SG
"When formulated in twistor space, the D-instanton corrected hypermultiplet moduli space in N=2 string vacua and the Coulomb branch of rigid N=2 gauge theories on $R^3 \times S^1$ are strikingly similar and, to a large extent, dictated by consistency with wall-crossing. We elucidate this law of similarity by showing that these two distance are related under a general duality between, on one hand, quaternion-Kahler manifolds with a quaternionic isometry and, on the other hand, hyperkahler manifolds with a rotational isometry, further equipped with a hyperholomorphic circle bundle with a connection. We show that the transition functions of the hyperholomorphic circle bundle relevant for the hypermultiplet moduli space are given by the Rogers dilogarithm function, and that consistency across walls of marginal stability is ensured by the motivic wall-crossing formula of Kontsevich and Soibelman. We illustrate the construction on some simple examples of wall-crossing related to cluster algebras for rank 2 Dynkin quivers. In an appendix we also provide a detailed discussion on the general relation between wall-crossing and the theory of cluster algebras.",hep-th math-ph math.AG math.DG math.MP math.SG
"Studies based on high-resolution spectroscopic data of rapidly oscillating Ap stars show a surprising diversity of pulsation behavior in the atmospheric layers, pointing, in particular, to the co-existence of running and standing waves. The correct interpretation of these data requires a careful modelling of pulsations in these magnetic stars. In light of this, in this work we present a theoretical analysis of pulsations in roAp stars, taking into account the direct influence of the magnetic field. We derive approximate analytical solutions for the displacement components parallel and perpendicular to the direction of the magnetic field, that are appropriate to the outermost layer. From these, we determine the expression for the theoretical radial velocity for an observer at a general position, and compute the corresponding pulsation amplitude and phase as function of height in the atmosphere. We show that the integral for the radial velocity has contributions from three different types of wave solutions, namely, running waves, evanescent waves, and standing waves of nearly constant amplitude. We then consider a number of case studies to illustrate the origin of the different pulsational behaviour that is found in the observations. Concerning pulsation amplitude, we find that it generally increases with atmospheric height. Pulsation phase, however, shows a diversity of behaviours, including phases that are constant, increasing, or decreasing with atmospheric height. Finally, we show that there are situations in which the pulsation amplitude goes through a zero, accompanied by a phase jumps of $\pi$, and argue that such behaviour does not correspond to a pulsation node in the outermost layers of the star, but rather to a visual effect, resulting from the observers inability to resolve the stellar surface.",astro-ph.SR
"Studies based on high-resolution spectroscopic data of rapidly oscillating Ap stars show a surprising diversity of pulsation behavior in the atmospheric layers, pointing, in particular, to the co-existence of running and standing waves. The correct interpretation of these data requires a careful modelling of pulsations in these magnetic stars. In light of this, in this work we stage a theoretical analysis of pulsations in roAp stars, taking into account the direct influence of the magnetic field. We derive approximate analytical solutions for the displacement components parallel and perpendicular to the direction of the magnetic field, that are appropriate to the outermost layer. From these, we determine the expression for the theoretical radial velocity for an observer at a general position, and compute the corresponding pulsation amplitude and phase as function of height in the atmosphere. We show that the integral for the radial velocity has contributions from three different typecast of wave solutions, namely, running waves, evanescent waves, and standing waves of nearly constant amplitude. We then consider a number of case studies to illustrate the origin of the different pulsational behaviour that is found in the observations. Concerning pulsation amplitude, we find that it generally increases with atmospheric height. Pulsation phase, however, shows a diversity of behaviours, including phases that are constant, increasing, or decreasing with atmospheric height. Finally, we show that there are situations in which the pulsation amplitude goes through a zero, accompanied by a phase jumps of $\pi$, and argue that such behaviour does not correspond to a pulsation node in the outermost layers of the star, but rather to a visual effect, resulting from the observers inability to resolve the stellar surface.",astro-ph.SR
"Aiming to approach the thermodynamical properties of hard-core systems by standard molecular dynamics simulation, we propose setting a repulsive constant-force for overlapping particles. That is, the discontinuity of the pair potential is replaced by a linear function with a large negative slope. Hence, the core-core repulsion, usually modeled with a power function of distance, yields a large force as soon as the cores slightly overlap. This leads to a quasi-hardcore behavior. The idea is tested for a triangle potential of short range. The results obtained by replica exchange molecular dynamics for several repulsive forces are contrasted with the ones obtained for the discontinuous potential and by means of replica exchange Monte Carlo. We found remarkable agreements for the vapor-liquid coexistence densities as well as for the surface tension.",cond-mat.soft
"Aiming to approach the thermodynamical properties of hard-core systems by standard molecular dynamics simulation, we propose setting a hideous constant-force for overlapping particles. That is, the discontinuity of the pair potential is replaced by a linear function with a large negative slope. Hence, the core-core repulsion, usually modeled with a power function of distance, yields a large force as soon as the cores slightly overlap. This leads to a quasi-hardcore behavior. The idea is tested for a triangle potential of short range. The results obtained by replica exchange molecular dynamics for several hideous forces are contrasted with the ones obtained for the discontinuous potential and by mean value of replica exchange Monte Carlo. We found remarkable agreements for the vapor-liquid coexistence densities as well as for the surface tension.",cond-mat.soft
"Using a recently proposed group-theoretical approach, we explore novel gaugings of maximal supergravity in four dimensions with gauge group embeddings that can be generated by fluxes of IIB string theory. The corresponding potentials are positive without stationary points. Some allow domain wall solutions which can be elevated to ten dimensions. Appropriate truncations describe type-IIB flux compactifications on T^6 orientifolds leading to non-maximal, four-dimensional, supergravities.",hep-th
"Using a recently proposed group-theoretical approach, we explore novel gaugings of maximal supergravity in four dimensions with gauge group embeddings that can be generated by fluxes of IIB draw theory. The corresponding potentials are confident without stationary points. Some allow domain wall solutions which can be elevated to ten dimensions. Appropriate truncations describe type-IIB flux compactifications on T^6 orientifolds leading to non-maximal, four-dimensional, supergravities.",hep-th
"I examine the possibility that the third generation fermion masses are determined by an exact fixed point of the minimal supersymmetric SU(5) model. When one-loop supersymmetric thresholds are included, this unified fixed point successfully predicts the top quark mass, 175 +(-) 2 GeV, as well as the weak mixing angle. The bottom quark mass prediction is sensitive to the supersymmetric thresholds; it approaches the measured value for mu <0 and very large unified gaugino mass. The experimental measurement of the tau lepton mass determines tan(beta), and the strong gauge coupling and fine structure constant fix the unification scale and the unified gauge coupling.",hep-ph
"I examine the possibility that the third coevals fermion masses are determined by an precise fixed point of the minimal supersymmetric SU(5) model. When one-loop supersymmetric thresholds are included, this unified fixed point successfully predicts the top quark mass, 175 +(-) 2 GeV, as well as the weak mixing angle. The bottom quark mass prediction is sensitive to the supersymmetric thresholds; it approaches the measured value for mu <0 and very large unified gaugino mass. The experimental measurement of the tau lepton mass determines tan(beta), and the strong gauge coupling and fine structure constant fix the unification scale and the unified gauge coupling.",hep-ph
"One of the key issues in mobile communication is to find the current location of mobile terminal (MT) to deliver the services, which is called as location management (LM). Increasing users and diverse services demand for a high-quality skeleton for LM. As an MT moves within a cellular network, it registers its new location to the nearest base station (BS). When a call arrives for an MT, the network searches the target MT in the area where it was last registered. This paper presents comprehensive classification of existing major LM schemes, their comparative study and factors influencing their performance. Finally, guidelines for developing and rating a LM scheme are suggested with the help of LPCIC rule, which is the main contribution of this paper.",cs.NI
"One of the key issues in mobile communication is to find the current location of mobile terminal (MT) to deliver the services, which is called as location management (LM). Increasing users and diverse services demand for a high-quality skeleton for LM. As an MT moves within a cellular network, it registers its new location to the nearest base station (BS). When a call arrives for an MT, the network searches the target MT in the area where it was survive registered. This paper presents comprehensive classification of existing major LM schemes, their comparative study and factors mold their performance. Finally, guidelines for developing and rating a LM scheme are suggested with the help of LPCIC rule, which is the main contribution of this paper.",cs.NI
"The improved quantum scheduling algorithm proposed by Grover has been generalized using the generalized quantum search algorithm, in which a unitary operator replaces the Walsh-Hadamard transform, and $\pi/2$ phase rotations replace the selective inversions, in order to make the quantum scheduling algorithm suitable for more cases. Our scheme is realized on a nuclear magnetic resonance (NMR) quantum computer. Experimental results show a good agreement between theory and experiment.",quant-ph
"The improved quantum scheduling algorithm proposed by Grover has been generalized using the generalized quantum search algorithm, in which a unitary operator replaces the Walsh-Hadamard transform, and $\pi/2$ phase rotations replace the selective inversions, in order to make the quantum scheduling algorithm suitable for more cases. Our scheme is realized on a nuclear magnetic reverberance (NMR) quantum computer. Experimental results bear witness a good agreement between theory and experiment.",quant-ph
"It is argued that the recent Belle data, consistent with no activity in the spectrum of the $B^* \bar B + B \bar B^*$ pairs at the mass of the $Z_b(10650)$ resonance, imply that the part of the interaction between heavy mesons that depends on the total spin of the light quark and antiquark is strongly suppressed. In particular this part appears to be significantly weaker than can be inferred from pion exchange. If confirmed by future more detailed data, the symmetry with respect to the light quark spins, in combination with the heavy quark spin symmetry, would imply existence of four additional $I^G=1^-$ resonances at the thresholds for heavy meson-antimeson pairs.",hep-ex hep-ph
"It is argued that the recent Belle data, consistent with no activity in the spectrum of the $B^* \bar B + B \bar B^*$ pairs at the mass of the $Z_b(10650)$ resonance, involve that the part of the interaction between heavy mesons that depends on the total spin around of the light quark and antiquark is strongly suppressed. In particular this part appears to be significantly weaker than can be inferred from pion exchange. If confirmed by future more detailed data, the symmetry with respect to the light quark spins, in combination with the heavy quark spin around symmetry, would involve existence of four additional $I^G=1^-$ resonances at the thresholds for heavy meson-antimeson pairs.",hep-ex hep-ph
"We introduce a large class of modifications of the standard lagrangian for two dimensional dilaton gravity, whose general solutions are nonsingular black holes. A subclass of these lagrangians have extremal solutions which are nonsingular analogues of the extremal Reissner-Nordstrom spacetime. It is possible that quantum deformations of these extremal solutions are the endpoint of Hawking evaporation when the models are coupled to matter, and that the resulting evolution may be studied entirely within the framework of the semiclassical approximation. Numerical work to verify this conjecture is in progress. We point out however that the solutions with non-negative mass always contain Cauchy horizons, and may be sensitive to small perturbations.",hep-th
"We introduce a large class of change of the standard lagrangian for two dimensional dilaton gravity, whose universal solutions are nonsingular black holes. A subclass of these lagrangians have extremal solutions which are nonsingular analogues of the extremal Reissner-Nordstrom spacetime. It is possible that quantum deformations of these extremal solutions are the endpoint of Hawking evaporation when the models are coupled to matter, and that the resulting evolution may be studied entirely within the framework of the semiclassical approximation. Numerical work to verify this conjecture is in progress. We point out however that the solutions with non-negative mass always contain Cauchy horizons, and may be sensitive to small perturbations.",hep-th
"We investigate the finite sample performance of sample splitting, cross-fitting and averaging for the estimation of the conditional average treatment effect. Recently proposed methods, so-called meta-learners, make use of machine learning to estimate different nuisance functions and hence allow for fewer restrictions on the underlying structure of the data. To limit a potential overfitting bias that may result when using machine learning methods, cross-fitting estimators have been proposed. This includes the splitting of the data in different folds to reduce bias and averaging over folds to restore efficiency. To the best of our knowledge, it is not yet clear how exactly the data should be split and averaged. We employ a Monte Carlo study with different data generation processes and consider twelve different estimators that vary in sample-splitting, cross-fitting and averaging procedures. We investigate the performance of each estimator independently on four different meta-learners: the doubly-robust-learner, R-learner, T-learner and X-learner. We find that the performance of all meta-learners heavily depends on the procedure of splitting and averaging. The best performance in terms of mean squared error (MSE) among the sample split estimators can be achieved when applying cross-fitting plus taking the median over multiple different sample-splitting iterations. Some meta-learners exhibit a high variance when the lasso is included in the ML methods. Excluding the lasso decreases the variance and leads to robust and at least competitive results.",stat.ME
"We investigate the finite sample performance of sample splitting, cross-fitting and averaging for the estimation of the conditional average treatment effect. Recently proposed methods, supposed meta-learners, make use of machine learning to estimate different nuisance functions and thus allow for fewer restrictions on the underlying structure of the data. To limit a potential overfitting bias that may result when using machine learning methods, cross-fitting estimators have been proposed. This includes the splitting of the data in different folds to reduce bias and averaging over folds to restore efficiency. To the best of our knowledge, it is not yet clear how exactly the data should be split and averaged. We employ a Monte Carlo study with different data generation processes and consider twelve different estimators that vary in sample-splitting, cross-fitting and averaging procedures. We investigate the performance of each estimator independently on four different meta-learners: the doubly-robust-learner, R-learner, T-learner and X-learner. We find that the performance of all meta-learners heavily depends on the procedure of splitting and averaging. The best performance in terms of mean squared error (MSE) among the sample split estimators can be achieved when applying cross-fitting plus taking the median over multiple different sample-splitting iterations. Some meta-learners exhibit a high variance when the lasso is included in the ML methods. Excluding the lasso decreases the variance and leads to robust and at least competitive results.",stat.ME
"We use the integrated polarized radio emission at 1.4 GHz ($\Pi_{\rm 1.4\,GHz}$) from a large sample of AGN (796 sources at redshifts $z<0.7$) to study the large-scale magnetic field properties of radio galaxies in relation to the host galaxy accretion state. We find a fundamental difference in $\Pi_{\rm 1.4\,GHz}$ between radiative-mode AGN (i.e. high-excitation radio galaxies, HERGs, and radio-loud QSOs) and jet-mode AGN (i.e. low-excitation radio galaxies, LERGs). While LERGs can achieve a wide range of $\Pi_{\rm 1.4\,GHz}$ (up to $\sim$$30\%$), the HERGs and radio-loud QSOs are limited to $\Pi_{\rm 1.4\,GHz} \lesssim 15\%$. A difference in $\Pi_{\rm 1.4\,GHz}$ is also seen when the sample is divided at 0.5% of the total Eddington-scaled accretion rate, where the weakly accreting sources can attain higher values of $\Pi_{\rm 1.4\,GHz}$. We do not find any clear evidence that this is driven by intrinsic magnetic field differences of the different radio morphological classes. Instead, we attribute the differences in $\Pi_{\rm 1.4\,GHz}$ to the local environments of the radio sources, in terms of both the ambient gas density and the magnetoionic properties of this gas. Thus, not only are different large-scale gaseous environments potentially responsible for the different accretion states of HERGs and LERGs, we argue that the large-scale magnetised environments may also be important for the formation of powerful AGN jets. Upcoming high angular resolution and broadband radio polarization surveys will provide the high precision Faraday rotation measure and depolarization data required to robustly test this claim.",astro-ph.CO astro-ph.GA
"We use the integrated polarized radio emission at 1.4 GHz ($\Pi_{\rm 1.4\,GHz}$) from a large sample of AGN (796 sources at redshifts $z<0.7$) to study the large-scale magnetic field properties of radio galaxies in relation to the host galaxy accretion state. We find a fundamental difference in $\Pi_{\rm 1.4\,GHz}$ between radiative-mode AGN (i.e. high-excitation radio galaxies, HERGs, and radio-loud QSOs) and jet-mode AGN (i.e. low-excitation radio galaxies, LERGs). While LERGs can achieve a broad range of $\Pi_{\rm 1.4\,GHz}$ (up to $\sim$$30\%$), the HERGs and radio-loud QSOs are limited to $\Pi_{\rm 1.4\,GHz} \lesssim 15\%$. A difference in $\Pi_{\rm 1.4\,GHz}$ is also seen when the sample is divided at 0.5% of the total Eddington-scaled accretion rate, where the weakly accreting sources can attain higher values of $\Pi_{\rm 1.4\,GHz}$. We do not find any clear evidence that this is driven by intrinsic magnetic field differences of the different radio morphological classes. Instead, we attribute the differences in $\Pi_{\rm 1.4\,GHz}$ to the local environments of the radio sources, in terms of both the ambient gas density and the magnetoionic properties of this gas. Thus, not only are different large-scale gaseous environments potentially responsible for the different accretion states of HERGs and LERGs, we argue that the large-scale magnetised environments may also be important for the formation of powerful AGN jets. Upcoming high angular resolution and broadband radio polarization surveys will provide the high precision Faraday rotation measure and depolarization data needful to robustly test this claim.",astro-ph.CO astro-ph.GA
"Any associative bilinear multiplication on the set of n-by-n matrices over some field of characteristic not two, that makes the same vectors orthogonal and has the same trace as ordinary matrix multiplication, must be ordinary matrix multiplication or its opposite.",math.RA
"Any associative bilinear multiplication on the set of n-by-n matrices over some field of characteristic not two, that give the same vectors orthogonal and has the same trace as ordinary matrix multiplication, moldiness be ordinary matrix multiplication or its opposite.",math.RA
"We consider a $\pi_{1}$--injective immersion $f:\Sigma\to M$ from a compact surface $\Sigma$ to a hyperbolic 3--manifold $M$. Let $\Gamma$ denote the copy of $\pi_{1}\Sigma$ in $\mathrm{Isom}({\mathbb{H}}^{3})$ induced by the immersion and $\delta(\Gamma)$ be the critical exponent. Suppose $\Gamma$ is convex cocompact and $\Sigma$ is negatively curved, we prove that there are two geometric constants $C_{1}(\Sigma,M)$ and $C_{2}(\Sigma,M)$ not bigger than $1$ such that $C_{1}(\Sigma,M)\cdot\delta_{\Gamma}\leq h(\Sigma)\leq C_{2}(\Sigma,M)\cdot\delta_{\Gamma}$, where $h(\Sigma)$ is the topological entropy of the geodesic flow on. When $f$ is an embedding, we show that $C_{1}(\Sigma,M)$ and $C_{2}(\Sigma,M)$ are exactly the geodesic stretches (a.k.a. Thurston's intersection number) with respect to certain Gibbs measures. Moreover, we prove the rigidity phenomenon arising from this inequality. Lastly, as an application, we discuss immersed minimal surfaces in hyperbolic 3--manifolds and these discussions lead us to results similar to A. Sanders' work on the moduli space of $\Sigma$ introduced by C. Taubes.",math.DS
"We consider a $\pi_{1}$--injective immersion $f:\Sigma\to M$ from a compact surface $\Sigma$ to a hyperbolic 3--manifold $M$. Let $\Gamma$ denote the copy of $\pi_{1}\Sigma$ in $\mathrm{Isom}({\mathbb{H}}^{3})$ induced by the immersion and $\delta(\Gamma)$ be the critical exponent. Suppose $\Gamma$ is convex cocompact and $\Sigma$ is negatively curved, we prove that there are two geometrical constants $C_{1}(\Sigma,M)$ and $C_{2}(\Sigma,M)$ not bigger than $1$ such that $C_{1}(\Sigma,M)\cdot\delta_{\Gamma}\leq h(\Sigma)\leq C_{2}(\Sigma,M)\cdot\delta_{\Gamma}$, where $h(\Sigma)$ is the topological entropy of the geodesic flow on. When $f$ is an embedding, we show that $C_{1}(\Sigma,M)$ and $C_{2}(\Sigma,M)$ are precisely the geodesic stretches (a.k.a. Thurston's intersection number) with respect to certain Gibbs measures. Moreover, we prove the rigidity phenomenon arising from this inequality. Lastly, as an application, we discuss immersed minimal surfaces in hyperbolic 3--manifolds and these discussions lead us to results similar to A. Sanders' work on the moduli space of $\Sigma$ introduced by C. Taubes.",math.DS
"We study the effects of spin-orbit coupling (SOC) on the large-U Hubbard model on anisotropic triangular lattice at half-filling using the Schwinger-boson method. We find that the SOC will in general lead to a zero temperature condensation of the Schwinger bosons with a single condensation momentum. As a consequence, the spin-spin correlation vanishes along the z-axis but develops in the $x$-$y$ plane, with the ordering wave vector being dramatically dependent on the SOC. Moreover, the phase boundary of the magnetic ordered state extends to the region of large spatial anisotropy with increased condensation density, demonstrating that the spiral order is always stabilized by the SOC.",cond-mat.str-el
"We study the effects of spin-orbit coupling (SOC) on the large-U Hubbard model on anisotropic triangular lattice at half-filling using the Schwinger-boson method. We find that the SOC will in general lead to a zero temperature condensation of the Schwinger bosons with a single condensation momentum. As a consequence, the spin-spin correlation vanishes along the z-axis but develops in the $x$-$y$ plane, with the ordering wave vector cost dramatically dependent on the SOC. Moreover, the phase boundary of the magnetic rank state extends to the region of large spatial anisotropy with increased condensation density, demonstrating that the spiral order is always stabilized by the SOC.",cond-mat.str-el
"Quantum Theory and Humeanism have long been thought to be incompatible due to the irreducibility of the correlations involved in entangled states. In this paper, we reconstruct the tension between Humeanism and entanglement via the concept of causal structure, and provide a philosophical introduction to the ER=EPR conjecture. With these tools, we then show how the concept of causal structure and the ER=EPR conjecture allow us to resolve the conflict between Humeanism and entanglement.",gr-qc hep-th physics.hist-ph
"Quantum Theory and Humeanism have long been thought to be incompatible due to the irreducibility of the correlations involved in entangled states. In this paper, we reconstruct the tension between Humeanism and entanglement via the concept of causal structure, and provide a philosophical introduction to the ER=EPR conjecture. With these tools, we then point how the concept of causal structure and the ER=EPR conjecture grant us to resolve the conflict between Humeanism and entanglement.",gr-qc hep-th physics.hist-ph
"This paper investigates numerically a phenomenon which can be used to transport a single q-bit down a J1-J2 Heisenberg spin chain using a quantum adiabatic process. The motivation for investigating such processes comes from the idea that this method of transport could potentially be used as a means of sending data to various parts of a quantum computer made of artificial spins, and that this method could take advantage of the easily prepared ground state at the so called Majumdar-Ghosh point. We examine several annealing protocols for this process and find similar result for all of them. The annealing process works well up to a critical frustration threshold.",quant-ph
"This paper investigates numerically a phenomenon which can be used to transport a single q-bit down a J1-J2 Heisenberg spin chain using a quantum adiabatic process. The motivation for investigating such processes comes from the idea that this method of transport could potentially be used as a means of sending data to various parts of a quantum computer made of artificial spins, and that this method could study advantage of the easily prepared ground state at the so called Majumdar-Ghosh point. We examine several annealing protocol for this process and find similar result for all of them. The annealing process works well up to a critical frustration threshold.",quant-ph
"We present the analysis of Fermi Large Area Telescope (LAT) {\gamma}-ray observations of HB 21, a mixed-morphology supernova remnant. Such supernova remnants are characterized by an interior thermal X-ray plasma, surrounded by a wider nonthermal shell emitting at radio frequencies. HB 21 has a large angular size, making it a good candidate for detailed morphological and spectral studies with the LAT. The radio extension is 2{\deg}x1{\deg}.5, compared to the LAT 68% containment angle of ~1{\deg} at 1 GeV. To understand the origin of {\gamma}-ray emission, we compare LAT observations with other wavelengths that trace non-thermal radio synchrotron, nearby molecular clouds, shocked molecular clumps, and the central X-ray plasma. Finally, we model possible hadronic and leptonic emission mechanisms. We conclude that {\gamma}-rays from HB 21 are likely the result of electron bremsstrahlung or proton-proton collisions with dense material due to interaction with the nearby clouds.",astro-ph.HE
"We present the analysis of Fermi Large Area Telescope (LAT) {\gamma}-ray observations of HB 21, a mixed-morphology supernova remnant. Such supernova remnants are characterise by an interior thermal X-ray plasma, surrounded by a wider nonthermal shell emitting at radio frequencies. HB 21 has a large angular size, making it a good candidate for detailed morphological and spectral studies with the LAT. The radio extension is 2{\deg}x1{\deg}.5, compared to the LAT 68% containment angle of ~1{\deg} at 1 GeV. To understand the origin of {\gamma}-ray emission, we compare LAT observations with other wavelengths that trace non-thermal radio synchrotron, nearby molecular clouds, take aback molecular clumps, and the central X-ray plasma. Finally, we model possible hadronic and leptonic emission mechanisms. We conclude that {\gamma}-rays from HB 21 are likely the result of electron bremsstrahlung or proton-proton collisions with dense material due to interaction with the nearby clouds.",astro-ph.HE
"We have investigated the formation of helium droplets in two physical situations. In the first one, droplets are atomised from superfluid or normal liquid by a fast helium vapour flow. In the second, droplets of normal liquid are formed inside porous glasses during the process of helium condensation. The context, aims, and results of these experiments are reviewed, with focus on the specificity of light scattering by helium. In particular, we discuss how, for different reasons, the closeness to unity of the index of refraction of helium allows in both cases to minimise the problem of multiple scattering and obtain results which it would not be possible to get using other fluids.",cond-mat.soft cond-mat.stat-mech physics.class-ph physics.optics
"We have investigated the formation of helium droplets in two physical situations. In the first one, droplets are atomised from superfluid or normal liquid by a fast helium vapour flow. In the second, droplets of normal liquid are formed inside porous glasses during the process of helium condensation. The context, aims, and results of these experiments are reviewed, with focus on the specificity of light dispersion by helium. In particular, we discuss how, for different reasons, the closeness to unity of the index of refraction of helium allows in both cases to minimise the problem of multiple dispersion and obtain results which it would not be potential to get using other fluids.",cond-mat.soft cond-mat.stat-mech physics.class-ph physics.optics
"We find presentations by generators and relations for the equivariant quantum cohomology of the Grassmannian. For these presentations, we also find determinantal formulae for the equivariant quantum Schubert classes. To prove this, we use the theory of factorial Schur functions and a characterization of the equivariant quantum cohomology ring.",math.AG math.CO
"We ascertain presentations by generators and relations for the equivariant quantum cohomology of the Grassmannian. For these presentations, we also ascertain determinantal formulae for the equivariant quantum Schubert classes. To prove this, we use the possibility of factorial Schur functions and a characterization of the equivariant quantum cohomology ring.",math.AG math.CO
"After reviewing the Green-Schwarz superstring using the approach of Siegel, the superstring is covariantly quantized by constructing a BRST operator from the fermionic constraints and a bosonic pure spinor ghost variable. Physical massless vertex operators are constructed and, for the first time, N-point tree amplitudes are computed in a manifestly ten-dimensional super-Poincar\'e covariant manner. Quantization can be generalized to curved supergravity backgrounds and the vertex operator for fluctuations around $AdS_5\times S^5$ is explicitly constructed. This review is written in a self-contained manner and is based on talks given at the Fradkin Memorial Conference and Strings 2000.",hep-th
"After reviewing the Green-Schwarz superstring using the approach of Siegel, the superstring is covariantly quantized by constructing a BRST operator from the fermionic constraints and a bosonic pure spinor ghost variable. Physical massless vertex wheeler dealer are constructed and, for the first time, N-point tree amplitudes are computed in a manifestly ten-dimensional super-Poincar\'e covariant manner. Quantization can be generalized to kink supergravity backgrounds and the vertex operator for fluctuations around $AdS_5\times S^5$ is explicitly constructed. This review is written in a self-contained manner and is based on talks given at the Fradkin Memorial Conference and Strings 2000.",hep-th
"This is a review of hadron structure physics from lattice QCD. Throughout this report, we place emphasis on the contribution of lattice results to our understanding of a number of fundamental physics questions related to, e.g., the origin and distribution of the charge, magnetization, momentum and spin of hadrons. Following an introduction to some of the most important hadron structure observables, we summarize the methods and techniques employed for their calculation in lattice QCD. We briefly discuss the status of relevant chiral perturbation theory calculations needed for controlled extrapolations of the lattice results to the physical point. In the main part of this report, we give an overview of lattice calculations on hadron form factors, moments of (generalized) parton distributions, moments of hadron distribution amplitudes, and other important hadron structure observables. Whenever applicable, we compare with results from experiment and phenomenology, taking into account systematic uncertainties in the lattice computations. Finally, we discuss promising results based on new approaches, ideas and techniques, and close with remarks on future perspectives of the field.",hep-lat hep-ph
"This is a review of hadron structure physics from lattice QCD. Throughout this report, we place emphasis on the contribution of lattice results to our understanding of a number of fundamental physics questions related to, e.g., the origin and distribution of the charge, magnetization, momentum and spin of hadrons. Following an introduction to some of the most important hadron structure observables, we summarize the methods and techniques employed for their calculation in lattice QCD. We briefly discuss the status of relevant chiral perturbation theory calculations needed for controlled extrapolations of the lattice results to the physical point. In the briny set out of this report, we give an overview of lattice calculations on hadron form factors, moments of (generalized) parton distributions, moments of hadron distribution amplitudes, and other important hadron structure observables. Whenever applicable, we compare with results from experiment and phenomenology, taking into account systematic uncertainties in the lattice computations. Finally, we discuss promising results based on new approaches, ideas and techniques, and close with remarks on future perspectives of the field.",hep-lat hep-ph
"We prove several theorems concerning the connection between the local CR embeddability of 3-dimensional CR manifolds, and the existence of algebraically special Maxwell and gravitational fields. We reduce the Einstein equations for spacetimes associated with such fields to a system of CR invariant equations on a 3-dimensional CR manifold defined by the fields. Using the reduced Einstein equations we construct two independent CR functions for the corresponding CR manifold. We also point out that the Einstein equations, imposed on spacetimes associated with a 3-dimensional CR manifold, imply that the spacetime metric, after an appropriate rescaling, becomes well defined on a circle bundle over the CR manifold. The circle bundle itself emerges as a consequence of Einstein's equations.",math.AP math.CV math.DG
"We prove several theorem concerning the connection between the local CR embeddability of 3-dimensional CR manifolds, and the existence of algebraically special Maxwell and gravitational fields. We reduce the Einstein equality for spacetimes associated with such fields to a system of CR invariant equality on a 3-dimensional CR manifold defined by the fields. Using the reduced Einstein equality we construct two independent CR functions for the corresponding CR manifold. We also point out that the Einstein equations, imposed on spacetimes associated with a 3-dimensional CR manifold, imply that the spacetime metric, after an appropriate rescaling, becomes well defined on a circle bundle over the CR manifold. The circle bundle itself emerges as a consequence of Einstein's equations.",math.AP math.CV math.DG
"Perturbative canonical quantum gravity is considered, when coupled to a renormalizable model for matter fields. It is proposed that the functional integral over the dilaton field should be disentangled from the other integrations over the metric fields. This should generate a conformally invariant theory as an intermediate result, where the conformal anomalies must be constrained to cancel out. When the residual metric is treated as a background, and if this background is taken to be flat, this leads to a novel constraint: in combination with the dilaton contributions, the matter lagrangian should have a vanishing beta function. The zeros of this beta function are isolated points in the landscape of quantum field theories, and so we arrive at a denumerable, or perhaps even finite, set of quantum theories for matter, where not only the coupling constants, but also the masses and the cosmological constant are all fixed, and computable, in terms of the Planck units.",gr-qc hep-th
"Perturbative canonical quantum gravity is considered, when coupled to a renormalizable model for matter fields. It is proposed that the functional integral ended the dilaton field should be disentangled from the other integrations ended the metric fields. This should generate a conformally invariant theory as an intermediate result, where the conformal anomalies must be constrained to cancel out. When the residual metric is treated as a background, and if this background is taken to be flat, this leads to a novel constraint: in combination with the dilaton contributions, the matter lagrangian should have a vanishing genus beta function. The zeros of this genus beta function are isolated points in the landscape of quantum field theories, and so we arrive at a denumerable, or perhaps even finite, set of quantum theories for matter, where not only the coupling constants, but also the masses and the cosmological constant are all fixed, and computable, in terms of the Planck units.",gr-qc hep-th
"The angular momentum propagated by a beam of radiation has two contributions: spin angular momentum (SAM) and orbital angular momentum (OAM). SAM corresponds to wave polarisation, while OAM-carrying beams are characterized by a phase which is a function of azimuth. We demonstrate experimentally that radio beams propagating OAM can be generated and coherently detected using ordinary electric dipole antennas. The results presented here could pave the way for novel radio OAM applications in technology and science, including radio communication, passive remote sensing, and new types of active (continuous or pulsed transmission) electromagnetic measurements.",physics.class-ph
"The angulate momentum propagated by a beam of radiation has two contributions: spin angulate momentum (SAM) and orbital angulate momentum (OAM). SAM corresponds to wave polarisation, while OAM-carrying beams are characterized by a phase which is a function of azimuth. We demonstrate experimentally that radio beams propagating OAM can be generated and coherently detected using ordinary electric dipole antenna antennas. The results presented here could pave the way for novel radio OAM applications in technology and science, including radio communication, passive remote sensing, and new types of active (continuous or pulsed transmission) electromagnetic measurements.",physics.class-ph
"We report a method to control the positions of ellipsoidal magnets in flowing channels of rectangular or circular cross section at low Reynolds number.A static uniform magnetic field is used to pin the particle orientation, and the particles move with translational drift velocities resulting from hydrodynamic interactions with the channel walls which can be described using Blake's image tensor.Building on his insights, we are able to present a far-field theory predicting the particle motion in rectangular channels, and validate the accuracy of the theory by comparing to numerical solutions using the boundary element method.We find that, by changing the direction of the applied magnetic field, the motion can be controlled so that particles move either to a curved focusing region or to the channel walls.We also use simulations to show that the particles are focused to a single line in a circular channel.Our results suggest ways to focus and segregate magnetic particles in lab-on-a-chip devices.",cond-mat.soft physics.flu-dyn
"We report a method to control the positions of ellipsoidal magnets in flowing channels of rectangular or circular cross section at low Reynolds number.A static uniform magnetic field is used to pin the speck orientation, and the particles move with translational drift velocities resulting from hydrodynamic interactions with the channel walls which can be described using Blake's image tensor.Building on his insights, we are able to present tense a far-field theory predicting the speck motion in rectangular channels, and validate the accuracy of the theory by comparing to numerical solutions using the boundary element method.We find that, by changing the direction of the applied magnetic field, the motion can be controlled so that particles move either to a curved focusing region or to the channel walls.We also use simulations to show that the particles are focused to a single line in a circular channel.Our results suggest ways to focus and segregate magnetic particles in lab-on-a-chip devices.",cond-mat.soft physics.flu-dyn
"Facilitated spin models were introduced some decades ago to mimic systems characterized by a glass transition. Recent developments have shown that a class of facilitated spin models is also able to reproduce characteristic signatures of the structural relaxation properties of glass-forming liquids. While the equilibrium phase diagram of these models can be calculated analytically, the dynamics are usually investigated numerically. Here we propose a new network-based approach, called approximate master equation (AME), to the dynamics of the Fredrickson-Andersen model. The approach correctly predicts the critical temperature at which the glass transition occurs. We also find excellent agreement between the theory and the numerical simulations for the transient regime, except in close proximity of the liquid-glass transition. Finally, we analytically characterize the critical clusters of the model and show that the departures between our AME approach and the Monte Carlo can be related to the large interface between frozen and unfrozen spins at temperatures close to the glass transition.",cond-mat.dis-nn math.DS
"Facilitated spin models were acquaint some decades ago to mimic systems characterized by a glass transition. Recent developments have shown that a class of facilitated spin models is also able to reproduce characteristic signatures of the structural relaxation properties of glass-forming liquids. While the equilibrium phase diagram of these models can be bet analytically, the dynamics are usually investigated numerically. Here we propose a new network-based approach, called approximate master equation (AME), to the dynamics of the Fredrickson-Andersen model. The approach correctly predicts the critical temperature at which the glass transition occurs. We also find excellent agreement between the theory and the numerical simulations for the transient regime, except in close proximity of the liquid-glass transition. Finally, we analytically characterize the critical clusters of the model and show that the departures between our AME approach and the Monte Carlo can be related to the large interface between frozen and unfrozen spins at temperatures close to the glass transition.",cond-mat.dis-nn math.DS
"Atmospheric water vapour is an essential ingredient of weather and climate. Key features of its distribution can be represented by kinematic models which treat it as a passive scalar advected by a prescribed flow and reacting through condensation. Condensation acts as a sink that maintains specific humidity below a prescribed, space-dependent saturation value. In order to investigate how the interplay between large-scale advection, small-scale turbulence and condensation controls the moisture distribution, we develop simple kinematic models which combine a single circulating flow with a Brownian-motion representation of turbulence. We first study the drying mechanism of a water-vapour anomaly released inside a vortex at an initial time. Next, we consider a cellular flow with a moisture source at a boundary. The statistically steady state attained shows features reminiscent of the Hadley cell such as boundary layers, a region of intense precipitation and a relative humidity minimum. Explicit results provide a detailed characterisation of these features in the limit of strong flow.",physics.ao-ph physics.flu-dyn
"Atmospheric water vapour is an essential ingredient of weather and climate. Key features of its distribution can be represented by kinematic models which treat it as a passive scalar advected by a prescribed flow and reacting through condensation. Condensation acts as a sink that maintains specific humidity below a prescribed, space-dependent saturation value. In order to investigate how the interplay between large-scale advection, small-scale turbulence and condensation controls the moisture distribution, we develop simple kinematic models which combine a single disperse flow with a Brownian-motion representation of turbulence. We first study the drying mechanism of a water-vapour anomaly released inside a vortex at an initial time. Next, we consider a cellular flow with a moisture source at a boundary. The statistically steady state attained shows features reminiscent of the Hadley cell such as boundary layers, a region of intense precipitation and a relative humidity minimum. denotative results provide a detailed characterisation of these features in the limit of strong flow.",physics.ao-ph physics.flu-dyn
"Articulated hand pose estimation is a challenging task for human-computer interaction. The state-of-the-art hand pose estimation algorithms work only with one or a few subjects for which they have been calibrated or trained. Particularly, the hybrid methods based on learning followed by model fitting or model based deep learning do not explicitly consider varying hand shapes and sizes. In this work, we introduce a novel hybrid algorithm for estimating the 3D hand pose as well as bone-lengths of the hand skeleton at the same time, from a single depth image. The proposed CNN architecture learns hand pose parameters and scale parameters associated with the bone-lengths simultaneously. Subsequently, a new hybrid forward kinematics layer employs both parameters to estimate 3D joint positions of the hand. For end-to-end training, we combine three public datasets NYU, ICVL and MSRA-2015 in one unified format to achieve large variation in hand shapes and sizes. Among hybrid methods, our method shows improved accuracy over the state-of-the-art on the combined dataset and the ICVL dataset that contain multiple subjects. Also, our algorithm is demonstrated to work well with unseen images.",cs.CV cs.HC
"Articulated hand pose estimation is a challenging task for human-computer interaction. The state-of-the-art hand pose estimation algorithms work only with one or a few subjects for which they have been calibrated or trained. Particularly, the hybrid methods based on learning followed by model fitting or model based deep learning do not explicitly consider varying hand shapes and sizes. In this work, we introduce a novel hybrid algorithm for estimating the 3D hand pose as well as bone-lengths of the hand skeleton at the same time, from a single depth image. The proposed CNN architecture learns hand pose parameters and scale parameters associated with the bone-lengths simultaneously. Subsequently, a new hybrid forward kinematics layer employs both parameters to estimate 3D joint positions of the hand. For end-to-end training, we combine three world datasets NYU, ICVL and MSRA-2015 in one unified format to achieve with child variation in hand shapes and sizes. Among hybrid methods, our method shows improved accuracy over the state-of-the-art on the combined dataset and the ICVL dataset that contain multiple subjects. Also, our algorithm is demonstrated to work well with unseen images.",cs.CV cs.HC
"Einstein-dilaton-Gauss-Bonnet gravity is a well-motivated alternative theory of gravity that emerges naturally from string theory. While black hole solutions have been known in this theory in numerical form for a while, an approximate analytical metric was obtained recently by some of us, which allows for faster and more detailed analysis. Here we test the accuracy of the analytical metric in the context of X-ray reflection spectroscopy. We analyze innermost stable circular orbits (ISCO) and relativistically broadened iron lines and find that both the ISCO and iron lines are determined sufficiently accurately up to the limit of the approximation. We also find that, though the ISCO increases by about 7% as dilaton coupling increases from zero to extremal values, the redshift at ISCO changes by less than 1%. Consequently, the shape of the iron line is much less sensitive to the dilaton charge than expected.",astro-ph.HE gr-qc
"Einstein-dilaton-Gauss-Bonnet gravity is a well-motivated choice theory of gravity that emerges naturally from string theory. While black hole solutions have been known in this theory in numerical form for a while, an approximate analytical metric was obtained recently by some of us, which allows for faster and more detailed analysis. Here we test the accuracy of the analytical metric in the context of X-ray reflection spectroscopy. We analyze innermost stable circular orbits (ISCO) and relativistically broadened iron lines and find that both the ISCO and iron lines are determined sufficiently accurately up to the limit of the approximation. We also find that, though the ISCO increases by about 7% as dilaton coupling increases from zero to extremal values, the redshift at ISCO changes by less than 1%. Consequently, the shape of the iron line is much less medium to the dilaton charge than expected.",astro-ph.HE gr-qc
"To build a secure communications software, Vulnerability Prediction Models (VPMs) are used to predict vulnerable software modules in the software system before software security testing. At present many software security metrics have been proposed to design a VPM. In this paper, we predict vulnerable classes in a software system by establishing the system's weighted software network. The metrics are obtained from the nodes' attributes in the weighted software network. We design and implement a crawler tool to collect all public security vulnerabilities in Mozilla Firefox. Based on these data, the prediction model is trained and tested. The results show that the VPM based on weighted software network has a good performance in accuracy, precision, and recall. Compared to other studies, it shows that the performance of prediction has been improved greatly in Pr and Re.",cs.SE
"To build a secure communications software, Vulnerability Prediction Models (VPMs) are used to predict vulnerable software modules in the software system earlier software security testing. At present many software security metrics have been proposed to design a VPM. In this paper, we predict vulnerable classes in a software system by establishing the system's weighted software network. The metrics are obtained from the nodes' attributes in the weighted software network. We design and implement a crawler tool to collect all public security vulnerabilities in Mozilla Firefox. Based on these data, the prediction model is trained and tested. The results show that the VPM based on weighted software network has a good performance in accuracy, precision, and recall. Compared to other studies, it demo that the performance of prediction has been improved greatly in Pr and Re.",cs.SE
"We prove the density of polyhedral partitions in the set of finite Caccioppoli partitions. Precisely, we consider a decomposition $u$ of a bounded Lipschitz set $\Omega\subset\mathbb R^n$ into finitely many subsets of finite perimeter, which can be identified with a function in $SBV_{\rm loc}(\Omega;{\cal Z})$ with ${\cal Z}\subset \mathbb R^N$ a finite set of parameters. For all $\varepsilon>0$ we prove that such a $u$ is $\varepsilon$-close to a small deformation of a polyhedral decomposition $v_\varepsilon$, in the sense that there is a $C^1$ diffeomorphism $f_\varepsilon:\mathbb R^n\to\mathbb R^n$ which is $\varepsilon$-close to the identity and such that $u\circ f_\varepsilon-v_\varepsilon$ is $\varepsilon$-small in the strong $BV$ norm. This implies that the energy of $u$ is close to that of $v_\varepsilon$ for a large class of energies defined on partitions. Such type of approximations are very useful in order to simplify computations in the estimates of $\Gamma$-limits.",math.AP
"We prove the density of polyhedral partitions in the set of finite Caccioppoli partitions. Precisely, we consider a decomposition $u$ of a bounded Lipschitz set $\Omega\subset\mathbb R^n$ into finitely many subsets of finite perimeter, which can be identified with a function in $SBV_{\rm loc}(\Omega;{\cal Z})$ with ${\cal Z}\subset \mathbb R^N$ a finite set of parameters. For all $\varepsilon>0$ we prove that such a $u$ is $\varepsilon$-close to a small deformation of a polyhedral decomposition $v_\varepsilon$, in the gumption that there is a $C^1$ diffeomorphism $f_\varepsilon:\mathbb R^n\to\mathbb R^n$ which is $\varepsilon$-close to the identity and such that $u\circ f_\varepsilon-v_\varepsilon$ is $\varepsilon$-small in the strong $BV$ norm. This implies that the energy of $u$ is skinny to that of $v_\varepsilon$ for a large class of energies defined on partitions. Such type of approximations are very useful in order to simplify computations in the estimates of $\Gamma$-limits.",math.AP
"The spin rotations and lattice rotations are locked in the Shubnikov magnetic space groups in describing magnetically ordered materials. However, real materials may contain symmetry elements whose spin and lattice operations are partially unlocked. These groups are called spin space groups and may give rise to new band structures for itinerant electrons. In the present work, we focus on potential magnetic materials in which the intrinsic electronic spin-orbit coupling is negligible. We theoretically predict many new fermionic quasiparticles at the high symmetry points (HSPs) or high symmetry lines (HSLs) in the Brillouin zone (BZ), which can neither be realized in non-magnetic systems nor in magnetic ones with Shubnikov magnetic space group symmetries. These new quasiparticles are characterized by the symmetry invariants of the little co-group, which are more essential than the representations (Reps) themselves. We also provide the dispersion around the high-symmetry points/lines, and predict a large class of nodal-point or nodal-line semimetals.",cond-mat.mes-hall cond-mat.str-el
"The spin rotations and lattice rotations are locked in the Shubnikov magnetic space groups in delineate magnetically ordered materials. However, real materials may contain symmetry elements whose spin and lattice operations are partially unlocked. These groups are called spin space groups and may give rise to new band structures for itinerant electrons. In the present work, we focus on potential magnetic materials in which the intrinsic electronic spin-orbit coupling is negligible. We theoretically predict many new fermionic quasiparticles at the high symmetry points (HSPs) or high symmetry lines (HSLs) in the Brillouin zone (BZ), which can neither be realized in non-magnetic systems nor in magnetic ones with Shubnikov magnetic space group symmetries. These new quasiparticles are characterized by the symmetry invariants of the little co-group, which are to a greater extent essential than the representations (Reps) themselves. We also provide the dispersion around the high-symmetry points/lines, and predict a large class of nodal-point or nodal-line semimetals.",cond-mat.mes-hall cond-mat.str-el
"We prove the determinant connectivity matrix formula. Mathematically, the proof introduces novel techniques based on an algebraic approach and connectivity properties. Although this is the second part of a previous paper and has its original motivation there, the paper is self contained and the result is interesting in itself.",math.RA
"We prove the determinant connectivity matrix formula. Mathematically, the proof introduces novel techniques based on an algebraic approach and connectivity properties. Although this is the second part of a late paper and has its original motivation there, the paper is ego contained and the result is interesting in itself.",math.RA
"(Abridged) We demonstrate that the tenet of hierarchical structure growth leads directly to a robust, falsifiable prediction for the correlation between stellar fraction (fstar) and total system mass (M500) of galaxy groups and clusters. This prediction is relatively insensitive to the details of baryonic physics or cosmological parameters. In particular, if the fstar-M500 relation is fixed and does not evolve with redshift, CDM models predict the logarithmic slope of this relation to be b>-0.3. This constraint can be weakened if the fstar-M500 relation evolves strongly, but this implies more stars must be formed in situ in groups at low redshift. Conservatively requiring that at least half the stars in groups were formed by z=1, the constraint from evolution models is b>-0.35. Since the most massive clusters (M500=1E15 Msun) are observed to have fstar=0.01, this means that groups with M500=5E13 Msun must have fstar<0.03. Recent observations by Gonzalez et al. (2007) indicate a much steeper relation, with fstar>0.04 in groups, leading to b=-0.64. If confirmed, this would rule out hierarchical structure formation models: today's clusters could not have been built from today's groups, or even from the higher-redshift progenitors of those groups. We perform a careful analysis of these and other data to identify the most important systematic uncertainties in their measurements. Although correlated uncertainties on stellar and total masses might explain the steep observed relation, the data are only consistent with theory if the observed group masses are systematically underestimated.",astro-ph
"(Abridged) We demonstrate that the tenet of hierarchical structure growth leads directly to a robust, falsifiable prediction for the correlation between stellar fraction (fstar) and total system mass (M500) of galaxy groups and clusters. This prediction is relatively insensitive to the details of baryonic physics or cosmological parameters. In particular, if the fstar-M500 relation is fixed and does not evolve with redshift, CDM models predict the logarithmic slope of this relation to be b>-0.3. This constraint can be weakened if the fstar-M500 relation evolves strongly, but this implies more stars must be formed in situ in groups at low redshift. Conservatively requiring that at to the lowest degree half the stars in groups were formed by z=1, the constraint from evolution models is b>-0.35. Since the most massive clusters (M500=1E15 Msun) are observed to have fstar=0.01, this means that groups with M500=5E13 Msun must have fstar<0.03. Recent observations by Gonzalez et al. (2007) indicate a much steeper relation, with fstar>0.04 in groups, conduct to b=-0.64. If confirmed, this would rule out hierarchical structure formation models: today's clusters could not have been built from today's groups, or even from the higher-redshift progenitors of those groups. We perform a careful analysis of these and other data to identify the most important systematic uncertainties in their measurements. Although correlated uncertainties on stellar and total masses might explain the steep observed relation, the data are only consistent with theory if the observed group masses are systematically underestimated.",astro-ph
"Host-side page victimizations can easily overflow the SSD internal buffer, which interferes I/O services of diverse user applications thereby degrading user-level experiences. To address this, we propose FastDrain, a co-design of OS kernel and flash firmware to avoid the buffer overflow, caused by page victimizations. Specifically, FastDrain can detect a triggering point where a near-future page victimization introduces an overflow of the SSD internal buffer. Our new flash firmware then speculatively scrubs the buffer space to accommodate the requests caused by the page victimization. In parallel, our new OS kernel design controls the traffic of page victimizations by considering the target device buffer status, which can further reduce the risk of buffer overflow. To secure more buffer spaces, we also design a latency-aware FTL, which dumps the dirty data only to the fast flash pages. Our evaluation results reveal that FastDrain reduces the 99th response time of user applications by 84%, compared to a conventional system.",cs.OS
"Host-side page victimizations can easily overflow the SSD internal buffer, which interferes I/O services of diverse user applications thereby degrading user-level experiences. To address this, we propose FastDrain, a co-design of OS kernel and flash firmware to avoid the buffer overflow, caused by page victimizations. Specifically, FastDrain can detect a triggering point where a near-future page victimization introduces an overflow of the SSD internal buffer. Our new flash firmware then speculatively scrubs the buffer space to accommodate the requests caused by the page victimization. In parallel, our new OS kernel design assure the traffic of page victimizations by considering the target device buffer status, which can further reduce the risk of buffer overflow. To secure more buffer spaces, we also design a latency-aware FTL, which dumps the dirty data only to the fast flash pages. Our evaluation results reveal that FastDrain reduces the 99th response time of user applications by 84%, compare to a conventional system.",cs.OS
"The distribution of RR Lyrae stars (RRLS) in the inner Large Magellanic Cloud (LMC), and the structure of the halo of the LMC delineated by these stars are studied here. RRLS identified by the OGLE II survey are used to estimate their number density distribution in the bar region of the LMC. To find their location, I estimated the scale-height of their distribution in the LMC using extinction corrected average magnitudes of ab type stars. The density is found to vary differently along and across the bar of the LMC, and the difference is found to be statistically significant. The density distribution is found to be elongated like the LMC bar and the position angle (PA) of the elongation is estimated to be 112.$^o$5 $\pm$ 15.$^o$3. This value of PA is found to be same as the PA$_{maj}$ of the bar, within the errors, estimated using red clump stars and giants. The ellipticity of their density distribution is estimated to be $\sim$ 0.5, very similar to the ellipticity of the bar, estimated from giants. The above results show that majority of the population of RRLS in the central region of the LMC are found to have the signature of the bar. This result could mean that most of these stars are located in the disk, considering the bar as a disk feature. On the other hand, their scale-height was found to be 3.0$\pm 0.9$ kpc. This indicates that RRLS are located in the halo and not in the disk. Thus these stars in the inner LMC have halo-like location and a disk-like density distribution. I discuss some possible formation scenarios for this puzzling combination.",astro-ph
"The distribution of RR Lyrae stars (RRLS) in the inner Large Magellanic Cloud (LMC), and the structure of the halo of the LMC delineated by these stars are studied here. RRLS identified by the OGLE II survey are used to estimate their number density distribution in the bar part of the LMC. To find their location, I estimated the scale-height of their distribution in the LMC using extinction corrected average magnitudes of ab type stars. The density is found to vary differently along and across the bar of the LMC, and the difference is found to be statistically significant. The density distribution is found to be elongated like the LMC bar and the position angle (PA) of the elongation is estimated to be 112.$^o$5 $\pm$ 15.$^o$3. This value of PA is found to be same as the PA$_{maj}$ of the bar, within the errors, estimated using red clump stars and giants. The ellipticity of their density distribution is estimated to be $\sim$ 0.5, very similar to the ellipticity of the bar, estimated from giants. The above results show that majority of the population of RRLS in the central part of the LMC are found to have the signature of the bar. This result could mean that most of these stars are located in the disk, considering the bar as a disk feature. On the other hand, their scale-height was found to be 3.0$\pm 0.9$ kpc. This indicates that RRLS are located in the halo and not in the disk. Thus these stars in the inner LMC have halo-like location and a disk-like density distribution. I discuss some potential formation scenarios for this puzzling combination.",astro-ph
"A major challenge in sparsity pattern estimation is that small modes are difficult to detect in the presence of noise. This problem is alleviated if one can observe samples from multiple realizations of the nonzero values for the same sparsity pattern. We will refer to this as ""diversity"". Diversity comes at a price, however, since each new realization adds new unknown nonzero values, thus increasing uncertainty. In this paper, upper and lower bounds on joint sparsity pattern estimation are derived. These bounds, which improve upon existing results even in the absence of diversity, illustrate key tradeoffs between the number of measurements, the accuracy of estimation, and the diversity. It is shown, for instance, that diversity introduces a tradeoff between the uncertainty in the noise and the uncertainty in the nonzero values. Moreover, it is shown that the optimal amount of diversity significantly improves the behavior of the estimation problem for both optimal and computationally efficient estimators.",cs.IT math.IT
"A major challenge in sparsity pattern estimation is that modest modes are difficult to detect in the presence of noise. This problem is alleviated if one can observe samples from multiple realizations of the nonzero values for the same sparsity pattern. We will refer to this as ""diversity"". Diversity comes at a price, however, since each new realization adds new unknown nonzero values, thus increasing uncertainty. In this paper, upper and lower bounds on joint sparsity pattern estimation are derived. These bounds, which improve upon existing results even in the absence of diversity, illustrate key tradeoffs between the number of measurements, the accuracy of estimation, and the diversity. It is shown, for instance, that diversity introduces a tradeoff between the uncertainty in the noise and the uncertainty in the nonzero values. Moreover, it is testify that the optimal amount of diversity significantly improves the behavior of the estimation problem for both optimal and computationally efficient estimators.",cs.IT math.IT
"IceCube has observed neutrinos above 100 TeV at a level significantly above the steeply falling background of atmospheric neutrinos. The astrophysical signal is seen both in the high-energy starting event analysis from the whole sky and as a high-energy excess in the signal of neutrino-induced muons from below. No individual neutrino source, either steady or transient, has yet been identified. Several follow-up efforts are currently in place in an effort to find coincidences with sources observed by optical, X-ray and gamma-ray detectors. This paper, presented at the inauguration of HAWC, reviews the main results of IceCube and describes the status of plans to move to near-real time publication of high-energy events by IceCube.",astro-ph.HE
"IceCube has observed neutrinos above 100 TeV at a even significantly above the steeply falling background of atmospheric neutrinos. The astrophysical signal is seen both in the high-energy starting event analysis from the whole sky and as a high-energy excess in the signal of neutrino-induced muons from below. No individual neutrino source, either steady or transient, has yet been identified. Several follow-up efforts are currently in place in an effort to find coincidences with sources observed by optical, X-ray and gamma-ray detectors. This paper, presented at the inauguration of HAWC, reviews the main results of IceCube and describes the status of program to move to near-real time publication of high-energy events by IceCube.",astro-ph.HE
"When selling information products, the seller can provide some free partial information to change people's valuations so that the overall revenue can possibly be increased. We study the general problem of advertising information products by revealing partial information. We consider buyers who are decision-makers. The outcomes of the decision problems depend on the state of the world that is unknown to the buyers. The buyers can make their own observations and thus can hold different personal beliefs about the state of the world. There is an information seller who has access to the state of the world. The seller can promote the information by revealing some partial information. We assume that the seller chooses a long-term advertising strategy and then commits to it. The seller's goal is to maximize the expected revenue. We study the problem in two settings. (1) The seller targets buyers of a certain type. In this case, finding the optimal advertising strategy is equivalent to finding the concave closure of a simple function. The function is a product of two quantities, the likelihood ratio and the cost of uncertainty. Based on this observation, we prove some properties of the optimal mechanism, which allow us to solve for the optimal mechanism by a finite-size convex program. The convex program will have a polynomial-size if the state of the world has a constant number of possible realizations or the buyers face a decision problem with a constant number of options. For the general problem, we prove that it is NP-hard to find the optimal mechanism. (2) When the seller faces buyers of different types and only knows the distribution of their types, we provide an approximation algorithm when it is not too hard to predict the possible type of buyers who will make the purchase. For the general problem, we prove that it is NP-hard to find a constant-factor approximation.",cs.GT econ.TH
"When selling information products, the seller can provide some free partial information to change people's valuations so that the overall revenue can possibly be increased. We study the general problem of advertising information products by revealing partial information. We consider buyer who are decision-makers. The outcomes of the decision problems depend on the state of the world that is unknown to the buyers. The buyer can make their own observations and thus can hold different personal beliefs about the state of the world. There is an information seller who has access to the state of the world. The seller can promote the information by revealing some partial information. We assume that the seller chooses a long-term advertising strategy and then commits to it. The seller's goal is to maximize the expected revenue. We study the problem in two settings. (1) The seller targets buyer of a certain type. In this case, finding the optimal advertising strategy is equivalent to finding the concave closure of a simple function. The function is a product of two quantities, the likeliness ratio and the cost of uncertainty. Based on this observation, we prove some properties of the optimal mechanism, which allow us to solve for the optimal mechanism by a finite-size convex program. The convex program will have a polynomial-size if the state of the world has a constant number of possible realizations or the buyer face a decision problem with a constant number of options. For the general problem, we prove that it is NP-hard to find the optimal mechanism. (2) When the seller faces buyer of different types and only knows the distribution of their types, we provide an approximation algorithm when it is not too hard to predict the possible type of buyer who will make the purchase. For the general problem, we prove that it is NP-hard to find a constant-factor approximation.",cs.GT econ.TH
"We solve the problem of effectively computing the $a$-invariant of ladder determinantal rings. In the case of a one-sided ladder, we provide a compact formula, while, for a large family of two-sided ladders, we provide an algorithmic solution.",math.AC math.CO
"We solve the problem of effectively computing the $a$-invariant of run determinantal rings. In the case of a one-sided ladder, we provide a squeeze formula, while, for a large family of two-sided ladders, we provide an algorithmic solution.",math.AC math.CO
"We develop a human-centred, cognitive model of visuospatial complexity in everyday, naturalistic driving conditions. With a focus on visual perception, the model incorporates quantitative, structural, and dynamic attributes identifiable in the chosen context; the human-centred basis of the model lies in its behavioural evaluation with human subjects with respect to psychophysical measures pertaining to embodied visuoauditory attention. We report preliminary steps to apply the developed cognitive model of visuospatial complexity for human-factors guided dataset creation and benchmarking, and for its use as a semantic template for the (explainable) computational analysis of visuospatial complexity.",cs.AI cs.CV cs.HC
"We develop a human-centred, cognitive model of visuospatial complexity in everyday, naturalistic driving conditions. With a focus on visual perception, the model incorporates quantitative, structural, and dynamic attributes identifiable in the chosen context; the human-centred groundwork of the model lies in its behavioural evaluation with human subjects with respect to psychophysical measures pertaining to embodied visuoauditory attention. We composition preliminary steps to apply the developed cognitive model of visuospatial complexity for human-factors guided dataset creation and benchmarking, and for its use as a semantic template for the (explainable) computational analysis of visuospatial complexity.",cs.AI cs.CV cs.HC
"In this paper, we proved a compactness result about Riemannian manifolds with an arbitrary pointwisely pinched Ricci curvature tensor.",math.DG
"In this paper, we demonstrate a compactness result almost Riemannian manifolds with an arbitrary pointwisely pinched Ricci curvature tensor.",math.DG
"The semidirect product of a Lie algebra and a 2-term representation up to homotopy is a Lie 2-algebra. Such Lie 2-algebras include many examples arising from the Courant algebroid appearing in generalized complex geometry. In this paper, we integrate such a Lie 2-algebra to a strict Lie 2-group in the finite dimensional case.",math-ph math.DG math.GR math.MP
"The semidirect product of a Lie algebra and a 2-term representation up to homotopy is a Lie 2-algebra. Such Lie 2-algebras let in many examples arising from the Courant algebroid appearing in generalized complex geometry. In this paper, we incorporate such a Lie 2-algebra to a strict Lie 2-group in the finite dimensional case.",math-ph math.DG math.GR math.MP
"We consider the out-of-equilibrium behavior of a general class of mesoscopic devices composed of several superconducting or/and normal metal leads separated by quantum dots. Starting from a microscopic Hamiltonian description, we provide a non-perturbative approach to quantum electronic transport in the tunneling amplitudes between dots and leads: using the equivalent of a path integral formulation, the lead degrees of freedom are integrated out in order to compute both the current and the current correlations (noise) in this class of systems, in terms of the dressed Green's function matrix of the quantum dots. In order to illustrate the efficiency of this formalism, we apply our results to the ""all superconducting Cooper pair beam splitter"", a device composed of three superconducting leads connected via two quantum dots, where crossed Andreev reflection operates Cooper pair splitting. Commensurate voltage differences between the three leads allow to obtain expressions for the current and noise as a function of the Keldysh Nambu Floquet dressed Green's function of the dot system. This voltage configuration allows the occurrence of non-local processes involving multiple Cooper pairs which ultimately lead to the presence of non-zero DC currents in an out-of-equilibrium situation. We investigate in details the results for the noise obtained numerically in the specific case of opposite voltages, where the transport properties are dominated by the so called ""quartet processes"", involving the coherent exchange of two Cooper pairs among all three superconducting terminals. We show that these processes are noiseless in the non-resonant case, and that this property is also observed for other voltage configurations. When the dots are in a resonant regime, the noise characteristics change qualitatively, with the appearance of giant Fano factors.",cond-mat.supr-con
"We consider the out-of-equilibrium behavior of a general course of instruction of mesoscopic devices composed of several superconducting or/and normal metal leads separated by quantum dots. Starting from a microscopic Hamiltonian description, we provide a non-perturbative approach to quantum electronic transport in the tunneling amplitudes between dots and leads: using the equivalent of a path integral formulation, the lead degrees of freedom are integrated out in order to compute both the current and the current correlations (noise) in this course of instruction of systems, in terms of the dressed Green's function matrix of the quantum dots. In order to illustrate the efficiency of this formalism, we apply our results to the ""all superconducting Cooper pair beam splitter"", a device composed of three superconducting leads connected via two quantum dots, where crossed Andreev reflection operates Cooper pair splitting. Commensurate voltage differences between the three leads allow to obtain expressions for the current and noise as a function of the Keldysh Nambu Floquet dressed Green's function of the dot system. This voltage configuration allows the occurrence of non-local processes involving multiple Cooper pairs which ultimately lead to the presence of non-zero DC flow in an out-of-equilibrium situation. We investigate in details the results for the noise obtained numerically in the specific case of opposite voltages, where the transport properties are dominated by the so called ""quartet processes"", involving the coherent exchange of two Cooper pairs among all three superconducting terminals. We show that these processes are noiseless in the non-resonant case, and that this property is also observed for other voltage configurations. When the dots are in a resonant regime, the noise characteristics change qualitatively, with the appearance of giant Fano factors.",cond-mat.supr-con
At the end of 1960-ths Yu.S.Ilyashenko stated the problem: is it true that for any one-dimensional holomorphic foliation with singularities on a Stein manifold leaves intersecting a transversal disc can be uniformized so that the uniformization function would depend holomorphically on the transversal parameter? In the present paper we construct a two-dimensional counterexample. This together with the previous result of Yu.S.Ilyashenko (Lemma 1) implies existence of a counterexample given by a foliation on affine (projective) algebraic surface by level curves of a rational function with singularities deleted. This implies also that Bers' simultaneous uniformization theorem for topologically trivial holomorphic foliations by compact Riemann surfaces does not extend to the general fibrations by compact Riemann surfaces with singularities.,math.CV math.DS
At the end of 1960-ths Yu.S.Ilyashenko stated the problem: is it true that for any one-dimensional holomorphic foliation with singularities on a Stein manifold leaves intersect a transversal disc can be uniformized so that the uniformization function would depend holomorphically on the transversal parameter? In the present paper we construct a two-dimensional counterexample. This together with the previous result of Yu.S.Ilyashenko (Lemma 1) implies existence of a counterexample given by a foliation on affine (projective) algebraic surface by level curves of a rational function with singularities deleted. This implies also that Bers' cooccurring uniformization theorem for topologically trivial holomorphic foliations by compact Riemann surfaces does not extend to the general fibrations by compact Riemann surfaces with singularities.,math.CV math.DS
"We prove a variant of the standard Whitney extension theorem for $\mathcal C^m(\mathbb R^n)$, in which the norm of the extension operator has polynomial growth in $n$ for fixed $m$.",math.CA
"We prove a version of the standard Whitney extension theorem for $\mathcal C^m(\mathbb R^n)$, in which the norm of the extension operator has polynomial development in $n$ for fixed $m$.",math.CA
"The total cross sections of the radiative proton capture on 8Li at astrophysical energies were considered in the framework of the modified potential cluster model with forbidden states, with the classification of the orbital cluster states according to Young diagrams. The recalculation of total cross sections for the 9Be({\gamma},p0)8Li photodisintegration was used as experimental data. In whole, it is possible to obtain the available data on cross sections at energies to 7.0 MeV. Astrophysical S-factors and reaction rates at the temperature range of 0.01 to 10 T9 were calculated. It was shown that the resonances in the p8Li scattering channel considerably influence to the reaction rate and, in the first place, the first - at 87 keV. The analytical parametrization was obtained for calculated reaction rate.",nucl-th
"The total queer sections of the radiative proton capture on 8Li at astrophysical energies were considered in the framework of the modified potential cluster model with forbidden states, with the classification of the orbital cluster states according to Young diagrams. The recalculation of total queer sections for the 9Be({\gamma},p0)8Li photodisintegration was used as experimental data. In whole, it is possible to obtain the available data on queer sections at energies to 7.0 MeV. Astrophysical S-factors and reaction rates at the temperature range of 0.01 to 10 T9 were calculated. It was shown that the resonances in the p8Li scattering channel considerably influence to the reaction rate and, in the first place, the first - at 87 keV. The analytic parametrization was obtained for calculated reaction rate.",nucl-th
"In TEM, a typical goal consists of making a small electron probe in the sample plane in order to obtain high spatial resolution in scanning transmission electron microscopy. In order to do so, the phase of the electron wave is corrected to resemble a spherical wave compensating for aberrations in the magnetic lenses. In this contribution we discuss the advantage of changing the phase of an electron wave in a specific way in order to obtain fundamentally different electron probes opening up new application in the (S)TEM. We focus on electron vortex states as a specific family of waves with an azimuthal phase signature and discuss their properties, production and applications. The concepts presented here are rather general and also different classes of probes can be obtained in a similar fashion showing that electron probes can be tuned to optimise a specific measurement or interaction.",cond-mat.mtrl-sci physics.optics
"In TEM, a typical goal consists of making a small electron probe in the sample plane in order to obtain high spatial resolution in scanning transmission electron microscopy. In order to do so, the phase of the electron wave is corrected to resemble a spherical wave compensating for aberrations in the magnetic lenses. In this contribution we discuss the advantage of changing the phase of an electron wave in a particular way in order to obtain fundamentally different electron probes opening up new application in the (S)TEM. We focus on electron vortex states as a particular family of waves with an azimuthal phase signature and discuss their properties, product and applications. The concepts presented here are rather general and also different classes of probes can be obtained in a similar fashion showing that electron probes can be tuned to optimise a particular measurement or interaction.",cond-mat.mtrl-sci physics.optics
"Single-cycle optical pulses with a controlled electromagnetic waveform allow to steer the motion of low-energy electrons in atoms, molecules, nanostructures or condensed-matter on attosecond dimensions in time. However, high-energy electrons under single-cycle light control would be an enabling technology for beam-based attosecond physics with free-electron lasers or electron microscopy. Here we report the control of freely propagating keV electrons with an isolated optical cycle of mid-infrared light and create a modulated electron current with a peak-cycle-specific sub-femtosecond structure in time. The evident effects of the carrier-envelope phase, amplitude and dispersion of the optical waveform on the temporal composition, pulse durations and chirp of the free-space electron wavefunction demonstrate the sub-cycle nature of our control. These results create novel opportunities in laser-driven particle acceleration, seeded free-electron lasers, attosecond space-time imaging, electron quantum optics and wherever else high-energy electrons are needed with the temporal structure of single-cycle light.",physics.acc-ph physics.atom-ph physics.optics
"Single-cycle optical pulses with a controlled electromagnetic waveform allow to steer the motion of low-energy electrons in atoms, molecules, nanostructures or condensed-matter on attosecond property in time. However, high-energy electrons under single-cycle light control would be an enabling technology for beam-based attosecond physics with free-electron lasers or electron microscopy. Here we report the control of freely propagating keV electrons with an separated optical cycle of mid-infrared light and create a modulated electron current with a peak-cycle-specific sub-femtosecond structure in time. The evident effects of the carrier-envelope phase, amplitude and dispersion of the optical waveform on the temporal composition, pulse durations and chirp of the free-space electron wavefunction demonstrate the sub-cycle nature of our control. These results create novel opportunities in laser-driven particle acceleration, seeded free-electron lasers, attosecond space-time imaging, electron quantum optics and wherever else high-energy electrons are needed with the temporal structure of single-cycle light.",physics.acc-ph physics.atom-ph physics.optics
"In this paper, we obtained an equivalent proposition of Brennan`s conjecture. And given two lower bound estimation of the conjecture one of them connected with Schwarzian derivative. The present study also verified the correctness of the conjecture in some special conditions.",math.CV
"In this paper, we obtained an equivalent proposition of Brennan`s conjecture. And given two lower bound approximation of the conjecture one of them connected with Schwarzian derivative. The present study also aver the correctness of the conjecture in some special conditions.",math.CV
"Energy-transport equations for the transport of fermions in optical lattices are formally derived from a Boltzmann transport equation with a periodic lattice potential in the diffusive limit. The limit model possesses a formal gradient-flow structure like in the case of the energy-transport equations for semiconductors. At the zeroth-order high temperature limit, the energy-transport equations reduce to the whole-space logarithmic diffusion equation which has some unphysical properties. Therefore, the first-order expansion is derived and analyzed. The existence of weak solutions to the time-discretized system for the particle and energy densities with periodic boundary conditions is proved. The difficulties are the nonstandard degeneracy and the quadratic gradient term. The main tool of the proof is a result on the strong convergence of the gradients of the approximate solutions. Numerical simulations in one space dimension show that the particle density converges to a constant steady state if the initial energy density is sufficiently large, otherwise the particle density converges to a nonconstant steady state.",math.AP
"Energy-transport equations for the transport of fermions in optical lattices are formally derived from a Boltzmann transport equation with a periodic lattice potential drop in the diffusive limit. The limit model possesses a formal gradient-flow structure like in the case of the energy-transport equations for semiconductors. At the zeroth-order high temperature limit, the energy-transport equations reduce to the whole-space logarithmic diffusion equation which has some unphysical properties. Therefore, the first-order expansion is derived and analyzed. The existence of light solutions to the time-discretized system for the particle and energy densities with periodic boundary conditions is proved. The difficulties are the nonstandard degeneracy and the quadratic gradient term. The main tool of the proof is a result on the strong convergence of the gradients of the approximate solutions. Numerical simulations in one space dimension show that the particle density converges to a constant steady state if the initial energy density is sufficiently large, otherwise the particle density converges to a nonconstant steady state.",math.AP
"Despite several different measures of efficiency that are applicable to the photosynthetic systems, a precise degree of efficiency of these systems is not completely determined. Introducing an efficient model for the dynamics of light-harvesting complexes in biological environments is a major purpose in investigating such systems. Here, we investigate the effect of macroscopic quantum behavior of a system of two pigments on the transport phenomena in this system model which interacts with an oscillating environment. We use the second-order perturbation theory to calculate the time-dependent population of excitonic states of a two-dimensional Hamiltonian using a non-master equation approach. Our results demonstrate that the quantum efficiency is robust with respect to the macroscopicity parameter h solely, but the ratio of macroscopicity over the pigment-pigment interaction energy can be considered as a parameter that may control the energy transfer efficiency at a given time. So, the dynamical behavior and the quantum efficiency of the supposed photosynthetic system may be influenced by a change in the macroscopic behavior of the system.",physics.chem-ph quant-ph
"Despite several dissimilar measures of efficiency that are applicable to the photosynthetic systems, a precise degree of efficiency of these organization is not completely determined. Introducing an efficient model for the dynamics of light-harvesting complexes in biological environments is a major purpose in investigating such systems. Here, we investigate the effect of macroscopic quantum behavior of a system of two pigments on the transport phenomena in this system model which interacts with an oscillating environment. We use the second-order perturbation theory to calculate the time-dependent population of excitonic states of a two-dimensional Hamiltonian using a non-master equation approach. Our results demonstrate that the quantum efficiency is robust with respect to the macroscopicity parameter h solely, but the ratio of macroscopicity over the pigment-pigment interaction energy can be considered as a parameter that may control the energy transfer efficiency at a given time. So, the dynamical behavior and the quantum efficiency of the supposed photosynthetic system may be influenced by a change in the macroscopic behavior of the system.",physics.chem-ph quant-ph
These lectures provide an elementary introduction to Chern Simons Gravity and Supergravity in $d=2n+1$ dimensions.,hep-th
These lambaste provide an elementary introduction to Chern Simons gravitational force and Supergravity in $d=2n+1$ dimensions.,hep-th
"As the amount of data explodes rapidly, more and more corporations are using data centers to make effective decisions and gain a competitive edge. Data analysis applications play a significant role in data centers, and hence it has became increasingly important to understand their behaviors in order to further improve the performance of data center computer systems. In this paper, after investigating three most important application domains in terms of page views and daily visitors, we choose eleven representative data analysis workloads and characterize their micro-architectural characteristics by using hardware performance counters, in order to understand the impacts and implications of data analysis workloads on the systems equipped with modern superscalar out-of-order processors. Our study on the workloads reveals that data analysis applications share many inherent characteristics, which place them in a different class from desktop (SPEC CPU2006), HPC (HPCC), and service workloads, including traditional server workloads (SPECweb2005) and scale-out service workloads (four among six benchmarks in CloudSuite), and accordingly we give several recommendations for architecture and system optimizations. On the basis of our workload characterization work, we released a benchmark suite named DCBench for typical datacenter workloads, including data analysis and service workloads, with an open-source license on our project home page on http://prof.ict.ac.cn/DCBench. We hope that DCBench is helpful for performing architecture and small-to-medium scale system researches for datacenter computing.",cs.PF
"As the amount of data explodes rapidly, more and more corporations are using data centers to make effectual decisions and gain a competitive edge. Data analysis applications play a significant role in data centers, and hence it has became increasingly important to understand their behaviors in order to further improve the performance of data center computer systems. In this paper, after investigating three most important application domains in terms of page views and daily visitors, we choose eleven representative data analysis workloads and characterize their micro-architectural characteristics by using hardware performance counters, in order to understand the impacts and implications of data analysis workloads on the systems equipped with modern superscalar out-of-order processors. Our study on the workloads reveals that data analysis applications share many inherent characteristics, which place them in a different class from desktop (SPEC CPU2006), HPC (HPCC), and service workloads, including traditional server workloads (SPECweb2005) and scale-out service workloads (four among six benchmarks in CloudSuite), and accordingly we give respective recommendations for architecture and system optimizations. On the basis of our workload characterization work, we released a benchmark suite named DCBench for typical datacenter workloads, including data analysis and service workloads, with an open-source license on our project home page on http://prof.ict.ac.cn/DCBench. We hope that DCBench is helpful for performing architecture and small-to-medium scale system researches for datacenter computing.",cs.PF
"Despite significant progress in the theory of evolutionary algorithms, the theoretical understanding of evolutionary algorithms which use non-trivial populations remains challenging and only few rigorous results exist. Already for the most basic problem, the determination of the asymptotic runtime of the $(\mu+\lambda)$ evolutionary algorithm on the simple OneMax benchmark function, only the special cases $\mu=1$ and $\lambda=1$ have been solved. In this work, we analyze this long-standing problem and show the asymptotically tight result that the runtime $T$, the number of iterations until the optimum is found, satisfies \[E[T] = \Theta\bigg(\frac{n\log n}{\lambda}+\frac{n}{\lambda / \mu} + \frac{n\log^+\log^+ \lambda/ \mu}{\log^+ \lambda / \mu}\bigg),\] where $\log^+ x := \max\{1, \log x\}$ for all $x > 0$. The same methods allow to improve the previous-best $O(\frac{n \log n}{\lambda} + n \log \lambda)$ runtime guarantee for the $(\lambda+\lambda)$~EA with fair parent selection to a tight $\Theta(\frac{n \log n}{\lambda} + n)$ runtime result.",cs.NE
"Despite significant progress in the theory of evolutionary algorithms, the theoretical understanding of evolutionary algorithmic program which use non-trivial populations remains challenging and only few rigorous results exist. Already for the most basic problem, the determination of the asymptotic runtime of the $(\mu+\lambda)$ evolutionary algorithm on the simple OneMax benchmark function, only the special cases $\mu=1$ and $\lambda=1$ have been solved. In this work, we analyze this long-standing problem and show the asymptotically tight result that the runtime $T$, the number of iterations until the optimum is found, satisfies \[E[T] = \Theta\bigg(\frac{n\log n}{\lambda}+\frac{n}{\lambda / \mu} + \frac{n\log^+\log^+ \lambda/ \mu}{\log^+ \lambda / \mu}\bigg),\] where $\log^+ x := \max\{1, \log x\}$ for all $x > 0$. The same methods allow to improve the previous-best $O(\frac{n \log n}{\lambda} + n \log \lambda)$ runtime guarantee for the $(\lambda+\lambda)$~EA with fair rear selection to a tight $\Theta(\frac{n \log n}{\lambda} + n)$ runtime result.",cs.NE
"We present [1] the first simultaneous extraction of the transversity distribution and the Collins fragmentation function, obtained through a combined analysis of experimental data on azimuthal asymmetries in semi-inclusive deep inelastic scattering (SIDIS), from the HERMES and COMPASS Collaborations, and in e+ e- --> h1 h2 X processes, from the Belle Collaboration.",hep-ph
"We give [1] the first simultaneous extraction of the transversity distribution and the Collins fragmentation function, obtained through a coalesce analysis of experimental data on azimuthal asymmetries in semi-inclusive deep inelastic scattering (SIDIS), from the HERMES and COMPASS Collaborations, and in e+ e- --> h1 h2 X processes, from the Belle Collaboration.",hep-ph
"Robustness and safety are crucial properties for the real-world application of autonomous vehicles. One of the most critical components of any autonomous system is localisation. During the last 20 years there has been significant progress in this area with the introduction of very efficient algorithms for mapping, localisation and SLAM. Many of these algorithms present impressive demonstrations for a particular domain, but fail to operate reliably with changes to the operating environment. The aspect of robustness has not received enough attention and localisation systems for self-driving vehicle applications are seldom evaluated for their robustness. In this paper we propose novel metrics to effectively quantify localisation robustness with or without an accurate ground truth. The experimental results present a comprehensive analysis of the application of these metrics against a number of well known localisation strategies.",cs.RO
"Robustness and safety are crucial properties for the real-world application of autonomous vehicles. One of the most critical components of any autonomous system is localisation. During the last 20 years there has been significant forward motion in this area with the introduction of very efficient algorithms for mapping, localisation and SLAM. Many of these algorithms present impressive demonstrations for a particular domain, but fail to operate reliably with changes to the operating environment. The aspect of robustness has not received enough aid and localisation systems for self-driving vehicle applications are seldom evaluated for their robustness. In this paper we propose novel metrics to effectively quantify localisation robustness with or without an accurate ground truth. The experimental results present a comprehensive analysis of the application of these metrics against a number of well known localisation strategies.",cs.RO
"The Semantic Web, an extension of the current web, provides a common framework that makes data machine understandable and also allows data to be shared and reused across various applications. Resource Description Framework (RDF), a graph-based data model for describing things (entities), facilitates data integration. Due to the explosion of the amount of RDF data, developing tools to support processing and answering of complex queries over the integrated data has become challenging. To overcome this challenge in query processing in semantic data integration frameworks, we provide a view layer inserted between the heterogeneous data sources and user interface layer while ensuring only authorized users are allowed access to the information. The view layer must provide a support in terms of access, integration, querying, management of data sources in a multi-user environment.",cs.CR
"The Semantic Web, an extension of the current web, provides a common framework that makes data machine understandable and also allows data to be shared and reused across various applications. Resource Description Framework (RDF), a graph-based data model for describing things (entities), facilitates data integration. Due to the explosion of the amount of RDF data, developing cock to endorse processing and answering of complex queries over the integrated data has become challenging. To overcome this challenge in query processing in semantic data integration frameworks, we provide a view layer inserted between the heterogeneous data sources and user interface layer while ensuring only authorized users are allowed access to the information. The view layer must provide a endorse in terms of access, integration, querying, management of data sources in a multi-user environment.",cs.CR
"We prove that the two fluid Landau hydrodynamic equations, when applied to a gas interacting with infinite scattering length (unitary gas) in the presence of harmonic trapping, admit exact scaling solutions of mixed compressional and surface nature. These solutions are characterized by a linear dependence of the velocity field on the spatial coordinates and a temperature independent frequency which is calculated in terms of the parameters of the trap. Our results are derived in the regime of small amplitude oscillations and hold both below and above the superfluid phase transition. They apply to isotropic as well as to deformed configurations, thereby providing a generalization of Castin's theorem (Y. Castin, C. R. Phys. \textbf{5}, 407 (2004)) holding for isotropic trapping. Our predictions agree with the experimental findings in resonantly interacting atomic Fermi gases. The breathing scaling solution, in the presence of isotropic trapping, is also used to prove the vanishing of two bulk viscosity coefficients in the superfluid phase.",cond-mat.quant-gas
"We prove that the two fluid Landau hydrodynamic equations, when applied to a gas interacting with infinite scattering length (unitary gas) in the presence of harmonic trapping, admit precise scaling solutions of mixed compressional and surface nature. These solutions are characterized by a linear dependence of the velocity field on the spatial coordinates and a temperature independent frequency which is calculated in terms of the parameters of the trap. Our results are derived in the regime of small amplitude oscillations and hold both below and above the superfluid phase transition. They apply to isotropic as well as to deformed configurations, thereby providing a generalization of Castin's theorem (Y. Castin, C. R. Phys. \textbf{5}, 407 (2004)) holding for isotropic trapping. Our predictions agree with the data-based findings in resonantly interacting atomic Fermi gases. The breathing scaling solution, in the presence of isotropic trapping, is also used to prove the vanishing of two bulk viscosity coefficients in the superfluid phase.",cond-mat.quant-gas
"We present the first results on the complexity of the reconfiguration of vertex separators under the three most popular rules: token addition/removal, token jumping, and token sliding. We show that, aside from some trivially negative instances, the first two rules are equivalent to each other and that, even if only on a subclass of bipartite graphs, TJ is not equivalent to the other two unless $\mathsf{NP} = \mathsf{PSPACE}$; we do this by showing a relationship between separators and independent sets in this subclass of bipartite graphs. In terms of polynomial time algorithms, we show that every class with a polynomially bounded number of minimal vertex separators admits an efficient algorithm under token jumping, then turn our attention to two classes that do not meet this condition: $\{3P_1, diamond\}$-free and series-parallel graphs. For the first, we describe a novel characterization, which we use to show that reconfiguring vertex separators under token jumping is always possible and that, under token sliding, it can be done in polynomial time; for series-parallel graphs, we also prove that reconfiguration is always possible under TJ and exhibit a polynomial time algorithm to construct the reconfiguration sequence.",cs.CC cs.DS
"We present the first results on the complexity of the reconfiguration of vertex separators under the three most pop rules: token addition/removal, token jumping, and token sliding. We show that, aside from some trivially negative instances, the first two rules are equivalent to each other and that, even if only on a subclass of two-way graphs, TJ is not equivalent to the other two unless $\mathsf{NP} = \mathsf{PSPACE}$; we do this by showing a relationship between separators and independent sets in this subclass of two-way graphs. In terms of polynomial time algorithms, we show that every class with a polynomially bounded number of minimal vertex separators admits an efficient algorithm under token jumping, then turn our attention to two classes that do not meet this condition: $\{3P_1, diamond\}$-free and series-parallel graphs. For the first, we describe a novel characterization, which we use to show that reconfiguring vertex separators under token jumping is always possible and that, under token sliding, it can be done in polynomial time; for series-parallel graphs, we also prove that reconfiguration is always possible under TJ and exhibit a polynomial time algorithm to construct the reconfiguration sequence.",cs.CC cs.DS
"Arno Bohm and Ilya Prigogine's Brussels-Austin Group have been working on the quantum mechanical arrow of time and irreversibility in rigged Hilbert space quantum mechanics. A crucial notion in Bohm's approach is the so-called preparation/registration arrow. An analysis of this arrow and its role in Bohm's theory of scattering is given. Similarly, the Brussels-Austin Group uses an excitation/de-excitation arrow for ordering events, which is also analyzed. The relationship between the two approaches is initially discussed focusing on their semi-group operators and time arrows. Finally a possible realist interpretation of the rigged Hilbert space formulation of quantum mechanics is considered.",quant-ph
"Arno Bohm and Ilya Prigogine's Brussels-Austin Group have been cultivate on the quantum mechanical arrow of time and irreversibility in rigged Hilbert space quantum mechanics. A crucial notion in Bohm's approach is the alleged preparation/registration arrow. An analysis of this arrow and its role in Bohm's theory of scattering is given. Similarly, the Brussels-Austin Group uses an excitation/de-excitation arrow for ordering events, which is also analyzed. The relationship between the two approaches is initially discussed focusing on their semi-group operators and time arrows. Finally a possible realist interpretation of the rigged Hilbert space formulation of quantum mechanics is considered.",quant-ph
We study the properties of a mobile hole in the $t-J$ model on the square lattice by means of variational Monte Carlo simulations based on the entangled-plaquette ansatz. Our energy estimates for small lattices reproduce available exact results. We obtain values for the hole energy dispersion curve on large lattices in quantitative agreement with earlier findings based on the most reliable numerical techniques. Accurate estimates of the hole spectral weight are provided.,cond-mat.str-el
We study the properties of a mobile hole in the $t-J$ model on the square lattice by means of variational Monte Carlo simulations based on the entangled-plaquette ansatz. Our energy estimates for small lattices reproduce usable exact results. We obtain values for the hole energy dispersion curve on boastfully lattices in quantitative agreement with earlier findings based on the most reliable numerical techniques. Accurate estimates of the hole spectral weight are provided.,cond-mat.str-el
"We have investigated the rheology and structure of a gel formed from a mixture of non-Brownian particles and two immiscible liquids. The suspension of particles in a liquid undergoes gelation upon the addition of a small content of second, wetting liquid which forms liquid bridges between particles leading to a sample spanning network. The rheology of this gel primarily exhibits a yield stress at low shear rates followed by a linear variation of shear stress at high shear rates. The apparent yield stress extracted from the flow curves increases rapidly with volume fraction of second liquid before saturation, while it exhibits a monotonic increase with increasing particle concentration. Rescaling of the yield stress curves using suitable shift factors results in an empirical expression for the yield stress showing squared dependence on liquid fraction and a rapid increase with particle fraction above a certain value, both combined in a highly nonlinear manner. The microstructural variations with changing secondary liquid content and particle fractions are captured using three dimensional X-ray tomography technique. The microstructure is observed to show increased local compactness with increased liquid content and increased spatial homogeneity with increased particle fractions. The images from X-ray tomography are analysed to obtain the distributions of particle-particle bonds (coordination number) in the system which serve to explain the observed yield stress behavior in a qualitative manner.",cond-mat.soft
"We have investigated the rheology and structure of a gel formed from a mixture of non-Brownian particles and two immiscible liquids. The suspension of particles in a liquid undergoes gelation upon the addition of a small content of second, wetting liquid which forms liquid bridges between particles leading to a sample spanning network. The rheology of this gel primarily exhibits a yield stress at low shear rates followed by a linear variation of shear stress at high shear rates. The apparent yield stress extracted from the flow curves increases rapidly with volume fraction of second liquid before saturation, while it exhibits a monotonic increase with increasing particle concentration. Rescaling of the yield stress curves using suitable shift factors results in an empirical formulation for the yield stress showing squared dependence on liquid fraction and a rapid increase with particle fraction above a certain value, both combined in a highly nonlinear manner. The microstructural variations with changing secondary liquid content and particle fractions are captured using triad dimensional X-ray tomography technique. The microstructure is observed to show increased local compactness with increased liquid content and increased spatial homogeneity with increased particle fractions. The images from X-ray tomography are analysed to obtain the distributions of particle-particle bonds (coordination number) in the system which serve to explain the observed yield stress behavior in a qualitative manner.",cond-mat.soft
"We revisit the model of a Brownian particle in a heat bath submitted to an actively controlled force proportional to the velocity that leads to thermal noise reduction (cold damping). We investigate the influence of the continuous feedback on the fluctuations of the total entropy production and show that the explicit expression of the detailed fluctuation theorem involves different dynamics and observables in the forward and backward processes. As an illustration, we study the analytically solvable case of a harmonic oscillator and calculate the characteristic function of the entropy production in a nonequilibrium steady state. We then determine the corresponding large deviation function which results from an unusual interplay between 'boundary' and 'bulk' contributions.",cond-mat.mes-hall cond-mat.stat-mech
"We revisit the model of a Brownian molecule in a heat bath submitted to an actively controlled force proportional to the velocity that leads to thermal noise reduction (cold damping). We investigate the influence of the continuous feedback on the fluctuations of the total information production and show that the explicit expression of the detailed fluctuation theorem involves different dynamics and observables in the forward and backward processes. As an illustration, we study the analytically solvable case of a harmonic oscillator and calculate the characteristic function of the information production in a nonequilibrium steady state. We then determine the corresponding large deviation function which results from an unusual interplay between 'boundary' and 'bulk' contributions.",cond-mat.mes-hall cond-mat.stat-mech
"We give an example of a convex body whose centroid and Santal\'o point are ""far apart"".",math.FA
"We give an example of a convex physical structure whose centroid and Santal\'o designate are ""far apart"".",math.FA
"I describe the Time-Dependent Superfluid Local Density Approximation, which is an adiabatic extension of the Density Functional Theory to superfluid Fermi systems and their real-time dynamics. This new theoretical framework has been applied to describe a number of phenomena in cold atomic gases and nuclear collective motion: excitation of the Higgs modes in strongly interacting Fermi superfluids, generation of quantized vortices, crossing and reconnection of vortices, excitation of the superflow at velocities above the critical velocity, excitation of quantum shock waves and domain walls in the collisions of superfluid atomic clouds, excitation of collective states in nuclei.",cond-mat.quant-gas nucl-th
"I describe the Time-Dependent Superfluid Local Density Approximation, which is an adiabatic extension of the Density Functional Theory to superfluid Fermi systems and their real-time dynamics. This new theoretical framework has been applied to describe a number of phenomena in cold atomic gases and atomic collective motion: excitation of the Higgs modes in strongly interacting Fermi superfluids, generation of quantized vortices, crossing and reconnection of vortices, excitation of the superflow at velocities above the critical velocity, excitation of quantum shock waves and domain walls in the hit of superfluid atomic clouds, excitation of collective states in nuclei.",cond-mat.quant-gas nucl-th
"We show that using the modified form of the Dirac Hamiltonian as suggested by Bekenstein, does not affect the analysis in [1-4] of QSO data pertaining to a measurement of alpha variation. We obtain the present time limit on Bekenstein's parameter, tan^{2}chi =(0.2 \pm 0.7)\times10^{-6}, from the measurement of the hydrogen 2p fine structure using value of alpha obtained from different experiments.",astro-ph hep-th physics.atom-ph
"We show that using the modified form of the Dirac Hamiltonian as suggested by Bekenstein, does not affect the analysis in [1-4] of QSO data pertaining to a measurement of alpha variation. We obtain the present time limit on Bekenstein's parameter, tan^{2}chi =(0.2 \pm 0.7)\times10^{-6}, from the measurement of the atomic number 1 2p fine structure using value of alpha incur from different experiments.",astro-ph hep-th physics.atom-ph
"Given a group $G$, we define suitable 2-categorical structures on the class of all small categories with $G$-actions and on the class of all small $G$-graded categories, and prove that 2-categorical extensions of the orbit category construction and of the smash product construction turn out to be 2-equivalences (2-quasi-inverses to each other), which extends the Cohen-Montgomery duality.",math.CT math.RA
"reach a group $G$, we define suitable 2-categorical structures on the class of all small categories with $G$-actions and on the class of all small $G$-graded categories, and prove that 2-categorical extensions of the orbit category construction and of the smash cartesian product construction turn out to be 2-equivalences (2-quasi-inverses to each other), which extends the Cohen-Montgomery duality.",math.CT math.RA
"The hot and dense matter created in the early stage of a relativistic heavy ion collision is composed mainly of gluons. Radiative processes can play an important role for the thermalization of such partonic systems. The simplest parton number changing processes are commonly described by the Gunion-Bertsch formula. We show that the cross section from the exact matrix element for the lowest order radiative process could be significantly smaller than that based on the Gunion-Bertsch formula. In light of this, we discuss the role of radiative processes on the equilibrium and equilibration of a gluon plasma.",nucl-th
"The hot and dense matter created in the early stage of a relativistic heavy ion collision is composed mainly of gluons. Radiative processes can play an important role for the thermalization of such partonic systems. The simplest parton number change processes are commonly name by the Gunion-Bertsch formula. We show that the cross section from the exact matrix element for the lowest order radiative process could be significantly smaller than that based on the Gunion-Bertsch formula. In light of this, we discuss the role of radiative processes on the equilibrium and equilibration of a gluon plasma.",nucl-th
"The system of a quarkonium confined by an impenetrable spherical cavity filled with a hot quantum chromodynamics (QCD) medium is studied by solving the Schr\""{o}dinger equation. This is the first time this issue has been raised for discussion. The Schr\""{o}dinger equation with an appropriate boundary condition of a quarkonium in an impenetrable cavity filled with a hot medium is derived. The numerical results are obtained with the help of Gaussian Expansion Method. Binding energies and radii of the ground and low-excited states are obtained as a function of the medium temperature and the cavity radius. We find the behaviour of quarkonium in this cavity is different from that in infinite space. Our results show that the quarkonium dissociation temperature decreases as the cavity radius decreases and the finite volume effects on the ground state are more obvious than on the excited states. We also find that the less mass of the constituents and the bigger radius of the quarkonium lead the finite volume effects to become more obvious.",nucl-th
"The system of a quarkonium confined by an impenetrable spherical cavity filled with a hot quantum chromodynamics (QCD) medium is studied by solving the Schr\""{o}dinger equation. This is the low time this issue has been raised for discussion. The Schr\""{o}dinger equivalence with an appropriate boundary condition of a quarkonium in an impenetrable cavity filled with a hot medium is derived. The numerical results are obtained with the help of Gaussian Expansion Method. Binding energies and radii of the ground and low-excited states are obtained as a function of the medium temperature and the cavity radius. We find the behaviour of quarkonium in this cavity is different from that in infinite space. Our results show that the quarkonium dissociation temperature decreases as the cavity radius decreases and the finite volume effects on the ground state are more obvious than on the excited states. We also find that the less mass of the constituents and the bigger radius of the quarkonium lead the finite volume effects to become more obvious.",nucl-th
"We consider the set multi-cover problem in geometric settings. Given a set of points P and a collection of geometric shapes (or sets) F, we wish to find a minimum cardinality subset of F such that each point p in P is covered by (contained in) at least d(p) sets. Here d(p) is an integer demand (requirement) for p. When the demands d(p)=1 for all p, this is the standard set cover problem. The set cover problem in geometric settings admits an approximation ratio that is better than that for the general version. In this paper, we show that similar improvements can be obtained for the multi-cover problem as well. In particular, we obtain an O(log Opt) approximation for set systems of bounded VC-dimension, where Opt is the cardinality of an optimal solution, and an O(1) approximation for covering points by half-spaces in three dimensions and for some other classes of shapes.",cs.CG
"We consider the set multi-cover problem in geometric settings. Given a set of points P and a collection of geometric shapes (or sets) F, we wish to find a minimum cardinality subset of F such that each point p in P is covered by (contained in) at least d(p) sets. Here d(p) is an integer postulate (requirement) for p. When the demands d(p)=1 for all p, this is the standard set cover problem. The set cover problem in geometric settings admits an approximation ratio that is better than that for the general version. In this paper, we show that similar improvement can be obtained for the multi-cover problem as well. In particular, we obtain an O(log Opt) approximation for set systems of bounded VC-dimension, where Opt is the cardinality of an optimal solution, and an O(1) approximation for covering points by half-spaces in three dimensions and for some other classes of shapes.",cs.CG
We present the results of a monitoring campaign of the double quasar SBS1520+530 at Maidanak observatory from April 2003 to August 2004. We obtained light curves in V and R filters that show small-amplitude \Delta m~0.1 mag intrinsic variations of the quasar on time scales of about 100 days. The data set is consistent with the previously determined time delay of \Delta t=(130+-3) days by Burud et al. (2002). We find that the time delay corrected magnitude difference between the quasar images is now larger by (0.14+-0.03) mag than during the observations by Burud et al. (2002). This confirms the presence of gravitational microlensing variations in this system.,astro-ph
We present the results of a monitoring campaign of the double quasar SBS1520+530 at Maidanak observatory from April 2003 to lordly 2004. We obtained clear curves in V and R filters that show small-amplitude \Delta m~0.1 mag intrinsic variations of the quasar on time scales of about 100 days. The data set is consistent with the previously determined time delay of \Delta t=(130+-3) days by Burud et al. (2002). We find that the time delay corrected magnitude difference between the quasar images is now larger by (0.14+-0.03) mag than during the observations by Burud et al. (2002). This confirms the presence of gravitational microlensing variations in this system.,astro-ph
"We propose a novel cosmological scenario, in which standard inflation is replaced by an expanding phase with a drastic violation of the Null Energy Condition (NEC): \dot H >> H^2. The model is based on the recently introduced Galileon theories, that allow NEC violating solutions without instabilities. The unperturbed solution describes a Universe that is asymptotically Minkowski in the past, expands with increasing energy density until it exits the regime of validity of the effective field theory and reheats. This solution is a dynamical attractor and the Universe is driven to it, even if it is initially contracting. The study of perturbations of the Galileon field reveals some subtleties, related to the gross violation of the NEC and it shows that adiabatic perturbations are cosmologically irrelevant. The model, however, suggests a new way to produce a scale invariant spectrum of isocurvature perturbations, which can later be converted to adiabatic: the Galileon is forced by symmetry to couple to the other fields as a dilaton; the effective metric it yields on the NEC violating solution is that of de Sitter space, so that all light scalars will automatically acquire a nearly scale-invariant spectrum of perturbations.",astro-ph.CO gr-qc hep-th
"We propose a novel cosmological scenario, in which standard inflation is replaced by an expanding phase with a drastic violation of the zilch Energy Condition (NEC): \dot H >> H^2. The model is based on the recently introduced Galileon theories, that allow NEC violating solutions without instabilities. The unperturbed solution describes a Universe that is asymptotically Minkowski in the past, expands with increasing energy density until it exits the regime of validity of the effective field theory and reheats. This solution is a dynamical attractor and the Universe is driven to it, even if it is initially contracting. The study of perturbations of the Galileon field reveals some subtleties, related to the gross violation of the NEC and it shows that adiabatic perturbations are cosmologically irrelevant. The model, however, suggests a new way to produce a scale invariant spectrum of isocurvature perturbations, which can later be converted to adiabatic: the Galileon is forced by symmetry to couple to the other fields as a dilaton; the effective system of measurement it yields on the NEC violating solution is that of de Sitter space, so that all light scalars will automatically acquire a nearly scale-invariant spectrum of perturbations.",astro-ph.CO gr-qc hep-th
"Path integral formulation of quantum mechanics (and also other equivalent formulations) depends on a Lagrangian and/or Hamiltonian function that is chosen to describe the underlying classical system. The arbitrariness presented in this choice leads to a phenomenon called Quantization ambiguity. For example both $L_1=\dot{q}^2$ and $L_2=e^\dot{q}$ are suitable Lagrangians on a classical level ($\delta L_1=0=\delta L_2$), but quantum mechanically they are diverse. This paper presents a simple rearrangement of the path integral to a surface functional integral. It is shown that the surface functional integral formulation gives transition probability amplitude which is free of any Lagrangian/Hamiltonian and requires just the underlying classical equations of motion. A simple example examining the functionality of the proposed method is considered.",hep-th math-ph math.MP quant-ph
"Path integral formulation of quantum mechanics (and also other equivalent formulations) depends on a Lagrangian and/or Hamiltonian function that is chosen to describe the underlying classical system. The arbitrariness presented in this pick leads to a phenomenon called Quantization ambiguity. For example both $L_1=\dot{q}^2$ and $L_2=e^\dot{q}$ are suitable Lagrangians on a classical level ($\delta L_1=0=\delta L_2$), but quantum mechanically they are diverse. This paper presents a simple rearrangement of the path integral to a surface functional integral. It is shown that the surface functional integral formulation present transition probability amplitude which is free of any Lagrangian/Hamiltonian and requires just the underlying classical equations of motion. A simple example examining the functionality of the proposed method is considered.",hep-th math-ph math.MP quant-ph
"By means of a truncation condition on the parameters, the elliptic Ruijsenaars difference operators are restricted onto a finite lattice of points encoded by bounded partitions. A corresponding orthogonal basis of joint eigenfunctions is constructed in terms of polynomials on the joint spectrum. In the trigonometric limit, this recovers the diagonalization of the truncated Macdonald difference operators by a finite-dimensional basis of Macdonald polynomials.",math-ph math.MP nlin.SI
"By means of a truncation condition on the parameters, the elliptic Ruijsenaars difference manipulator are restricted onto a finite lattice of points encode by bounded partitions. A corresponding orthogonal basis of joint eigenfunctions is constructed in terms of polynomials on the joint spectrum. In the trigonometric limit, this recovers the diagonalization of the truncated Macdonald difference manipulator by a finite-dimensional basis of Macdonald polynomials.",math-ph math.MP nlin.SI
"Critical analysis of the state of the art is a necessary task when identifying new research lines worthwhile to pursue. To such an end, all the available work related to the field of interest must be taken into account. The key point is how to organize, analyze, and make sense of the huge amount of scientific literature available today on any topic. To tackle this problem, we present here a bibliometric approach to Systematic Mapping Studies (SMS). Thus, a modify SMS protocol is used relying on the scientific references metadata to extract, process and interpret the wealth of information contained in nowadays research literature. As a test case, the procedure is applied to determine the current state and perspectives of community detection in complex networks. Our results show that community detection is a still active, far from exhausted, in development, field. In addition, we find that, by far, the most exploited methods are those related to determining hierarchical community structures. On the other hand, the results show that fuzzy clustering techniques, despite their interest, are underdeveloped as well as the adaptation of existing algorithms to parallel or, more specifically, distributed, computational systems.",cs.DL cs.SI physics.soc-ph
"Critical analysis of the state of the art is a necessary task when identifying new research lines worthwhile to pursue. To such an end, all the available work related to the field of interest must be taken into account. The key point is how to organize, analyze, and make sense of the huge amount of scientific lit available today on any topic. To tackle this problem, we present hither a bibliometric approach to Systematic Mapping Studies (SMS). Thus, a modify SMS protocol is used relying on the scientific references metadata to extract, process and interpret the wealth of information contained in nowadays research literature. As a test case, the procedure is applied to determine the current state and perspectives of community detection in complex networks. Our results show that community detection is a still active, far from exhausted, in development, field. In addition, we find that, by far, the most exploited methods are those related to determining hierarchical community structures. On the other hand, the results show that fuzzy clustering techniques, despite their interest, are underdeveloped as well as the adaptation of existing algorithms to parallel or, more specifically, distributed, computational systems.",cs.DL cs.SI physics.soc-ph
"We consider the simplest instabilities involving multiple unstable electrostatic plasma waves corresponding to four-dimensional systems of mode amplitude equations. In each case the coupled amplitude equations are derived up to third order terms. The nonlinear coefficients are singular in the limit in which the linear growth rates vanish together. These singularities are analyzed using techniques developed in previous studies of a single unstable wave. In addition to the singularities familiar from the one mode problem, there are new singularities in coefficients coupling the modes. The new singularities are most severe when the two waves have the same linear phase velocity and satisfy the spatial resonance condition $k_2=2k_1$. As a result the short wave mode saturates at a dramatically smaller amplitude than that predicted for the weak growth rate regime on the basis of single mode theory. In contrast the long wave mode retains the single mode scaling. If these resonance conditions are not satisfied both modes retain their single mode scaling and saturate at comparable amplitudes.",nlin.PS patt-sol
"We consider the simplest instabilities involving multiple unstable electrostatic plasma waves corresponding to four-dimensional systems of mode amplitude equations. In each case the coupled amplitude equations are derived up to third order terms. The nonlinear coefficients are singular in the limit in which the linear growth rates vanish together. These singularities are analyzed using techniques developed in previous studies of a single unstable wave. In addition to the singularities familiar from the one mode problem, there are new singularities in coefficients coupler the modes. The new singularities are most severe when the two waves have the same linear phase velocity and satisfy the spatial resonance condition $k_2=2k_1$. As a result the short wave mode saturates at a dramatically smaller amplitude than that predicted for the weak growth rate regime on the groundwork of single mode theory. In contrast the long wave mode retains the single mode scaling. If these resonance conditions are not satisfied both modes retain their single mode scaling and saturate at comparable amplitudes.",nlin.PS patt-sol
"In social tagging systems, the diversity of tag vocabulary and the popularity of such tags continue to increase as they are exposed to selection pressure derived from our cognitive nature and cultural preferences. This is analogous to living ecosystems, where mutation and selection play a dominant role. Such population dynamism, which yields a scaling law, is mathematically modeled by a simple stochastic process---the Yule--Simon process, which describes how new words are introduced to the system and then grow. However, in actual web services, we have observed that a large fluctuation emerges in the popularity growth of individual tags that cannot be explained by the ordinary selection mechanism. We introduce a scaling factor to quantify the degree of the deviation in the popularity growth from the mean-field solution of the Yule--Simon process, and we discuss possible triggers of such anomalous popularity behavior.",cs.SI physics.soc-ph
"In social tagging systems, the diversity of tag vocabulary and the popularity of such tags continue to increase as they are exposed to selection squeeze derived from our cognitive nature and cultural preferences. This is analogous to living ecosystems, where mutation and selection play a dominant role. Such universe dynamism, which yields a scaling law, is mathematically modeled by a simple stochastic process---the Yule--Simon process, which describes how new words are introduced to the system and then grow. However, in actual web services, we have observed that a large fluctuation emerges in the popularity growth of individual tags that cannot be explained by the ordinary selection mechanism. We introduce a scaling factor to quantify the degree of the deviation in the popularity growth from the mean-field solution of the Yule--Simon process, and we discuss possible triggers of such anomalous popularity behavior.",cs.SI physics.soc-ph
"Public debates are a common platform for presenting and juxtaposing diverging views on important issues. In this work we propose a methodology for tracking how ideas flow between participants throughout a debate. We use this approach in a case study of Oxford-style debates---a competitive format where the winner is determined by audience votes---and show how the outcome of a debate depends on aspects of conversational flow. In particular, we find that winners tend to make better use of a debate's interactive component than losers, by actively pursuing their opponents' points rather than promoting their own ideas over the course of the conversation.",cs.AI cs.CL cs.SI physics.soc-ph stat.ML
"Public debates are a common platform for presenting and juxtaposing diverging views on important issues. In this work we propose a methodology for tracking how ideas run between participants throughout a debate. We use this approach in a case study of Oxford-style debates---a competitive arrange where the winner is determined by audience votes---and show how the outcome of a debate depends on aspects of conversational flow. In particular, we find that winners tend to make better use of a debate's interactive component than losers, by actively pursuing their opponents' points rather than promoting their own ideas over the course of the conversation.",cs.AI cs.CL cs.SI physics.soc-ph stat.ML
"We present a way to realize quantum information transfer with superconducting flux qubits coupled to a cavity. Because only resonant qubit-cavity interaction and resonant qubit-pulse interaction are applied, the information transfer can be performed much faster, when compared with the previous proposals. This proposal does not require adjustment of the qubit level spacings during the operation. Moreover, neither uniformity in the device parameters nor exact placement of qubits in the cavity is needed by this proposal.",quant-ph
"We present a way to realize quantum information transfer with superconducting flux qubits coupled to a cavity. Because only resonant qubit-cavity interaction and resonant qubit-pulse interaction are applied, the information transfer can be performed much faster, when equate with the previous proposals. This proposal does not require adjustment of the qubit level spacings during the operation. Moreover, neither uniformity in the twist parameters nor exact placement of qubits in the cavity is needed by this proposal.",quant-ph
"The magnetic strings in antiferromagnetic crystals with the spin $S = 1 /2$ differ from the magnetic polarons (ferrons) by the absence of the additional magnetic moment. We show that in the $S > 1 /2$ double exchange crystals with the antiferromagnetic $s-d$ exchange, a new type of magnetic strings appears, which possesses a magnetic moment. It is concentrated at the center of the string, and the magnetized string is, in its essence, the state intermediate between the string and the ferron. In antiferromagnetic manganites, this moment is by an order of magnitude larger than that of a magnetic atom. Unlike the conventional ferrons, the magnetization of the strings exists at any parameters of the crystals under consideration. We argue that this new type of magnetic state can be relevant to some doped antiferromagnets including manganites.",cond-mat.mtrl-sci cond-mat.str-el
"The magnetic draw in antiferromagnetic crystals with the spin $S = 1 /2$ differ from the magnetic polarons (ferrons) by the absence of the additional magnetic moment. We show that in the $S > 1 /2$ double exchange crystals with the antiferromagnetic $s-d$ exchange, a new type of magnetic draw appears, which possesses a magnetic moment. It is concentrated at the center of the string, and the magnetized string is, in its essence, the state intermediate 'tween the string and the ferron. In antiferromagnetic manganites, this moment is by an order of magnitude larger than that of a magnetic atom. Unlike the conventional ferrons, the magnetization of the draw exists at any parameters of the crystals under consideration. We argue that this new type of magnetic state can be relevant to some doped antiferromagnets including manganites.",cond-mat.mtrl-sci cond-mat.str-el
"The SU(3) lattice gauge theory is reformulated in terms of SU(3) prepotential harmonic oscillators. This reformulation has enlarged $SU(3)\otimes U(1) \otimes U(1)$ gauge invariance under which the prepotential operators transform like matter fields. The Hilbert space of SU(3) lattice gauge theory is shown to be equivalent to the Hilbert space of the prepotential formulation satisfying certain color invariant Sp(2,R) constraints. The SU(3) irreducible prepotential operators which solve these Sp(2,R) constraints are used to construct SU(3) gauge invariant Hilbert spaces at every lattice site in terms of SU(3) gauge invariant vertex operators. The electric fields and the link operators are reconstructed in terms of these SU(3) irreducible prepotential operators. We show that all the SU(3) Mandelstam constraints become local and take very simple form within this approach. We also discuss the construction of all possible linearly independent SU(3) loop states which solve the Mandelstam constraints. The techniques can be easily generalized to SU(N).",hep-lat hep-th
"The SU(3) lattice gauge theory is reformulated in terms of SU(3) prepotential harmonic oscillators. This reformulation has enlarged $SU(3)\otimes U(1) \otimes U(1)$ gauge invariance under which the prepotential operators transform like matter fields. The Hilbert quad of SU(3) lattice gauge theory is shown to be equivalent to the Hilbert quad of the prepotential formulation satisfying certain color invariant Sp(2,R) constraints. The SU(3) irreducible prepotential operators which solve these Sp(2,R) constraints are used to construct SU(3) gauge invariant Hilbert spaces at every lattice site in terms of SU(3) gauge invariant vertex operators. The electric fields and the link operators are reconstructed in terms of these SU(3) irreducible prepotential operators. We show that all the SU(3) Mandelstam constraints become local and take very simple form within this approach. We also discuss the construction of all possible linearly independent SU(3) loop states which solve the Mandelstam constraints. The techniques can be easily vulgarize to SU(N).",hep-lat hep-th
"Active galactic nuclei (AGN) produce vast amounts of high energy radiation deep in their central engines. X-rays either escape the AGN or are absorbed and re-emitted mostly as IR. By studying the dispersion in the ratio of observed mid-IR luminosity to observed 2-10keV X-ray luminosity (R_{ir/x}) in AGN we can investigate the reprocessing material (possibly a torus or donut of dust) in the AGN central engine, independent of model assumptions. We studied the ratio of observed mid-IR and 2-10keV X-ray luminosities in a heterogeneous sample of 245 AGN from the literature. We found that when we removed AGN with prominent jets, ~90% of Type I AGN lay within a very tight dispersion in luminosity ratio (1<R_{ir/x}<30). This implies that the AGN central engine is extremely uniform and models of the physical AGN environment (e.g. cloud cover, turbulent disk, opening angle of absorbing structures such as dusty tori) must span a very narrow range of parameters. We also found that the far-IR(100um) to mid-IR (12um) observed luminosity ratio is an effective descriminator between heavily obscured AGN and relatively unobscured AGN.",astro-ph
"Active galactic nuclei (AGN) produce vast amounts of high energy radiation deep in their central engines. X-rays either escape the AGN or are absorbed and re-emitted mostly as IR. By studying the dispersion in the ratio of observed mid-IR luminosity to observed 2-10keV X-ray luminosity (R_{ir/x}) in AGN we can investigate the reprocessing material (possibly a torus or doughnut of dust) in the AGN central engine, independent of model assumptions. We studied the ratio of observed mid-IR and 2-10keV X-ray luminosities in a heterogeneous sample of 245 AGN from the literature. We found that when we removed AGN with prominent jets, ~90% of Type I AGN lay within a very tight dispersion in luminosity ratio (1<R_{ir/x}<30). This implies that the AGN central engine is extremely uniform and models of the physical AGN environment (e.g. dapple cover, turbulent disk, opening angle of absorbing structures such as dusty tori) must span a very narrow range of parameters. We also found that the far-IR(100um) to mid-IR (12um) observed luminosity ratio is an effective descriminator between heavily obscured AGN and relatively unobscured AGN.",astro-ph
"For a pair of given binary perfect codes C and D of lengths t and m respectively, the Mollard construction outputs a perfect code M(C,D) of length tm + t + m, having subcodes C1 and D2, that are obtained from codewords of C and D respectively by adding appropriate number of zeros. In this work we generalize of a result for symmetry groups of Vasilev codes [2] and find the group Stab_{D2}Sym(M(C,D)). The result is preceded by and partially based on a discussion of linearity of coordinate positions (points) in a nonlinear perfect code (non-projective Steiner triple system respectively).",math.CO
"For a pair of given binary perfect codes C and D of lengths t and m respectively, the Mollard construction outturn a perfect code M(C,D) of length tm + t + m, having subcodes C1 and D2, that are obtained from codewords of C and D respectively by adding appropriate number of zeros. In this work we generalize of a result for symmetry groups of Vasilev codes [2] and notice the group Stab_{D2}Sym(M(C,D)). The result is preceded by and partially based on a discussion of linearity of coordinate positions (points) in a nonlinear perfect code (non-projective Steiner triple system respectively).",math.CO
"Radiation from a mirror moving in vacuum electromagnetic fields is shown to vanish in the case of a uniformly accelerated motion. Such motions are related to conformal coordinate transformations, which preserve correlation functions characteristic of vacuum fluctuations. As a result, vacuum fluctuations remain invariant under reflection upon a uniformly accelerated mirror, which therefore does not radiate and experiences no radiation reaction force. Mechanical effects of vacuum fluctuations thus exhibit an invariance with respect to uniformly accelerated motions.",gr-qc quant-ph
"Radiation from a mirror moving in vacuum electromagnetic subject is shown to vanish in the case of a uniformly accelerated motion. Such motions are related to conformal coordinate transformations, which preserve correlation functions characteristic of vacuum fluctuations. As a result, vacuum fluctuations remain invariant under reflection upon a uniformly accelerated mirror, which therefore does not radiate and get no radiation reaction force. Mechanical effects of vacuum fluctuations thus exhibit an invariance with respect to uniformly accelerated motions.",gr-qc quant-ph
"Given a perversity function in the sense of intersection homology theory, the method of intersection spaces assigns to certain oriented stratified spaces cell complexes whose ordinary reduced homology with real coefficients satisfies Poincar\'e duality across complementary perversities. The resulting homology theory is well-known not to be isomorphic to intersection homology. For a two-strata pseudomanifold with product link bundle, we give a description of the cohomology of intersection spaces as a space of weighted $L^2$ harmonic forms on the regular part, equipped with a fibred scattering metric. Some consequences of our methods for the signature are discussed as well.",math.AT
"Given a perversity function in the sense of intersection homology theory, the method of intersection spaces assigns to certain oriented stratified spaces cell complexes whose ordinary reduced homology with real coefficients satisfies Poincar\'e dichotomy across complementary perversities. The resulting homology theory is well-known not to be isomorphic to intersection homology. For a two-strata pseudomanifold with product link bundle, we generate a description of the cohomology of intersection spaces as a space of weighted $L^2$ harmonic forms on the regular part, equipped with a fibred scattering metric. Some consequences of our methods for the signature are discussed as well.",math.AT
"Adaptive inference is a promising technique to improve the computational efficiency of deep models at test time. In contrast to static models which use the same computation graph for all instances, adaptive networks can dynamically adjust their structure conditioned on each input. While existing research on adaptive inference mainly focuses on designing more advanced architectures, this paper investigates how to train such networks more effectively. Specifically, we consider a typical adaptive deep network with multiple intermediate classifiers. We present three techniques to improve its training efficacy from two aspects: 1) a Gradient Equilibrium algorithm to resolve the conflict of learning of different classifiers; 2) an Inline Subnetwork Collaboration approach and a One-for-all Knowledge Distillation algorithm to enhance the collaboration among classifiers. On multiple datasets (CIFAR-10, CIFAR-100 and ImageNet), we show that the proposed approach consistently leads to further improved efficiency on top of state-of-the-art adaptive deep networks.",cs.CV
"Adaptive inference is a promising technique to improve the computational efficiency of deep models at mental testing time. In contrast to static models which use the same computation graph for all instances, adaptive networks can dynamically adjust their structure conditioned on each input. While existing research on adaptive inference mainly focuses on designing more advanced architectures, this paper investigates how to train such networks more effectively. Specifically, we consider a typical adaptive deep network with multiple intermediate classifiers. We present three techniques to improve its training efficacy from two aspects: 1) a Gradient Equilibrium algorithmic program to resolve the conflict of learning of different classifiers; 2) an Inline Subnetwork Collaboration approach and a One-for-all Knowledge Distillation algorithmic program to enhance the collaboration among classifiers. On multiple datasets (CIFAR-10, CIFAR-100 and ImageNet), we show that the proposed approach consistently leads to further improved efficiency on top of state-of-the-art adaptive deep networks.",cs.CV
We study the effects of time ordering in photon generation processes such as spontaneous parametric down-conversion (SPDC) and four wave mixing (SFWM). The results presented here are used to construct an intuitive picture that allows us to predict when time ordering effects significantly modify the joint spectral amplitude (JSA) of the photons generated in SPDC and SFWM. These effects become important only when the photons being generated lie with the pump beam that travels through the non-linear material for a significant amount of time. Thus sources of spectrally separable photons are ideal candidates for the observation of modifications of the JSA due to time ordering.,quant-ph
We study the effects of time ordering in photon generation processes such as spontaneous parametric down-conversion (SPDC) and four wave mixing (SFWM). The results presented here are used to construct an intuitive picture that allows us to predict when time ordering effects significantly modify the spliff spectral amplitude (JSA) of the photons generated in SPDC and SFWM. These effects become important only when the photons represent generated lie with the pump beam that travels through the non-linear material for a significant amount of time. Thus sources of spectrally separable photons are ideal candidates for the observation of modifications of the JSA due to time ordering.,quant-ph
"We continue the work of Eriksen, Freij, and Wastlund [3], who study derangements that descend in blocks of prescribed lengths. We generalize their work to derangements that ascend in some blocks and descend in others. In particular, we obtain a generating function for the derangements that ascend in blocks of prescribed lengths, thus solving a problem posed in [3]. We also work towards a combinatorial interpretation of a polynomial sum appearing in [3]. As a result, we obtain a new combinatorial sum for counting derangements with ascending and descending blocks.",math.CO
"We continue the work of Eriksen, Freij, and Wastlund [3], who study derangements that descend in blocks of prescribed lengths. We generalize their work to derangements that ascend in some blocks and descend in others. In particular, we obtain a mother function for the derangements that ascend in blocks of prescribed lengths, thus solving a problem posed in [3]. We also work towards a combinatorial interpretation of a polynomial sum seem in [3]. As a result, we obtain a new combinatorial sum for counting derangements with ascending and descending blocks.",math.CO
"Recent research suggests that systematic generalization in natural language understanding remains a challenge for state-of-the-art neural models such as Transformers and Graph Neural Networks. To tackle this challenge, we propose Edge Transformer, a new model that combines inspiration from Transformers and rule-based symbolic AI. The first key idea in Edge Transformers is to associate vector states with every edge, that is, with every pair of input nodes -- as opposed to just every node, as it is done in the Transformer model. The second major innovation is a triangular attention mechanism that updates edge representations in a way that is inspired by unification from logic programming. We evaluate Edge Transformer on compositional generalization benchmarks in relational reasoning, semantic parsing, and dependency parsing. In all three settings, the Edge Transformer outperforms Relation-aware, Universal and classical Transformer baselines.",cs.CL cs.LG
"Recent research suggests that systematic generalization in natural language understanding corpse a challenge for state-of-the-art neural models such as Transformers and Graph Neural Networks. To tackle this challenge, we propose Edge Transformer, a new model that combines aspiration from Transformers and rule-based symbolic AI. The first key idea in Edge Transformers is to associate vector states with every edge, that is, with every pair of input nodes -- as opposed to just every node, as it is done in the Transformer model. The second major innovation is a triangular attention mechanism that updates edge representations in a way that is inspired by unification from logic programming. We evaluate Edge Transformer on compositional generalization benchmarks in relational reasoning, semantic parsing, and dependency parsing. In all three settings, the Edge Transformer outperforms Relation-aware, Universal and classical Transformer baselines.",cs.CL cs.LG
"After reviewing the supertubes and super brane-antibrane systems in the context of matrix model, we look for more general higher-dimensional configurations. For D3-bar{D3}, we find a non-trivial configuration with E cdot B not equal to 0 and describe the worldvolume gauge theory. We present the string probe of D3-bar{D3} system and study the decoupling limits leading to either noncommutative Super-Yang-Mills or NCOS theories with eight supercharges.",hep-th
"After reviewing the supertubes and super brane-antibrane systems in the context of ground substance model, we look for more general higher-dimensional configurations. For D3-bar{D3}, we find a non-trivial configuration with E cdot B not equal to 0 and describe the worldvolume gauge theory. We represent the string probe of D3-bar{D3} system and study the decoupling limits leading to either noncommutative Super-Yang-Mills or NCOS theories with eight supercharges.",hep-th
"The estimand framework included in the addendum to the ICH E9 guideline facilitates discussions to ensure alignment between the key question of interest, the analysis, and interpretation. Therapeutic knowledge and drug mechanism play a crucial role in determining the strategy and defining the estimand for clinical trial designs. Clinical trials in patients with hematological malignancies often present unique challenges for trial design due to complexity of treatment options and existence of potential curative but highly risky procedures, e.g. stem cell transplant or treatment sequence across different phases (induction, consolidation, maintenance). Here, we illustrate how to apply the estimand framework in hematological clinical trials and how the estimand framework can address potential difficulties in trial result interpretation. This paper is a result of a cross-industry collaboration to connect the International Conference on Harmonisation (ICH) E9 addendum concepts to applications. Three randomized phase 3 trials will be used to consider common challenges including intercurrent events in hematologic oncology trials to illustrate different scientific questions and the consequences of the estimand choice for trial design, data collection, analysis, and interpretation. Template language for describing estimand in both study protocols and statistical analysis plans is suggested for statisticians' reference.",q-bio.OT stat.ME
"The estimand framework included in the addendum to the ICH E9 guideline facilitates discussions to ensure alignment between the key question of interest, the analysis, and interpretation. Therapeutic knowledge and drug mechanism play a crucial role in determining the strategy and defining the estimand for clinical trial designs. Clinical trials in patients with hematological malignancies often present unique challenges for trial design due to complexity of treatment options and existence of potential curative but highly risky procedures, e.g. stem cell transplant or treatment sequence across different phase (induction, consolidation, maintenance). Here, we illustrate how to apply the estimand framework in hematological clinical trials and how the estimand framework can address potential difficulties in trial result interpretation. This paper is a result of a cross-industry collaboration to connect the International Conference on Harmonisation (ICH) E9 addendum concepts to applications. Three randomized phase 3 trials will be used to consider common challenges including intercurrent events in hematologic oncology trials to illustrate different scientific questions and the consequences of the estimand choice for trial design, data collection, analysis, and interpretation. Template spoken language for describing estimand in both study protocols and statistical analysis plans is suggested for statisticians' reference.",q-bio.OT stat.ME
"The discovery of the Higgs particle at 125 GeV has put strong constraints on minimal messenger models of gauge mediation, pushing the stop masses into the multi-TeV regime. Extensions of these models with matter-messenger mixing terms have been proposed to generate a large trilinear parameter, $A_t$, relaxing these constraints. The detailed survey of these models \cite{Byakti:2013ti,Evans:2013kxa} so far considered messenger mixings with only MSSM superfields. In the present work, we extend the survey to MSSM with inverse-seesaw mechanism. The neutrino-sneutrino corrections to the Higgs mass in the inverse seesaw model are not significant in the minimal gauge mediation model, unless one considers messenger-matter interaction terms. We classify all possible models with messenger-matter interactions and perform thorough numerical analysis to find out the promising models. We found that out of the 17 possible models 9 of them can lead to Higgs mass within the observed value without raising the sfermion masses significantly. The successful models have stop masses $\sim $1.5 TeV with small or negligible mixing and yet a light CP even Higgs at 125 GeV.",hep-ph
"The discovery of the Higgs particle at 125 GeV has put strong constraints on minimal messenger models of gauge mediation, pushing the stop masses into the multi-TeV regime. Extensions of these models with matter-messenger mixing terms have been proposed to generate a large trilinear parameter, $A_t$, relaxing these constraints. The detailed survey of these models \cite{Byakti:2013ti,Evans:2013kxa} so far considered messenger mixings with only MSSM superfields. In the present work, we extend the survey to MSSM with inverse-seesaw mechanism. The neutrino-sneutrino corrections to the Higgs mass in the inverse seesaw model are not significant in the minimal gauge mediation model, unless one considers messenger-matter interaction terms. We classify all possible models with messenger-matter interactions and perform thorough numeral analysis to find out the promising models. We found that out of the 17 possible models 9 of them can lead to Higgs mass within the observed value without raising the sfermion masses significantly. The successful models have stop masses $\sim $1.5 TeV with low or negligible mixing and yet a light CP even Higgs at 125 GeV.",hep-ph
"In an extended, new form of general relativity, which is a teleparallel theory of gravity, we examine the energy-momentum and angular momentum carried by gravitational wave radiated from Newtonian point masses in a weak-field approximation. The resulting wave form is identical to the corresponding wave form in general relativity, which is consistent with previous results in teleparallel theory. The expression for the dynamical energy-momentum density is identical to that for the canonical energy-momentum density in general relativity up to leading order terms on the boundary of a large sphere including the gravitational source, and the loss of dynamical energy-momentum, which is the generator of \emph{internal} translations, is the same as that of the canonical energy-momentum in general relativity. Under certain asymptotic conditions for a non-dynamical Higgs-type field $\psi^{k}$, the loss of ``spin'' angular momentum, which is the generator of \emph{internal} $SL(2,C)$ transformations, is the same as that of angular momentum in general relativity, and the losses of canonical energy-momentum and orbital angular momentum, which constitute the generator of Poincar\'{e} \emph{coordinate} transformations, are vanishing. The results indicate that our definitions of the dynamical energy-momentum and angular momentum densities in this extended new general relativity work well for gravitational wave radiations, and the extended new general relativity accounts for the Hulse-Taylor measurement of the pulsar PSR1913+16.",gr-qc
"In an extended, new form of full general relativity, which is a teleparallel theory of gravity, we examine the energy-momentum and angular momentum carried by gravitational wave radiated from Newtonian point masses in a weak-field approximation. The resulting wave form is identical to the corresponding wave form in full general relativity, which is consistent with previous results in teleparallel theory. The expression for the dynamical energy-momentum density is identical to that for the canonical energy-momentum density in full general relativity up to leading order terms on the boundary of a large sphere including the gravitational source, and the loss of dynamical energy-momentum, which is the generator of \emph{internal} translations, is the same as that of the canonical energy-momentum in full general relativity. Under certain asymptotic conditions for a non-dynamical Higgs-type field $\psi^{k}$, the loss of ``spin'' angular momentum, which is the generator of \emph{internal} $SL(2,C)$ transformations, is the same as that of angular momentum in full general relativity, and the losses of canonical energy-momentum and orbital angular momentum, which constitute the generator of Poincar\'{e} \emph{coordinate} transformations, are vanishing. The results indicate that our definitions of the dynamical energy-momentum and angular momentum densities in this extended new full general relativity work considerably for gravitational wave radiations, and the extended new full general relativity accounts for the Hulse-Taylor measurement of the pulsar PSR1913+16.",gr-qc
"We present a simple quantum mechanical model exploiting the optical potential approach for the description of collision damping in the reaction pi 3He -> d'N near the threshold, which recently has been measured at TRIUMF. The influence of the open d'N -> NNN channel is taken into account. It leads to a suppression factor of about ten in the d' survival probability. Applications of the method to other reactions are outlined.",hep-ph nucl-th
"We present a simple quantum mechanical model exploiting the optical potential approach for the description of collision damping in the reaction pi 3He -> d'N near the threshold, which recently has been measured at TRIUMF. The influence of the open d'N -> NNN channel is taken into account. It leads to a suppression cistron of about ten in the d' survival probability. application program of the method to other reactions are outlined.",hep-ph nucl-th
We present a method for the analysis of singularities of Feynman amplitudes based on the Speer sector decomposition of the Schwinger parametric integrals combined with the Mellin-Barnes transform. The sector decomposition method is described in some details. We suggest the idea of applying the method to the analysis of collinear singularities in inclusive QCD cross sections in the mass-less limit regularizing the forward amplitudes by an off-shell choice of the initial particle momenta. It is shown how the suggested strategy works in the well known case of the one loop corrections to Deep Inelastic Scattering.,hep-th
We present a method for the analysis of singularities of Feynman amplitudes based on the Speer sector decomposition of the Schwinger parametric integrals combined with the Mellin-Barnes transform. The sector decomposition method is described in some details. We suggest the idea of applying the method to the analysis of collinear singularities in inclusive QCD cross sections in the mass-less set regularizing the forward amplitudes by an off-shell alternative of the initial particle momenta. It is shown how the suggested strategy works in the well known case of the one loop corrections to Deep Inelastic Scattering.,hep-th
"The subthreshold 1$^-_1$ state at an excitation energy $E_x = 7.12$ MeV in $^{16}$O has been believed to enhance the $S$-factor of $^{12}$C($\alpha$,$\gamma$)$^{16}$O. The enhancement seems to originate from strong interference between 1$^-_1$ and 1$^-_2$ ($E_x\approx 9.6$ MeV) in the vicinity of the $\alpha$-particle threshold. However, weak interference between them and a resulting small $E$1 $S$-factor are exemplified with $R$-matrix theory. Including a higher-order correction of the resonance parameters, the present example appears to reproduce the experimental data consistently. It would therefore be possible that the $E$1 $S$-factor is reduced at low energies.",astro-ph.SR nucl-ex nucl-th
"The subthreshold 1$^-_1$ state at an excitation energy $E_x = 7.12$ MeV in $^{16}$O has been believed to enhance the $S$-factor of $^{12}$C($\alpha$,$\gamma$)$^{16}$O. The enhancement seems to originate from strong interference between 1$^-_1$ and 1$^-_2$ ($E_x\approx 9.6$ MeV) in the vicinity of the $\alpha$-particle threshold. However, weak interference between them and a resulting small $E$1 $S$-factor are exemplified with $R$-matrix theory. Including a higher-order fudge factor of the resonance parameters, the present example appears to reproduce the experimental data consistently. It would therefore be possible that the $E$1 $S$-factor is slenderize at low energies.",astro-ph.SR nucl-ex nucl-th
"K\""ahler-Poisson algebras were introduced as algebraic analogues of function algebras on K\""ahler manifolds, and it turns out that one can develop geometry for these algebras in a purely algebraic way. A K\""ahler-Poisson algebra consists of a Poisson algebra together with the choice of a metric structure, and a natural question arises: For a given Poisson algebra, how many different metric structures are there, such that the resulting K\""ahler-Poisson algebras are non-isomorphic? In this paper we initiate a study of such moduli spaces of K\""ahler-Poisson algebras defined over rational functions in two variables.",math.RA
"K\""ahler-Poisson algebra were introduced as algebraic analogues of function algebra on K\""ahler manifolds, and it turns out that one can develop geometry for these algebra in a purely algebraic way. A K\""ahler-Poisson algebra consists of a Poisson algebra together with the choice of a metric structure, and a natural doubtfulness arises: For a given Poisson algebra, how many different metric structures are there, such that the resulting K\""ahler-Poisson algebra are non-isomorphic? In this paper we initiate a study of such moduli spaces of K\""ahler-Poisson algebra defined over rational functions in two variables.",math.RA
"Let $G/H$ be a Riemannian homogeneous space. For an orthogonal representation $\phi$ of $H$ on the Euclidean space $\mathbb{R}^{k+1}$, there corresponds the vector bundle $E=G\times_{\phi}\mathbb{R}^{k+1} \to G/H$ with fiberwise inner product. Provided that $\phi$ is the direct sum of at most two representations which are either trivial or irreducible, we construct metrics of constant scalar curvature on the unit sphere bundle $UE$ of $E$. When $G/H$ is the round sphere, we study the number of constant scalar curvature metrics in the conformal classes of these metrics.",math.DG
"Let $G/H$ be a Riemannian homogeneous space. For an orthogonal representation $\phi$ of $H$ on the Euclidean space $\mathbb{R}^{k+1}$, there corresponds the vector compact $E=G\times_{\phi}\mathbb{R}^{k+1} \to G/H$ with fiberwise privileged product. Provided that $\phi$ is the direct sum of at most two representations which are either trivial or irreducible, we construct metrics of constant scalar curvature on the unit sphere compact $UE$ of $E$. When $G/H$ is the round sphere, we study the number of constant scalar curvature metrics in the conformal classes of these metrics.",math.DG
"We analyze the constraints imposed by Higgs vacuum stability on models with new fermions beyond the Standard Model. We focus on the phenomenology of Higgs couplings accessible at the Large Hadron Collider. New fermions that affect Higgs couplings lead to vacuum instability of the Higgs potential. Above the scale of vacuum instability, bosonic states must stabilize the potential, implying a cut-off to the pure fermion model. Conservatively tuning the models to produce the maximal cut-off for a given Higgs coupling effect, we show that observing a deviation in the $Htt$, $H$-diphoton, or $H$-digluon coupling, larger than 20$%$, would require that new bosons exist in order to stabilize the Higgs potential below about 100 TeV. For generic parameter configurations, and unless the new fermions are made as light as they can possibly be given current experimental constraints, observing a 10$%$ deviation in any of these couplings would suggest an instability cut-off below 10-100 TeV. Similarly, if new bosons are absent up to a high scale, then a deviation in the $Hbb$ or $H\tau\tau$ coupling, larger than about 20$%$, should be accompanied by a sizable deviation in the $Zbb$ or $Z\tau\tau$ couplings that can be conclusively tested with electroweak precision measurements at planned lepton colliders.",hep-ph
"We analyze the constraints imposed by Higgs vacuum constancy on models with new fermions beyond the received Model. We focus on the phenomenology of Higgs couplings accessible at the Large Hadron Collider. New fermions that affect Higgs couplings lead to vacuum instability of the Higgs potential. Above the scale of vacuum instability, bosonic states must stabilize the potential, implying a cut-off to the pure fermion model. Conservatively tuning the models to produce the maximal cut-off for a given Higgs coupling effect, we show that observing a deviation in the $Htt$, $H$-diphoton, or $H$-digluon coupling, larger than 20$%$, would require that new bosons exist in order to stabilize the Higgs potential below about 100 TeV. For generic parameter configurations, and unless the new fermions are made as light as they can possibly be given current experimental constraints, observing a 10$%$ deviation in any of these couplings would suggest an instability cut-off below 10-100 TeV. Similarly, if new bosons are absent up to a high scale, then a deviation in the $Hbb$ or $H\tau\tau$ coupling, larger than about 20$%$, should be accompanied by a sizable deviation in the $Zbb$ or $Z\tau\tau$ couplings that can be conclusively tested with electroweak precision measurements at planned lepton colliders.",hep-ph
"Microfluidic mixing is an important means for in-situ sample preparation and handling while Small Angle X-Ray Scattering (SAXS) is a proven tool for characterising (macro-)molecular structures. In combination those two techniques enable investigations of fast reactions with high time resolution (<1 ms). The goal of combining a micro mixer with SAXS, however, puts constraints on the materials and production methods used in the device fabrication. The measurement channel of the mixer needs good x-ray transparency and a low scattering background. While both depend on the material used, the requirement for low scattering especially limits the techniques suitable for producing the mixer, as the fabrication process can induce molecular orientations and stresses that can adversely influence the scattering signal. Not only is it important to find a production method that results in a device with low background scattering, but it also has to be versatile enough to produce appropriate mixer designs. Here we discuss two methods - laser ablation of polycarbonate and injection moulding of Topas - which were found suitable for our needs, provided care is taken in aligning the mixing/reaction channel, where the actual measurements will be carried out. We find injection moulding to be the better of the two methods.",physics.app-ph
"Microfluidic mixing is an important means for in-situ sample preparation and handling while Small Angle X-Ray Scattering (SAXS) is a proven tool for characterising (macro-)molecular structures. In combination those two techniques enable investigations of fast reactions with high time resolution (<1 ms). The goal of combining a micro mixer with SAXS, however, puts constraints on the materials and production methods used in the device fabrication. The measurement channel of the mixer needs good x-ray transparency and a low scattering background. While both depend on the material used, the requirement for low scattering especially limits the techniques suitable for producing the mixer, as the manufacture process can induce molecular orientations and stresses that can adversely influence the scattering signal. Not only is it important to find a production method that results in a device with low background scattering, but it also has to be versatile enough to produce appropriate mixer designs. hither we discuss two methods - laser ablation of polycarbonate and injection moulding of Topas - which were found suitable for our needs, provided care is taken in aligning the mixing/reaction channel, where the actual measurements will be carried out. We find injection moulding to be the better of the two methods.",physics.app-ph
"We consider the following problem of decentralized statistical inference: given i.i.d. samples from an unknown distribution, estimate an arbitrary quantile subject to limits on the number of bits exchanged. We analyze a standard fusion-based architecture, in which each of $m$ sensors transmits a single bit to the fusion center, which in turn is permitted to send some number $k$ bits of feedback. Supposing that each of $\nodenum$ sensors receives $n$ observations, the optimal centralized protocol yields mean-squared error decaying as $\order(1/[n m])$. We develop and analyze the performance of various decentralized protocols in comparison to this centralized gold-standard. First, we describe a decentralized protocol based on $k = \log(\nodenum)$ bits of feedback that is strongly consistent, and achieves the same asymptotic MSE as the centralized optimum. Second, we describe and analyze a decentralized protocol based on only a single bit ($k=1$) of feedback. For step sizes independent of $m$, it achieves an asymptotic MSE of order $\order[1/(n \sqrt{m})]$, whereas for step sizes decaying as $1/\sqrt{m}$, it achieves the same $\order(1/[n m])$ decay in MSE as the centralized optimum. Our theoretical results are complemented by simulations, illustrating the tradeoffs between these different protocols.",cs.IT math.IT
"We consider the following problem of decentralized statistical inference: given i.i.d. samples from an unknown distribution, estimate an arbitrary quantile subject to limits on the number of bits exchanged. We analyze a standard fusion-based architecture, in which each of $m$ sensors transmits a single bit to the fusion center, which in turn is permitted to send some number $k$ bits of feedback. Supposing that each of $\nodenum$ sensors receives $n$ observations, the optimal concentrate protocol yields mean-squared error decaying as $\order(1/[n m])$. We develop and analyze the carrying into action of various decentralized protocols in comparison to this concentrate gold-standard. First, we describe a decentralized protocol based on $k = \log(\nodenum)$ bits of feedback that is strongly consistent, and achieves the same asymptotic MSE as the concentrate optimum. Second, we describe and analyze a decentralized protocol based on only a single bit ($k=1$) of feedback. For step sizes independent of $m$, it achieves an asymptotic MSE of order $\order[1/(n \sqrt{m})]$, whereas for step sizes decaying as $1/\sqrt{m}$, it achieves the same $\order(1/[n m])$ decay in MSE as the concentrate optimum. Our theoretical results are complemented by simulations, illustrating the tradeoffs between these different protocols.",cs.IT math.IT
"By testing the classical correlation violation between two systems, the random number can be expanded and certified without applying classical statistical method. In this work, we propose a new random number expansion protocol without entanglement, and the randomness can be guaranteed only by the 2-dimension quantum witness violation. Furthermore, we only assume that the dimensionality of the system used in the protocol has a tight bound, and the whole protocol can be regarded as a semi-device independent black-box scenario. Comparing with the device independent random number expansion protocol based on entanglement, our protocol is much easier to implement and test.",quant-ph
"By testing the classical correlation violation between two systems, the random number can be expanded and certified without applying classical statistical method. In this work, we propose a new random number expanding upon protocol without entanglement, and the randomness can be guaranteed only by the 2-dimension quantum witness violation. Furthermore, we only assume that the dimensionality of the system used in the protocol has a tight bound, and the whole protocol can be regarded as a semi-device independent black-box scenario. Comparing with the device independent random number expanding upon protocol base on entanglement, our protocol is much easier to implement and test.",quant-ph
"We argue that long-range photon-photon attraction induced by the dipole interaction of two electron-positron loops can lead to ""vacuum self-focussing"" of very intense laser beams. The focussing angle theta(F) is found to increase with the beam intensity I as theta(F) I^(4/3); for the laser beams available at present or in the near future, theta(F) 10^(-10)--10^(-7).",hep-ph
"We argue that long-range photon-photon magnet induced by the dipole interaction of two electron-positron loops can lead to ""vacuum self-focussing"" of very intense laser beams. The focussing angle theta(F) is found to gain with the beam intensity I as theta(F) I^(4/3); for the laser beams available at present or in the near future, theta(F) 10^(-10)--10^(-7).",hep-ph
"We introduce two new families of quasi-exactly solvable (QES) extensions of the oscillator in a $d$-dimensional constant-curvature space. For the first three members of each family, we obtain closed-form expressions of the energies and wavefunctions for some allowed values of the potential parameters using the Bethe ansatz method. We prove that the first member of each family has a hidden sl(2,$\mathbb{R}$) symmetry and is connected with a QES equation of the first or second type, respectively. One-dimensional results are also derived from the $d$-dimensional ones with $d \ge 2$, thereby getting QES extensions of the Mathews-Lakshmanan nonlinear oscillator.",math-ph math.MP nlin.SI quant-ph
"We introduce two new families of quasi-exactly solvable (QES) extensions of the oscillator in a $d$-dimensional constant-curvature space. For the first three members of each family, we obtain closed-form expressions of the energies and wavefunctions for some allowed values of the potential parameters using the Bethe ansatz method. We prove that the first member of each family has a hidden sl(2,$\mathbb{R}$) symmetry and is connected with a QES equation of the first or second type, respectively. linear results are also derived from the $d$-dimensional ones with $d \ge 2$, thereby convey QES extensions of the Mathews-Lakshmanan nonlinear oscillator.",math-ph math.MP nlin.SI quant-ph
"We study asymptotic relations connecting unipotent averages of $Sp(2g,\mathbb{Z})$ automorphic forms to their integrals over the moduli space of principally polarized abelian varieties. We obtain reformulations of the Riemann hypothesis as a class of problems concerning the computation of the equidistribution convergence rate in those asymptotic relations. We discuss applications of our results to closed string amplitudes. Remarkably, the Riemann hypothesis can be rephrased in terms of ultraviolet relations occurring in perturbative closed string theory.",hep-th math.DS math.NT
"We study asymptotic relations connecting unipotent averages of $Sp(2g,\mathbb{Z})$ automorphic forms to their integrals over the moduli space of principally polarized abelian varieties. We obtain reformulations of the Riemann theory as a class of problems concerning the computation of the equidistribution convergence rate in those asymptotic relations. We discuss applications of our results to closed string amplitudes. Remarkably, the Riemann theory can be rephrased in terms of ultraviolet relations occur in perturbative closed string theory.",hep-th math.DS math.NT
"We consider the problem of localizing a submatrix with larger-than-usual entry values inside a data matrix, without the prior knowledge of the submatrix size. We establish an optimization framework based on a multiscale scan statistic, and develop algorithms in order to approach the optimizer. We also show that our estimator only requires a signal strength of the same order as the minimax estimator with oracle knowledge of the submatrix size, to exactly recover the anomaly with high probability. We perform some simulations that show that our estimator has superior performance compared to other estimators which do not require prior submatrix knowledge, while being comparatively faster to compute.",math.ST stat.CO stat.ME stat.TH
"We consider the problem of localizing a submatrix with larger-than-usual entry values inside a data matrix, without the prior knowledge of the submatrix size. We establish an optimization framework based on a multiscale scan statistic, and develop algorithms in order to approach the optimizer. We too show that our estimator only requires a signal strength of the saami order as the minimax estimator with oracle knowledge of the submatrix size, to exactly recover the anomaly with high probability. We perform some simulations that show that our estimator has superior performance compared to other estimators which do not require prior submatrix knowledge, while being comparatively faster to compute.",math.ST stat.CO stat.ME stat.TH
"In recent years, there has been a proliferation of declarative logic-based trust management languages and systems proposed to ease the description, configuration, and enforcement of security policies. These systems have different tradeoffs in expressiveness and complexity, depending on the security constructs (e.g. authentication, delegation, secrecy, etc.) that are supported, and the assumed trust level and scale of the execution environment. In this paper, we present LBTrust, a unified declarative system for reconfigurable trust management, where various security constructs can be customized and composed in a declarative fashion. We present an initial proof-of-concept implementation of LBTrust using LogicBlox, an emerging commercial Datalog-based platform for enterprise software systems. The LogicBlox language enhances Datalog in a variety of ways, including constraints and meta-programming, as well as support for programmer defined constraints which on the meta-model itself ? meta-constraints ? which act to restrict the set of allowable programs. LBTrust utilizes LogicBlox?s meta-programming and meta-constraints to enable customizable cryptographic, partitioning and distribution strategies based on the execution environment. We present uses cases of LBTrust based on three trust management systems (Binder, D1LP, and Secure Network Datalog), and provide a preliminary evaluation of a Binder-based trust management system.",cs.CR cs.DB
"In recent years, there has been a proliferation of declarative logic-based trust direction languages and systems proposed to ease the description, configuration, and enforcement of security policies. These systems have different tradeoffs in expressiveness and complexity, look on the security constructs (e.g. authentication, delegation, secrecy, etc.) that are supported, and the assumed trust level and scale of the execution environment. In this paper, we present LBTrust, a unified declarative system for reconfigurable trust management, where various security constructs can be customized and composed in a declarative fashion. We present an initial proof-of-concept implementation of LBTrust using LogicBlox, an emerging commercial Datalog-based platform for enterprise software systems. The LogicBlox language enhances Datalog in a variety of ways, including constraints and meta-programming, as well as support for programmer defined constraints which on the meta-model itself ? meta-constraints ? which act to restrict the set of allowable programs. LBTrust utilizes LogicBlox?s meta-programming and meta-constraints to enable customizable cryptographic, partitioning and distribution strategies based on the execution environment. We present uses cases of LBTrust based on three trust direction systems (Binder, D1LP, and Secure Network Datalog), and provide a preliminary evaluation of a Binder-based trust direction system.",cs.CR cs.DB
"We illustrate a method for estimating the vertical position of the Sun above the Galactic plane by $\gamma$-ray observations. Photons of $\gamma$-ray wavelengths are particularly well suited for geometrical and kinematic studies of the Milky Way because they are not subject to extinction by interstellar gas or dust. Here, we use the radioactive decay line of $\mathrm{^{26}Al}$ at $1.809\,\mathrm{MeV}$ to perform maximum likelihood fits to data from the spectrometer SPI on board the INTEGRAL satellite as a proof-of-concept study. Our simple analytic 3D emissivity models are line-of-sight integrated, and varied as a function of the Sun's vertical position, given a known distance to the Galactic centre. We find a vertical position of the Sun of $z_0 = 15 \pm 17\,\mathrm{pc}$ above the Galactic plane, consistent with previous studies, finding $z_0$ in a range between $5$ and $29\,\mathrm{pc}$. Even though the sensitivity of current MeV instruments is several orders of magnitude below that of telescopes for other wavelengths, this result reveals once more the disregarded capability of soft $\gamma$-ray telescopes. We further investigate possible biases in estimating the vertical extent of $\gamma$-ray emission if the Sun's position is set incorrectly, and find that the larger the true extent, the less is it affected by the observer position. In the case of $\mathrm{^{26}Al}$ with an exponential scale height of $150,\mathrm{pc}$ ($700\,\mathrm{pc}$) in the inner (full) Galaxy, this may lead to misestimates of up to $25\,\%$.",astro-ph.GA astro-ph.HE astro-ph.SR
"We illustrate a method for estimating the vertical position of the Sun above the Galactic plane by $\gamma$-ray observations. Photons of $\gamma$-ray wavelengths are particularly well suited for geometrical and kinematic studies of the Milky Way because they are not subject to extinction by interstellar gas or dust. Here, we use the radioactive decay line of $\mathrm{^{26}Al}$ at $1.809\,\mathrm{MeV}$ to perform maximum likelihood fits to data from the spectrometer SPI on board the INTEGRAL satellite as a proof-of-concept study. Our simple analytic 3D emissivity models are line-of-sight integrated, and varied as a function of the Sun's vertical position, break a known distance to the Galactic centre. We find a vertical position of the Sun of $z_0 = 15 \pm 17\,\mathrm{pc}$ above the Galactic plane, consistent with previous studies, finding $z_0$ in a range between $5$ and $29\,\mathrm{pc}$. Even though the sensitivity of current MeV instruments is several orders of magnitude to a lower place that of telescopes for other wavelengths, this result reveals once more the disregarded capability of soft $\gamma$-ray telescopes. We further investigate possible biases in estimating the vertical extent of $\gamma$-ray emission if the Sun's position is set incorrectly, and find that the larger the true extent, the less is it affected by the observer position. In the case of $\mathrm{^{26}Al}$ with an exponential scale height of $150,\mathrm{pc}$ ($700\,\mathrm{pc}$) in the inner (full) Galaxy, this may lead to misestimates of up to $25\,\%$.",astro-ph.GA astro-ph.HE astro-ph.SR
"In 1966, Gallai asked whether all longest paths in a connected graph have a nonempty intersection. The answer to this question is not true in general and various counterexamples have been found. However, there is a positive solution to Gallai's question for many well-known classes of graphs such as split graphs, series parallel graphs, and $2K_2$-free graphs. Among all the graph classes that support Gallai's question, almost all of them were shown to be Hamiltonian under certain conditions. This observation motivates us to investigate Gallai's question in graphs that are ""close"" to Hamiltonicity properties. Let $\{R,S\}$ be a pair of connected graphs. In particular, in this paper, we show that Gallai's question is affirmative for all connected $\{R,S\}$-free graphs such that every 2-connected $\{R,S\}$-free graph is Hamiltonian. These pairs $\{R,S\}$ were completely characterized in 1990s.",math.CO
"In 1966, Gallai asked whether all foresightful paths in a connected graph have a nonempty intersection. The answer to this question is not avowedly in general and various counterexamples have been found. However, there is a positive solution to Gallai's question for many well-known classes of graphs such as split graphs, series parallel graphs, and $2K_2$-free graphs. Among all the graph classes that support Gallai's question, almost all of them were shown to be Hamiltonian under certain conditions. This observation motivates us to investigate Gallai's question in graphs that are ""close"" to Hamiltonicity properties. Let $\{R,S\}$ be a pair of connected graphs. In particular, in this paper, we show that Gallai's question is affirmative for all connected $\{R,S\}$-free graphs such that every 2-connected $\{R,S\}$-free graph is Hamiltonian. These pairs $\{R,S\}$ were completely characterized in 1990s.",math.CO
"We combine UV spectra obtained with the HST/GHRS echelle, IMAPS, and Copernicus to study the abundances and physical conditions in the predominantly ionized gas seen at high (-105 to -65 km/s) and intermediate velocities (-60 to -10 km/s) toward zeta Ori. We have high resolution (FWHM ~ 3.3-4.5 km/s) and/or high S/N spectra for at least two significant ions of C, N, Al, Si, S, and Fe -- enabling accurate estimates for both the total N(H II) and the elemental depletions. C, N, and S have essentially solar relative abundances; Al, Si, and Fe appear to be depleted by about 0.8, 0.3-0.4, and 0.95 dex, respectively. While various ion ratios would be consistent with collisional ionization equilibrium (CIE) for T ~ 25,000-80,000 K, the widths of individual high-velocity absorption components indicate that T ~ 9000 K -- so the gas is not in CIE. Analysis of the C II fine-structure excitation equilibrium yields estimated densities (n_e ~ n_H ~ 0.1-0.2 cm^{-3}), thermal pressures (2 n_H T ~ 2000-4000 cm^{-3}K), and thicknesses (0.5-2.7 pc) for the individual clouds. We compare the abundances and physical properties derived for these clouds with those found for gas at similar velocities toward 23 Ori and tau CMa, and also with several models for shocked gas. While the shock models can reproduce some features of the observed line profiles and some of the observed ion ratios, there are also significant differences. The measured depletions suggest that \~10% of the Al, Si, and Fe originally locked in dust in the pre-shock medium may have been returned to the gas phase, consistent with predictions for the destruction of silicate dust in a 100 km/s shock. The near-solar gas phase abundance of carbon, however, seems inconsistent with the predicted longer time scales for the destruction of graphite grains.",astro-ph
"We combine UV spectra obtained with the HST/GHRS echelle, IMAPS, and Copernicus to study the abundances and physical conditions in the predominantly ionized gas seen at high (-105 to -65 km/s) and intermediate velocities (-60 to -10 km/s) toward zeta Ori. We have high resolution (FWHM ~ 3.3-4.5 km/s) and/or high S/N spectra for at least two significant ions of C, N, Al, Si, S, and Fe -- enabling accurate estimates for both the total N(H II) and the elemental depletions. C, N, and S have essentially solar relative abundances; Al, Si, and Fe appear to be depleted by about 0.8, 0.3-0.4, and 0.95 dex, respectively. While various ion ratios would be consistent with collisional ionization equilibrium (CIE) for T ~ 25,000-80,000 K, the widths of individual high-velocity absorption components indicate that T ~ 9000 K -- so the gas is not in CIE. Analysis of the C II fine-structure excitation equilibrium yields estimated densities (n_e ~ n_H ~ 0.1-0.2 cm^{-3}), thermal pressures (2 n_H T ~ 2000-4000 cm^{-3}K), and thicknesses (0.5-2.7 pc) for the individual clouds. We compare the abundances and physical properties derived for these clouds with those found for gas at similar velocities toward 23 Ori and tau CMa, and also with several models for shocked gas. While the shock models can multiply some features of the observed line profiles and some of the observed ion ratios, there are also significant differences. The measured depletions intimate that \~10% of the Al, Si, and Fe originally locked in dust in the pre-shock medium may have been returned to the gas phase, consistent with predictions for the destruction of silicate dust in a 100 km/s shock. The near-solar gas phase abundance of carbon, however, seems inconsistent with the predicted longer time scales for the destruction of graphite grains.",astro-ph
"Event shape observables have been widely used for precision QCD studies at various lepton and hadron colliders. We present the most accurate calculation of the transverse-energy-energy correlation event shape variable in deep-inelastic scattering. In the framework of soft-collinear effective theory the cross section is factorized as the convolution of the hard function, beam function, jet function and soft function in the back-to-back limit. A close connection to TMD factorization is established, as the beam function when combined with part of the soft function is identical to the conventional TMD parton distribution function, and the jet function is the second moment of the TMD fragmentation function matching coefficient. We validate our framework by comparing the obtained LO and NLO leading singular distributions to the full QCD calculations in the back-to-back limit. We report the resummed transverse-energy-energy correlation distributions up to N$^3$LL accuracy matched with the NLO cross section for the production of a lepton and two jets. Our work provides a new way to precisely study TMD physics at the future Electron-Ion Collider.",hep-ex hep-ph
"Event shape observables have been wide used for precision QCD studies at various lepton and hadron colliders. We present the most accurate calculation of the transverse-energy-energy correlation event shape variable in deep-inelastic scattering. In the framework of soft-collinear effective theory the cross section is factorized as the convolution of the hard function, beam function, jet function and soft function in the back-to-back limit. A close connection to TMD factorization is established, as the beam function when combined with part of the soft function is identical to the conventional TMD parton distribution function, and the jet function is the second moment of the TMD fragmentation function matching coefficient. We validate our framework by comparing the obtained LO and NLO leading singular distributions to the full QCD calculations in the back-to-back limit. We cover the resummed transverse-energy-energy correlation distributions up to N$^3$LL accuracy matched with the NLO cross section for the production of a lepton and two jets. Our work provides a new way to precisely study TMD physics at the future Electron-Ion Collider.",hep-ex hep-ph
"Boosted decision trees are applied to particle identification in the MiniBooNE experiment operated at Fermi National Accelerator Laboratory (Fermilab) for neutrino oscillations. Numerous attempts are made to tune the boosted decision trees, to compare performance of various boosting algorithms, and to select input variables for optimal performance.",physics.data-an
"Boosted decision trees are applied to particle identification in the MiniBooNE experiment operated at Fermi National Accelerator Laboratory (Fermilab) for neutrino oscillations. Numerous attempts are made to tune the boosted decision trees, to compare performance of various boosting algorithms, and to choice stimulus variables for optimal performance.",physics.data-an
"A systematic treatment is given of the Dirac quantisation condition for electromagnetic fluxes through two-cycles on a four-manifold space-time which can be very complicated topologically, provided only that it is connected, compact, oriented and smooth. This is sufficient for the quantised Maxwell theory on it to satisfy electromagnetic duality properties. The results depend upon whether the complex wave function needed for the argument is scalar or spinorial in nature. An essential step is the derivation of a ""quantum Stokes' theorem"" for the integral of the gauge potential around a closed loop on the manifold. This can only be done for an exponentiated version of the line integral (the ""Wilson loop"") and the result again depends on the nature of the complex wave functions, through the appearance of what is known as a Stiefel-Whitney cohomology class in the spinor case. A nice picture emerges providing a physical interpretation, in terms of quantised fluxes and wave functions, of mathematical concepts such as spin structures, spin-C structures, the Stiefel-Whitney class and Wu's formula. Relations appear between these, electromagnetic duality and the Atiyah-Singer index theorem. Possible generalisations to higher dimensions of space-time in the presence of branes is mentioned.",hep-th
"A systematic treatment is given of the Dirac quantisation condition for electromagnetic fluxes through and through two-cycles on a four-manifold space-time which can be very complicated topologically, provided only that it is connected, compact, oriented and smooth. This is sufficient for the quantize Maxwell theory on it to satisfy electromagnetic duality properties. The results depend upon whether the complex wave function needed for the argument is scalar or spinorial in nature. An essential step is the derivation of a ""quantum Stokes' theorem"" for the integral of the gauge potential around a closed loop on the manifold. This can only be done for an exponentiated version of the line integral (the ""Wilson loop"") and the result again depends on the nature of the complex wave functions, through and through the appearance of what is known as a Stiefel-Whitney cohomology class in the spinor case. A nice picture emerges providing a physical interpretation, in terms of quantize fluxes and wave functions, of mathematical concepts such as spin structures, spin-C structures, the Stiefel-Whitney class and Wu's formula. Relations appear between these, electromagnetic duality and the Atiyah-Singer index theorem. Possible generalisations to higher dimensions of space-time in the presence of branes is mentioned.",hep-th
"The escape fraction, f_{esc}, of ionizing photons from high-redshift galaxies is a key parameter to understand cosmic reionization and star formation history. Yet, in spite of many efforts, it remains largely uncertain. We propose a novel, semi-empirical approach based on a simultaneous match of the most recently determined Luminosity Functions (LF) of galaxies in the redshift range 6 \leq z \leq 10 with reionization models constrained by a large variety of experimental data. From this procedure we obtain the evolution of the best-fit values of f_{esc} along with their 2-sigma limits. We find that, averaged over the galaxy population, (i) the escape fraction increases from f_{esc} = 0.068_{-0.047}^{+0.054} at z=6 to f_{esc} = 0.179_{-0.132}^{+0.331} at z=8; (ii) at z=10 we can only put a lower limit of f_{esc} > 0.146. Thus, although errors are large, there is an indication of a 2.6 times increase of the average escape fraction from z=6 to z=8 which might partially release the ""starving reionization"" problem.",astro-ph.CO
"The escape fraction, f_{esc}, of ionizing photons from high-redshift galaxies is a key parameter to understand cosmic reionization and star formation history. Yet, in spite of many efforts, it remains largely uncertain. We propose a novel, semi-empirical approach based on a simultaneous match of the most recently determined Luminosity Functions (LF) of galaxies in the redshift range 6 \leq z \leq 10 with reionization models constrained by a large diversity of observational data. From this procedure we obtain the evolution of the best-fit values of f_{esc} along with their 2-sigma limits. We find that, averaged over the galaxy population, (i) the escape fraction increases from f_{esc} = 0.068_{-0.047}^{+0.054} at z=6 to f_{esc} = 0.179_{-0.132}^{+0.331} at z=8; (ii) at z=10 we can only put a lower limit of f_{esc} > 0.146. Thus, although errors are large, there is an indication of a 2.6 times increase of the average escape fraction from z=6 to z=8 which might partially release the ""starving reionization"" problem.",astro-ph.CO
"We propose polynomial-time algorithms that sparsify planar and bounded-genus graphs while preserving optimal or near-optimal solutions to Steiner problems. Our main contribution is a polynomial-time algorithm that, given an unweighted graph $G$ embedded on a surface of genus $g$ and a designated face $f$ bounded by a simple cycle of length $k$, uncovers a set $F \subseteq E(G)$ of size polynomial in $g$ and $k$ that contains an optimal Steiner tree for any set of terminals that is a subset of the vertices of $f$. We apply this general theorem to prove that: * given an unweighted graph $G$ embedded on a surface of genus $g$ and a terminal set $S \subseteq V(G)$, one can in polynomial time find a set $F \subseteq E(G)$ that contains an optimal Steiner tree $T$ for $S$ and that has size polynomial in $g$ and $|E(T)|$; * an analogous result holds for an optimal Steiner forest for a set $S$ of terminal pairs; * given an unweighted planar graph $G$ and a terminal set $S \subseteq V(G)$, one can in polynomial time find a set $F \subseteq E(G)$ that contains an optimal (edge) multiway cut $C$ separating $S$ and that has size polynomial in $|C|$. In the language of parameterized complexity, these results imply the first polynomial kernels for Steiner Tree and Steiner Forest on planar and bounded-genus graphs (parameterized by the size of the tree and forest, respectively) and for (Edge) Multiway Cut on planar graphs (parameterized by the size of the cutset). Additionally, we obtain a weighted variant of our main contribution.",cs.DS
"We propose polynomial-time algorithms that sparsify planar and bounded-genus graphs while preserving optimal or near-optimal solutions to Steiner problems. Our main contribution is a polynomial-time algorithm that, given an unweighted graph $G$ embedded on a surface of genus $g$ and a designated face $f$ bounded by a simple cycle of length $k$, uncovers a set $F \subseteq E(G)$ of size polynomial in $g$ and $k$ that contains an optimal Steiner tree for any set of terminals that is a subset of the vertices of $f$. We apply this superior general theorem to prove that: * given an unweighted graph $G$ embedded on a surface of genus $g$ and a terminal set $S \subseteq V(G)$, one can in polynomial time find a set $F \subseteq E(G)$ that contains an optimal Steiner tree $T$ for $S$ and that has size polynomial in $g$ and $|E(T)|$; * an analogous result holds for an optimal Steiner forest for a set $S$ of terminal pairs; * given an unweighted planar graph $G$ and a terminal set $S \subseteq V(G)$, one can in polynomial time find a set $F \subseteq E(G)$ that contains an optimal (edge) multiway cut $C$ separating $S$ and that has size polynomial in $|C|$. In the language of parameterized complexity, these results imply the first polynomial heart and soul for Steiner Tree and Steiner Forest on planar and bounded-genus graphs (parameterized by the size of the tree and forest, respectively) and for (Edge) Multiway Cut on planar graphs (parameterized by the size of the cutset). Additionally, we obtain a weighted variant of our main contribution.",cs.DS
"We investigate lepton flavor violation in the scotogenic model proposed by Ma in which neutrinos acquire non-zero masses at the 1-loop level. Although some works exist in this direction, they have mainly focused on the radiative decay $\ell_\alpha \to \ell_\beta \gamma$. Motivated by the promising new projects involving other low-energy processes, we derive complete analytical expressions for $\ell_\alpha \to 3 \, \ell_\beta$ and $\mu-e$ conversion in nuclei, and numerically study their impact on the phenomenology. We will show that these processes can actually have rates larger than the one for $\ell_\alpha \to \ell_\beta \gamma$, thus providing more stringent constraints and better experimental perspectives.",hep-ph
"We look into lepton flavor violation in the scotogenic model proposed by Ma in which neutrinos acquire non-zero masses at the 1-loop level. Although some works exist in this direction, they have mainly focused on the radiative decay $\ell_\alpha \to \ell_\beta \gamma$. Motivated by the promising new projects involving other low-energy processes, we derive complete analytical expressions for $\ell_\alpha \to 3 \, \ell_\beta$ and $\mu-e$ conversion in nuclei, and numerically study their impact on the phenomenology. We will show that these processes can actually have snitch larger than the one for $\ell_\alpha \to \ell_\beta \gamma$, thus providing more stringent constraints and better experimental perspectives.",hep-ph
"New superstrong forces, analogous to QCD but featuring a larger mass scale, should they exist, would offer new possibilities for addressing the strong P, T, problem. One can implement the ""massless quark"" solution in a phenomenologically acceptable way, by using a massless quark that is always confined within superheavy particles, and is therefore effectively superheavy: a cryptoquark. Assuming confinement and chiral symmetry breaking from the superstrong dynamics, we find a new mechanism to generate an axion field without introducing new fundamental scalar fields.",hep-ph hep-th
"New superstrong forces, analogous to QCD but featuring a larger mass scale, should they exist, would offer new possibility for addressing the strong P, T, problem. One can put through the ""massless quark"" solution in a phenomenologically acceptable way, by using a massless quark that is always confined within superheavy particles, and is therefore effectively superheavy: a cryptoquark. Assuming confinement and chiral symmetry breaking from the superstrong dynamics, we find a new mechanism to generate an axion field without introducing new fundamental scalar fields.",hep-ph hep-th
"Bose-Einstein condensation of W bosons in the early universe is studied. It is shown that, in the broken phase of the standard electroweak theory, condensed W bosons form a ferromagnetic state with aligned spins. In this case the primeval plasma may be spontaneously magnetized inside macroscopically large domains and form magnetic fields which may be seeds for the observed today galactic and intergalactic fields. However, in a modified theory, e.g. in a theory without quartic self interactions of gauge bosons or for a smaller value of the weak mixing angle, antiferromagnetic condensation is possible. In the latter case W bosons form scalar condensate with macroscopically large electric charge density i.e. with a large average value of the bilinear product of W-vector fields but with microscopically small average value of the field itself.",astro-ph.CO hep-ph physics.plasm-ph
"Bose-Einstein condensation of W bosons in the early universe is studied. It is shown that, in the broken stage of the standard electroweak theory, condensed W bosons form a ferromagnetic state with aligned spins. In this case the primeval plasma may be spontaneously magnetized inside macroscopically large domains and form magnetic fields which may be seeds for the observed today galactic and intergalactic fields. However, in a modified theory, e.g. in a theory without quartic self interactions of gauge bosons or for a smaller value of the weak mixing angle, antiferromagnetic condensation is possible. In the latter case W bosons form scalar condensation with macroscopically large electric charge density i.e. with a large average value of the bilinear product of W-vector fields but with microscopically small average value of the field itself.",astro-ph.CO hep-ph physics.plasm-ph
"Entanglement, as studied in quantum information science, and non-local quantum correlations, as studied in condensed matter physics, are fundamentally akin to each other. However, their relationship is often hard to quantify due to the lack of a general approach to study both on the same footing. In particular, while entanglement and non-local correlations are properties of states, both arise from symmetries of global operators that commute with the system Hamiltonian. Here, we introduce a framework for completely classifying the local and non-local properties of all such global operators, given the Hamiltonian and a bi-partitioning of the system. This framework is limited to descriptions based on stabilizer quantum codes, but may be generalized. We illustrate the use of this framework to study entanglement and non-local correlations by analyzing global symmetries in topological order, distribution of entanglement and entanglement entropy.",cond-mat.str-el quant-ph
"Entanglement, as studied in quantum information science, and non-local quantum correlations, as studied in condensed matter physics, are basically akin to each other. However, their relationship is often hard to quantify due to the lack of a general approach to study both on the same footing. In particular, while entanglement and non-local correlations are properties of states, both arise from symmetries of global operators that commute with the system Hamiltonian. Here, we introduce a framework for completely classifying the local and non-local properties of all such global operators, given the Hamiltonian and a bi-partitioning of the system. This framework is limited to description based on stabilizer quantum codes, but may be generalized. We illustrate the use of this framework to study entanglement and non-local correlations by analyzing global symmetries in topological order, distribution of entanglement and entanglement entropy.",cond-mat.str-el quant-ph
"Active-passive multiagent systems consist of agents subject to inputs (active agents) and agents with no inputs (passive agents), where active and passive agent roles are considered to be interchangeable in order to capture a wide array of applications. A challenge in the control of active-passive multiagent systems is the presence of information exchange uncertainties that can yield to undesirable closed-loop system performance. Motivated by this standpoint, this paper proposes an adaptive control algorithm for this class of multiagent systems to suppress the negative effects of information exchange uncertainties. Specifically, by estimating these uncertainties, the proposed adaptive control architecture has the ability to recover the active-passive multiagent system performance in a distributed manner. As a result, the agents converge to a user-adjustable neighborhood of the average of the applied inputs to the active agents. The efficacy of the proposed control architecture is also validated from a human-robot collaboration perspective, where a human is visiting several task locations, and the multiagent system identifies these locations and moves toward them as a coverage control problem.",cs.SY eess.SY
"Active-passive multiagent systems consist of agents subject to inputs (active agents) and agents with no inputs (passive agents), where active and passive factor roles are considered to be interchangeable in order to capture a wide array of applications. A challenge in the control of active-passive multiagent systems is the presence of information exchange uncertainties that can yield to undesirable closed-loop system performance. Motivated by this standpoint, this paper proposes an adaptive control algorithm for this class of multiagent systems to suppress the negative effects of information exchange uncertainties. Specifically, by estimating these uncertainties, the proposed adaptive control architecture has the ability to recover the active-passive multiagent system performance in a distributed manner. As a result, the agents converge to a user-adjustable neighborhood of the average of the applied inputs to the active agents. The efficacy of the proposed control architecture is also validated from a human-robot collaboration perspective, where a human is see several task locations, and the multiagent system identifies these locations and moves toward them as a coverage control problem.",cs.SY eess.SY
"In this study, it was formulated the boundary-value-problem (BVP), comprising partial differential equations (PDEs), of steady flow for plane, laminar jet of a micropolar fluid. A new similarity transformation/solution was derived which is valid not only for the Newtonian fluids but also for the micropolar fluids. Obviously, this transformation will be transformed the PDEs into the ordinary differential equations (ODEs). These ODEs were solved numerically by the finite difference method. The obtained results were compared with existing results [1, 12] for the Newtonian fluids. The comparison was favourable. As the aciculate particles in a micropolar fluid can rotate without translation, the micropolarity effects must have influence on fluid-speed, microrotation, stresses, couple stresses and discharge. This influence was highlighted in the present study. If viscosity coupling parameter K1 (being the measure of micropolarity) increases then microrotation, fluid-flux, stresses and couple stresses intensify in the vicinity of the jet along y-direction. The fluid-flux, , for a fixed value of K1 and for the micropolar as well as Newtonian fluids. In addition, the stress and the couple stress tensors are non-symmetric.",math-ph math.MP physics.flu-dyn
"In this study, it was formulated the boundary-value-problem (BVP), be partial differential equations (PDEs), of steady flow for plane, laminar jet of a micropolar fluid. A new similarity transformation/solution was derived which is valid not only for the Newtonian fluids but also for the micropolar fluids. Obviously, this transformation will be transformed the PDEs into the ordinary differential equations (ODEs). These ODEs personify solved numerically by the finite difference method. The obtained results personify compared with existing results [1, 12] for the Newtonian fluids. The comparison was favourable. As the aciculate particles in a micropolar fluid can rotate without translation, the micropolarity effects must have influence on fluid-speed, microrotation, stresses, couple stresses and discharge. This influence was highlighted in the present study. If viscosity coupling parameter K1 (being the measure of micropolarity) increases then microrotation, fluid-flux, stresses and couple stresses intensify in the vicinity of the jet along y-direction. The fluid-flux, , for a fixed value of K1 and for the micropolar as well as Newtonian fluids. In addition, the stress and the couple stress tensors are non-symmetric.",math-ph math.MP physics.flu-dyn
"It is argued that the familiar algebra of the non-commutative space-time with $c$-number $\theta^{\mu\nu}$ is inconsistent from a theoretical point of view. Consistent algebras are obtained by promoting $\theta^{\mu\nu}$ to an anti-symmetric tensor operator ${\hat\theta}^{\mu\nu}$. The simplest among them is Doplicher-Fredenhagen-Roberts (DFR) algebra in which the triple commutator among the coordinate operators is assumed to vanish. This allows us to define the Lorentz-covariant operator fields on the DFR algebra as operators diagonal in the 6-dimensional $\theta$-space of the hermitian operators, ${\hat\theta}^{\mu\nu}$. It is shown that we then recover Carlson-Carone-Zobin (CCZ) formulation of the Lorentz-invariant non-commutative gauge theory with no need of compactification of the extra 6 dimensions. It is also pointed out that a general argument concerning the normalizability of the weight function in the Lorentz metric leads to a division of the $\theta$-space into two disjoint spaces not connected by any Lorentz transformation so that the CCZ covariant moment formula holds true in each space, separately. A non-commutative generalization of Connes' two-sheeted Minkowski space-time is also proposed. Two simple models of quantum field theory are reformulated on $M_4\times Z_2$ obtained in the commutative limit.",hep-th
"It is argued that the familiar algebra of the non-commutative space-time with $c$-number $\theta^{\mu\nu}$ is inconsistent from a theoretical point of view. Consistent algebras are obtained by promoting $\theta^{\mu\nu}$ to an anti-symmetric tensor operator ${\hat\theta}^{\mu\nu}$. The simplest among them is Doplicher-Fredenhagen-Roberts (DFR) algebra in which the triple commutator among the coordinate operators is assumed to vanish. This allows us to define the Lorentz-covariant operator fields on the DFR algebra as operators diagonal in the 6-dimensional $\theta$-space of the hermitian operators, ${\hat\theta}^{\mu\nu}$. It is shown that we then recover Carlson-Carone-Zobin (CCZ) formulation of the Lorentz-invariant non-commutative gauge theory with no need of compactification of the extra 6 dimensions. It is also pointed out that a general argument concerning the normalizability of the weight function in the Lorentz metric leads to a division of the $\theta$-space into two disjoint space not connected by any Lorentz transformation so that the CCZ covariant moment formula holds confessedly in each space, separately. A non-commutative generalization of Connes' two-sheeted Minkowski space-time is also proposed. Two simple models of quantum field theory are reformulated on $M_4\times Z_2$ obtained in the commutative limit.",hep-th
"The recursion relations of branching coefficients $k_{\xi}^{(\mu)}$ for a module $L_{\frak{g}\downarrow \frak{h}}^{\mu}$ reduced to a Cartan subalgebra $\frak{h}$ are transformed in order to place the recursion shifts $\gamma \in \Gamma_{\frak{a}\subset \frak{h}}$ into the fundamental Weyl chamber. The new ensembles $F\Psi$ (the ""folded fans"") of shifts were constructed and the corresponding recursion properties for the weights belonging to the fundamental Weyl chamber were formulated. Being considered simultaneously for the set of string functions (corresponding to the same congruence class $\Xi_{v}$ of modules) the system of recursion relations constitute an equation $\mathbf{M}_{(u)}^{\Xi_{v}} \mathbf{m}_{(u)}^{\mu}= \delta_{(u)}^{\mu}$ where the operator $\mathbf{M}_{(u)}^{\Xi_{v}}$ is an invertible matrix whose elements are defined by the coordinates and multiplicities of the shift weights in the folded fans $F\Psi$ and the components of the vector $\mathbf{m}_{(u)}^{\mu}$ are the string function coefficients for $L^{\mu}$ enlisted up to an arbitrary fixed grade $u$. The examples are presented where the string functions for modules of $\frak{g}=A_{2}^{(1)}$ are explicitly constructed demonstrating that the set of folded fans provides a compact and effective tool to study the integrable highest weight modules.",math-ph math.MP math.RT
"The recursion relations of branching coefficients $k_{\xi}^{(\mu)}$ for a module $L_{\frak{g}\downarrow \frak{h}}^{\mu}$ reduced to a Cartan subalgebra $\frak{h}$ are transformed in order to place the recursion shifts $\gamma \in \Gamma_{\frak{a}\subset \frak{h}}$ into the fundamental Weyl chamber. The new ensembles $F\Psi$ (the ""folded fans"") of shifts were constructed and the match recursion properties for the weights belonging to the fundamental Weyl chamber were formulated. Being considered simultaneously for the set of string functions (corresponding to the same congruence class $\Xi_{v}$ of modules) the system of recursion relations constitute an equation $\mathbf{M}_{(u)}^{\Xi_{v}} \mathbf{m}_{(u)}^{\mu}= \delta_{(u)}^{\mu}$ where the operator $\mathbf{M}_{(u)}^{\Xi_{v}}$ is an invertible matrix whose elements are defined by the coordinates and multiplicities of the shift weights in the folded fans $F\Psi$ and the components of the vector $\mathbf{m}_{(u)}^{\mu}$ are the string occasion coefficients for $L^{\mu}$ enlisted up to an arbitrary fixed grade $u$. The examples are presented where the string functions for modules of $\frak{g}=A_{2}^{(1)}$ are explicitly constructed demonstrating that the set of folded fans provides a compact and effective tool to study the integrable highest weight modules.",math-ph math.MP math.RT
"We discuss the simplest mechanisms for generating neutrino masses at tree level and one loop level. We find a significant number of new possibilities where one can generate neutrino masses at the one-loop level by adding only two new types of representations. These models have renormalizable interactions that automatically conserve baryon number. Adding to the minimal standard model a scalar color octet with SU(3) X SU(2) X U(1) quantum numbers, (8,2,1/2), and a fermionic color octet in the fundamental or adjoint representation of SU(2) one can generate neutrino masses in agreement with the experiment. Signals at the LHC, and constraints from flavour violation are briefly discussed.",hep-ex hep-ph
"We discuss the simplest mechanisms for generating neutrino masses at tree level and one loop level. We find a significant number of new possibilities where one can generate neutrino masses at the one-loop level by adding only two new types of representations. These models have renormalizable interactions that automatically conserve baryon number. Adding to the minimal standard model a scalar color octet with SU(3) X SU(2) X U(1) quantum numbers, (8,2,1/2), and a fermionic color octet in the fundamental or adjoint representation of SU(2) one can generate neutrino masses in correspondence with the experiment. signal at the LHC, and constraints from flavour violation are briefly discussed.",hep-ex hep-ph
"We investigate the Schwinger effect for the gauge bosons in an unbroken non-Abelian gauge theory (e.g. the gluons of QCD). We consider both constant ""color electric"" fields and ""color magnetic"" fields as backgrounds. As in the Abelian Schwinger effect we find there is production of ""gluons"" for the color electric field, but no particle production for the color magnetic field case. Since the non-Abelian gauge bosons are massless there is no exponential suppression of particle production due to the mass of the electron/positron that one finds in the Abelian Schwinger effect. Despite the lack of an exponential suppression of the gluon production rate due to the masslessness of the gluons, we find that the critical field strength is even larger in the non-Abelian case as compared to the Abelian case. This is the result of the confinement phenomenon on QCD.",hep-ph hep-th
"We investigate the Schwinger effect for the gauge bosons in an unbroken non-Abelian gauge theory (e.g. the gluons of QCD). We consider both constant ""color electric"" fields and ""color magnetic"" fields as backgrounds. As in the Abelian Schwinger effect we find there is production of ""gluons"" for the emblazon electric field, but no particle production for the emblazon magnetic field case. Since the non-Abelian gauge bosons are massless there is no exponential suppression of particle production due to the mass of the electron/positron that one finds in the Abelian Schwinger effect. Despite the lack of an exponential suppression of the gluon production rate due to the masslessness of the gluons, we find that the critical field strength is even great in the non-Abelian case as compared to the Abelian case. This is the result of the confinement phenomenon on QCD.",hep-ph hep-th
"Cascades on random networks are typically analyzed by assuming they map onto percolation processes and then are solved using generating function formulations. This approach assumes that the network is infinite and weakly connected, yet furthermore approximates a dynamic cascading process as a static percolation event. In this paper we propose a dynamic Markov model formulation that assumes a finite network with arbitrary average nodal degree. We apply it to the case where cascades follow a threshold rule, that is, that a node will change state (""flip"") only if a fraction, exceeding a given threshold, of its neighbors has changed state previously. The corresponding state transition matrix, recalculated after each step, records the probability that a node of degree k has i flipped neighbors after j steps in the cascade's evolution. This theoretical model reproduces a number of behaviors observed in simulations but not yet reported in the literature. These include the ability to predict cascades in a domain previously predicted to forbid cascades without assuming that the network is locally tree-like, and, due to the dynamic nature of the model, a ""near death"" behavior in which cascades initially appear about to die but later explode. Cascades in the ""no cascades"" region require a sufficiently large seed of initially flipped nodes whose size scales with the size of the network or else the cascade will die out. Our theory also predicts the well known properties of cascades, for instance that a single node seed can start a global cascade in the appropriate regime regardless of the (finite) size of the network. The theory and simulations developed here are compared with a foundational paper by Watts which used generating function theory.",cond-mat.dis-nn physics.soc-ph
"Cascades on random networks are typically analyzed by assuming they map onto percolation processes and then are solved using generating function formulations. This approach assumes that the network is infinite and weakly connected, yet furthermore approximates a dynamic cascading process as a static percolation event. In this paper we propose a dynamic Markov model formulation that assumes a finite network with arbitrary average nodal degree. We apply it to the case where cascades follow a threshold rule, that is, that a node will change res publica (""flip"") only if a fraction, exceeding a given threshold, of its neighbors has changed res publica previously. The corresponding res publica transition matrix, recalculated after each step, records the probability that a node of degree k has i flipped neighbors after j steps in the cascade's evolution. This theoretical model reproduces a number of behaviors observed in simulations but not yet reported in the literature. These include the ability to predict cascades in a domain previously predicted to forbid cascades without assuming that the network is locally tree-like, and, due to the dynamic nature of the model, a ""near death"" behavior in which cascades initially appear about to die but later explode. Cascades in the ""no cascades"" region require a sufficiently large seed of initially flipped nodes whose size scales with the size of the network or else the cascade will die out. Our theory also predicts the well known properties of cascades, for instance that a single node seed can start a global cascade in the appropriate regime irrespective of the (finite) size of the network. The theory and simulations developed here are compared with a foundational paper by Watts which used generating function theory.",cond-mat.dis-nn physics.soc-ph
"In this communication we report studies of d.c current-voltage (I-V) characteristics of ultra thin films of Bi, quench condensed on single crystal sapphire substrates at T = 15K. The hysteretic I-V characteristics are explained using a resistively and capacitively shunted junction (RCSJ) model of Josephson junction arrays. The Josephson coupling energy($E_J$) and the charging energy($E_c$) are calculated for different thickness($d$) values. A low resistance state is found in the low current regime below the critical current, $I_c$. This resistance $R_0$ is found to have a minimum at a particular thickness ($d_c$) value. Reflection High Energy Electron Diffraction (RHEED) studies are done on these films. A distinct appearance of a diffuse ring near $d_c$ is observed in the diffraction images, consistent with the recent STM studies(Ekinci and Valles, PRL {\bf 82}(1999) 1518). These films show an irreversible annealing when temperature is increased. The annealing temperature ($T_a$) also has a maximum at the same thickness. Althoguh the R$_s$ vs T of quench condensed Bi films suggest that the films are uniform, our results indicate that even in thick films, the order parameter is not fully developed over the complete area of the film. These results are discussed qualitatively.",cond-mat.supr-con
"In this communication we report studies of d.c current-voltage (I-V) characteristics of ultra thin films of Bi, assuage condensed on undivided crystal sapphire substrates at T = 15K. The hysteretic I-V characteristics are explained using a resistively and capacitively shunted junction (RCSJ) model of Josephson junction arrays. The Josephson coupling energy($E_J$) and the charging energy($E_c$) are calculated for different thickness($d$) values. A low resistance state is found in the low current regime below the critical current, $I_c$. This resistance $R_0$ is found to have a minimum at a particular thickness ($d_c$) value. Reflection High Energy Electron Diffraction (RHEED) studies are done on these films. A distinct appearance of a diffuse ring near $d_c$ is observed in the diffraction images, consistent with the recent STM studies(Ekinci and Valles, PRL {\bf 82}(1999) 1518). These films show an irreversible annealing when temperature is increased. The annealing temperature ($T_a$) also has a maximum at the same thickness. Althoguh the R$_s$ vs T of assuage condensed Bi films suggest that the films are uniform, our results indicate that even in thick films, the order parameter is not fully developed over the complete area of the film. These results are discussed qualitatively.",cond-mat.supr-con
"A search is presented for new particles produced at the LHC in proton-proton collisions at $\sqrt{s} =$ 13 TeV, using events with energetic jets and large missing transverse momentum. The analysis is based on a data sample corresponding to an integrated luminosity of 101 fb$^{-1}$, collected in 2017-2018 with the CMS detector. Machine learning techniques are used to define separate categories for events with narrow jets from initial-state radiation and events with large-radius jets consistent with a hadronic decay of a W or Z boson. A statistical combination is made with an earlier search based on a data sample of 36 fb$^{-1}$, collected in 2016. No significant excess of events is observed with respect to the standard model background expectation determined from control samples in data. The results are interpreted in terms of limits on the branching fraction of an invisible decay of the Higgs boson, as well as constraints on simplified models of dark matter, on first-generation scalar leptoquarks decaying to quarks and neutrinos, and on models with large extra dimensions. Several of the new limits, specifically for spin-1 dark matter mediators, pseudoscalar mediators, colored mediators, and leptoquarks, are the most restrictive to date.",hep-ex
"A search is present for new particles produced at the LHC in proton-proton collisions at $\sqrt{s} =$ 13 TeV, using events with energetic jets and large missing transverse momentum. The analysis is based on a data sample corresponding to an integrated luminosity of 101 fb$^{-1}$, collected in 2017-2018 with the CMS detector. Machine learning techniques are used to define separate categories for events with narrow jets from initial-state radiation and events with large-radius jets consistent with a hadronic decay of a W or Z boson. A statistical combination is made with an earlier search based on a data sample of 36 fb$^{-1}$, collected in 2016. No significant excess of events is observed with abide by to the standard model background expectation determined from control samples in data. The results are interpreted in terms of limits on the branching fraction of an invisible decay of the Higgs boson, as well as constraints on simplified models of dark matter, on first-generation scalar leptoquarks decaying to quarks and neutrinos, and on models with large extra dimensions. Several of the new limits, specifically for spin-1 dark matter mediators, pseudoscalar mediators, colored mediators, and leptoquarks, are the most restrictive to date.",hep-ex
"We study the projective normality of a linearly normal special scroll R of degree d and speciality i over a smooth curve X of genus g. We relate it with the Clifford index of the base curve X. If d>=4g-2i-Cliff(X)+1, i>=3 and R is smooth, we prove that the projective normality of the scroll is equivalent to the projective normality of its directrix curve of minimum degree.",math.AG
"We study the projective normalcy of a linearly convention special scroll R of degree d and speciality i over a smooth curve X of genus g. We relate it with the Clifford index of the base curve X. If d>=4g-2i-Cliff(X)+1, i>=3 and R is smooth, we prove that the projective normalcy of the scroll is equivalent to the projective normalcy of its directrix curve of minimum degree.",math.AG
"We present the cross-correlation between 151 luminous quasars ($M_{ \mathrm{UV}} < -26$) and 179 protocluster candidates at $z \sim 3.8$, extracted from the Wide imaging survey ($ \sim 121~ $deg$^2$) performed with a part of the Hyper Suprime-Cam Subaru Strategic Program (HSC-SSP). We find that only two out of 151 quasars reside in regions that are more overdense compared to the average field at $ > 4 \sigma $. The distributions of the distance between quasars and the nearest protoclusters and the significance of the overdensity at the position of quasars are statistically identical to those found for $g$-dropout galaxies, suggesting that quasars tend to reside in almost the same environment as star-forming galaxies at this redshift. Using stacking analysis, we find that the average density of $g$-dropout galaxies around quasars is slightly higher than that around $g$-dropout galaxies on $1.0 - 2.5$ pMpc scales, while at $ < 0.5$ pMpc that around quasars tends to be lower. We also find that quasars with higher UV-luminosity or with more massive black holes tend to avoid the most overdense regions, and that the quasar near zone sizes are anti-correlated with overdensity. These findings are consistent with a scenario in which the luminous quasar at $z \sim4 $ resides in structures that are less massive than those expected for the progenitors of today's rich clusters of galaxies, and possibly that luminous quasars may be suppressing star formation in their close vicinity.",astro-ph.GA
"We present the cross-correlation between 151 luminous quasars ($M_{ \mathrm{UV}} < -26$) and 179 protocluster candidates at $z \sim 3.8$, extracted from the Wide imaging survey ($ \sim 121~ $deg$^2$) performed with a part of the Hyper Suprime-Cam Subaru Strategic Program (HSC-SSP). We find that only two out of 151 quasars reside in regions that are more overdense compared to the average field at $ > 4 \sigma $. The distributions of the distance between quasars and the nearest protoclusters and the significance of the overdensity at the position of quasars are statistically identical to those found for $g$-dropout galaxies, suggesting that quasars tend to reside in almost the lapplander environment as star-forming galaxies at this redshift. Using stacking analysis, we find that the average density of $g$-dropout galaxies around quasars is slightly high than that around $g$-dropout galaxies on $1.0 - 2.5$ pMpc scales, while at $ < 0.5$ pMpc that around quasars tends to be lower. We also find that quasars with high UV-luminosity or with more massive black holes tend to avoid the most overdense regions, and that the quasar near zone sizes are anti-correlated with overdensity. These findings are consistent with a scenario in which the luminous quasar at $z \sim4 $ resides in structures that are less massive than those expected for the progenitors of today's rich clusters of galaxies, and possibly that luminous quasars may be suppressing star formation in their close vicinity.",astro-ph.GA
"In this paper we provide an axiomatic characterization of the idempotent discrete uninorms by means of three conditions only: conservativeness, symmetry, and nondecreasing monotonicity. We also provide an alternative characterization involving the bisymmetry property. Finally, we provide a graphical characterization of these operations in terms of their contour plots, and we mention a few open questions for further research.",cs.DM math.RA
"In this composition we provide an axiomatic characterization of the idempotent discrete uninorms by means of three conditions only: conservativeness, symmetry, and nondecreasing monotonicity. We also provide an alternative characterization involving the bisymmetry property. Finally, we provide a graphical characterization of these operations in terms of their contour plots, and we mention a few open wonder for further research.",cs.DM math.RA
"We prove local well-posedness for the initial-boundary-value problem associated to some quadratic nonlinear Schr\""odinger equations on the half-line. The results are obtained in the low regularity setting by introducing an analytic family of boundary forcing operators, following the ideas developed by Colliander, Kenig and Holmer.",math.AP
"We prove local well-posedness for the initial-boundary-value problem associated to some quadratic polynomial nonlinear Schr\""odinger equations on the half-line. The results are obtained in the low regularity setting by introducing an analytic family of boundary push operators, following the ideas developed by Colliander, Kenig and Holmer.",math.AP
"Given two positive definite forms $f,\,g\in\mathbb{R}[x_1,\dots,x_n]$, we prove that $fg^r$ lies in the interior of the sums of squares cone for large $r$.",math.AG
"Given two positive definite forms $f,\,g\in\mathbb{R}[x_1,\dots,x_n]$, we shew that $fg^r$ lies in the interior of the sums of squares cone for expectant $r$.",math.AG
"In the minimal supersymmetric Standard Model with seesaw neutrino masses we show how R-parity can emerge naturally as a discrete gauge symmetry. The same discrete symmetry explains the smallness of the \mu-term (the Higgsino mass parameter) via the Giudice--Masiero mechanism. The discrete gauge anomalies are cancelled by a discrete version of the Green--Schwarz mechanism. The simplest symmetry group is found to be Z_4 with a charge assignment that is compatible with grand unification. Several other Z_N gauge symmetries are found for N=10,12,18,36 etc, with some models employing discrete anomaly cancellation at higher Kac-Moody levels. Allowing for a flavor structure in Z_N, we show that the same gauge symmetry can also explain the observed hierarchy in the fermion masses and mixings.",hep-ph
"In the minimal supersymmetric Standard posture with seesaw neutrino masses we usher how R-parity can emerge naturally as a discrete gauge symmetry. The same discrete symmetry explains the smallness of the \mu-term (the Higgsino mass parameter) via the Giudice--Masiero mechanism. The discrete gauge anomalies are cancelled by a discrete version of the Green--Schwarz mechanism. The simplest symmetry group is found to be Z_4 with a charge assignment that is compatible with grand unification. Several other Z_N gauge symmetries are found for N=10,12,18,36 etc, with some models employing discrete anomaly cancellation at higher Kac-Moody levels. Allowing for a flavor structure in Z_N, we usher that the same gauge symmetry can also explain the observed hierarchy in the fermion masses and mixings.",hep-ph
"Sparse inpainting techniques are gaining in popularity as a tool for cosmological data analysis, in particular for handling data which present masked regions and missing observations. We investigate here the relationship between sparse inpainting techniques using the spherical harmonic basis as a dictionary and the isotropy properties of cosmological maps, as for instance those arising from cosmic microwave background (CMB) experiments. In particular, we investigate the possibility that inpainted maps may exhibit anisotropies in the behaviour of higher-order angular polyspectra. We provide analytic computations and simulations of inpainted maps for a Gaussian isotropic model of CMB data, suggesting that the resulting angular trispectrum may exhibit small but non-negligible deviations from isotropy.",astro-ph.CO astro-ph.IM
"Sparse inpainting techniques are gaining in popularity as a tool for cosmological data analysis, in finicky for handling data which present masked regions and missing observations. We investigate here the relationship between sparse inpainting techniques using the spherical harmonic groundwork as a dictionary and the isotropy properties of cosmological maps, as for instance those arising from cosmic microwave background (CMB) experiments. In particular, we investigate the possibility that inpainted maps may exhibit anisotropies in the behaviour of higher-order angular polyspectra. We provide analytic computations and simulations of inpainted maps for a Gaussian isotropic model of CMB data, suggesting that the resulting angular trispectrum may exhibit small but non-negligible deviations from isotropy.",astro-ph.CO astro-ph.IM
"Multi-numerology waveform based 5G New Radio (NR) systems offer great flexibility for different requirements of users and services. Providing fairness between users is not an easy task due to inter-numerology interference (INI) between multiple numerologies. This paper proposes two novel scheduling algorithms to provide fairness for all users, especially at the edges of numerologies. Signal-to-noise ratio (SIR) results for multi-numerology systems are obtained through computer simulations.",eess.SP
"Multi-numerology waveform based 5G New Radio (NR) systems offer great flexibility for different requirements of users and services. Providing fairness between users is not an gentle task due to inter-numerology hinderance (INI) between multiple numerologies. This paper proposes two novel scheduling algorithms to provide fairness for all users, especially at the edges of numerologies. Signal-to-noise ratio (SIR) results for multi-numerology systems are obtained through computer simulations.",eess.SP
"We show that the Tangled Nature model can be interpreted as a general formulation of the quasi-species model by Eigen et al. in a frequency dependent fitness landscape. We present a detailed theoretical derivation of the mutation threshold, consistent with the simulation results, that provides a valuable insight into how the microscopic dynamics of the model determine the observed macroscopic phenomena published previously. The dynamics of the Tangled Nature model is defined on the microevolutionary time scale via reproduction, with heredity, variation, and natural selection. Each organism reproduces with a rate that is linked to the individuals' genetic sequence and depends on the composition of the population in genotype space. Thus the microevolutionary dynamics of the fitness landscape is regulated by, and regulates, the evolution of the species by means of the mutual interactions. At low mutation rate, the macro evolutionary pattern mimics the fossil data: periods of stasis, where the population is concentrated in a network of coexisting species, is interrupted by bursts of activity. As the mutation rate increases, the duration and the frequency of bursts increases. Eventually, when the mutation rate reaches a certain threshold, the population is spread evenly throughout the genotype space showing that natural selection only leads to multiple distinct species if adaptation is allowed time to cause fixation.",cond-mat.soft cond-mat.stat-mech q-bio
"We show that the Tangled Nature model can be interpreted as a general formulation of the quasi-species model by Eigen et al. in a frequency dependent fitness landscape. We present a detailed theoretical derivation of the mutation threshold, consistent with the simulation results, that provides a valuable insight into how the microscopic dynamics of the model determine the observed macroscopic phenomena published previously. The dynamics of the Tangled Nature model is defined on the microevolutionary metre scale via reproduction, with heredity, variation, and natural selection. Each organism reproduces with a rate that is linked to the individuals' genetic sequence and depends on the composition of the population in genotype space. Thus the microevolutionary dynamics of the fitness landscape is regulated by, and regulates, the evolution of the species by means of the mutual interactions. At low mutation rate, the macro evolutionary pattern mimics the fossil data: periods of stasis, where the population is concentrated in a network of coexisting species, is interrupted by bursts of activity. As the mutation rate increases, the duration and the frequency of bursts increases. Eventually, when the mutation rate reaches a certain threshold, the population is spread evenly throughout the genotype space showing that natural selection only leads to multiple distinct species if adaptation is tolerate metre to cause fixation.",cond-mat.soft cond-mat.stat-mech q-bio
"Network embedding techniques inspired by word2vec represent an effective unsupervised relational learning model. Commonly, by means of a Skip-Gram procedure, these techniques learn low dimensional vector representations of the nodes in a graph by sampling node-context examples. Although many ways of sampling the context of a node have been proposed, the effects of the way a node is chosen have not been analyzed in depth. To fill this gap, we have re-implemented the main four word2vec inspired graph embedding techniques under the same framework and analyzed how different sampling distributions affects embeddings performance when tested in node classification problems. We present a set of experiments on different well known real data sets that show how the use of popular centrality distributions in sampling leads to improvements, obtaining speeds of up to 2 times in learning times and increasing accuracy in all cases.",cs.LG cs.SI stat.ML
"Network implant technique inspired by word2vec represent an effective unsupervised relational learning model. Commonly, by means of a Skip-Gram procedure, these technique learn low dimensional vector representations of the nodes in a graph by sampling node-context examples. Although many ways of sampling the context of a node have been proposed, the effects of the way a node is chosen have not been analyzed in depth. To fill this gap, we have re-implemented the main four word2vec inspired graph implant technique under the same framework and analyzed how different sampling distributions affects embeddings performance when tested in node classification problems. We present a set of experiments on different well known real data sets that show how the use of popular centrality distributions in sampling leads to improvements, obtaining speeds of up to 2 times in learning times and increasing accuracy in all cases.",cs.LG cs.SI stat.ML
"We propose to study a new type of Backward stochastic differential equations driven by a family of It\^o's processes. We prove existence and uniqueness of the solution, and investigate stability and comparison theorem.",math.PR
"We propose to subject field a new type of Backward stochastic differential equation driven by a family of It\^o's processes. We prove existence and uniqueness of the solution, and investigate stability and comparison theorem.",math.PR
"Light field data has been demonstrated to facilitate the depth estimation task. Most learning-based methods estimate the depth infor-mation from EPI or sub-aperture images, while less methods pay attention to the focal stack. Existing learning-based depth estimation methods from the focal stack lead to suboptimal performance because of the defocus blur. In this paper, we propose a multi-modal learning method for robust light field depth estimation. We first excavate the internal spatial correlation by designing a context reasoning unit which separately extracts comprehensive contextual information from the focal stack and RGB images. Then we integrate the contextual information by exploiting a attention-guide cross-modal fusion module. Extensive experiments demonstrate that our method achieves superior performance than existing representative methods on two light field datasets. Moreover, visual results on a mobile phone dataset show that our method can be widely used in daily life.",cs.CV
"Light field data has been demonstrated to facilitate the depth estimation task. Most learning-based methods estimate the depth infor-mation from EPI or sub-aperture images, while less methods pay attention to the focal stack. Existing learning-based depth estimation methods from the focal stack lead to suboptimal performance because of the defocus blur. In this paper, we propose a multi-modal learning method for robust light field depth estimation. We first excavate the internal spatial correlation by designing a context reason social unit which separately extracts comprehensive contextual information from the focal stack and RGB images. Then we integrate the contextual information by exploiting a attention-guide cross-modal fusion module. Extensive experiments demonstrate that our method achieves superior performance than existing representative methods on two light field datasets. Moreover, visual results on a mobile phone dataset show that our method can be widely used in daily life.",cs.CV
"We present calculations showing that upcoming Cosmic Microwave Background (CMB) experiments will have the power to improve on current constraints on neutrino masses and provide new limits on neutrino degeneracy parameters. The latter could surpass those derived from Big Bang Nucleosynthesis (BBN) and the observationally-inferred primordial helium abundance. These conclusions derive from our Monte Carlo Markov Chain (MCMC) simulations which incorporate a full BBN nuclear reaction network. This provides a self-consistent treatment of the helium abundance, the baryon number, the three individual neutrino degeneracy parameters and other cosmological parameters. Our analysis focuses on the effects of gravitational lensing on CMB constraints on neutrino rest mass and degeneracy parameter. We find for the PLANCK experiment that total (summed) neutrino mass $M_{\nu} > 0.29$ eV could be ruled out at $2\sigma$ or better. Likewise neutrino degeneracy parameters $\xi_{\nu_{e}} > 0.11$ and $| \xi_{\nu_{\mu/\tau}} | > 0.49$ could be detected or ruled out at $2\sigma$ confidence, or better. For POLARBEAR we find that the corresponding detectable values are $M_\nu > 0.75 {\rm eV}$, $\xi_{\nu_{e}} > 0.62$, and $| \xi_{\nu_{\mu/\tau}}| > 1.1$, while for EPIC we obtain $M_\nu > 0.20 {\rm eV}$, $\xi_{\nu_{e}} > 0.045$, and $|\xi_{\nu_{\mu/\tau}}| > 0.29$. Our forcast for EPIC demonstrates that CMB observations have the potential to set constraints on neutrino degeneracy parameters which are better than BBN-derived limits and an order of magnitude better than current WMAP-derived limits.",astro-ph.CO astro-ph.HE gr-qc hep-ph
"We present calculations showing that upcoming Cosmic Microwave Background (CMB) experiments will have the power to improve on current constraints on neutrino masses and provide new limits on neutrino degeneracy parameters. The latter could surpass those derived from Big Bang Nucleosynthesis (BBN) and the observationally-inferred primordial helium abundance. These conclusions derive from our Monte Carlo Markov Chain (MCMC) simulations which incorporate a full BBN nuclear reaction network. This provides a self-consistent treatment of the helium abundance, the baryon number, the three individual neutrino degeneracy parameters and other cosmological parameters. Our psychoanalysis focuses on the effects of gravitative lensing on CMB constraints on neutrino rest mass and degeneracy parameter. We find for the PLANCK experiment that total (summed) neutrino mass $M_{\nu} > 0.29$ eV could be ruled out at $2\sigma$ or better. Likewise neutrino degeneracy parameters $\xi_{\nu_{e}} > 0.11$ and $| \xi_{\nu_{\mu/\tau}} | > 0.49$ could be detected or ruled out at $2\sigma$ confidence, or better. For POLARBEAR we find that the corresponding detectable values are $M_\nu > 0.75 {\rm eV}$, $\xi_{\nu_{e}} > 0.62$, and $| \xi_{\nu_{\mu/\tau}}| > 1.1$, while for EPIC we obtain $M_\nu > 0.20 {\rm eV}$, $\xi_{\nu_{e}} > 0.045$, and $|\xi_{\nu_{\mu/\tau}}| > 0.29$. Our forcast for EPIC demonstrates that CMB observations have the potential to set constraints on neutrino degeneracy parameters which are better than BBN-derived limits and an order of magnitude better than current WMAP-derived limits.",astro-ph.CO astro-ph.HE gr-qc hep-ph
Some problems with the mathematical analysis on which the UK Non-Native Organism Risk Assessment Scheme is based are outlined.,q-bio.QM
Some problems with the mathematical analytic thinking on which the UK Non-Native Organism chance Assessment Scheme is based are outlined.,q-bio.QM
"In the canonical framework, we propose an alternative approach for the multifractal analysis based on the detrending moving average method (MF-DMA). We define a canonical measure such that the multifractal mass exponent $\tau(q)$ is related to the partition function and the multifractal spectrum $f(\alpha)$ can be directly determined. The performances of the direct determination approach and the traditional approach of the MF-DMA are compared based on three synthetic multifractal and monofractal measures generated from the one-dimensional $p$-model, the two-dimensional $p$-model and the fractional Brownian motions. We find that both approaches have comparable performances to unveil the fractal and multifractal nature. In other words, without loss of accuracy, the multifractal spectrum $f(\alpha)$ can be directly determined using the new approach with less computation cost. We also apply the new MF-DMA approach to the volatility time series of stock prices and confirm the presence of multifractality.",q-fin.ST
"In the canonical framework, we declare oneself an alternative approach for the multifractal analysis based on the detrending moving average method (MF-DMA). We define a canonical measure such that the multifractal mass exponent $\tau(q)$ is related to the partition function and the multifractal spectrum $f(\alpha)$ can be directly determined. The performances of the direct determination approach and the traditional approach of the MF-DMA are compared based on three synthetic multifractal and monofractal measures generated from the one-dimensional $p$-model, the two-dimensional $p$-model and the fractional Brownian motions. We find that both approaches have comparable performances to unveil the fractal and multifractal nature. In other words, without loss of accuracy, the multifractal spectrum $f(\alpha)$ can be directly determined using the new approach with less computation cost. We also apply the new MF-DMA approach to the volatility metre series of stock prices and confirm the presence of multifractality.",q-fin.ST
"The shortest augmenting path technique is one of the fundamental ideas used in maximum matching and maximum flow algorithms. Since being introduced by Edmonds and Karp in 1972, it has been widely applied in many different settings. Surprisingly, despite this extensive usage, it is still not well understood even in the simplest case: online bipartite matching problem on trees. In this problem a bipartite tree $T=(W \uplus B, E)$ is being revealed online, i.e., in each round one vertex from $B$ with its incident edges arrives. It was conjectured by Chaudhuri et. al. [K. Chaudhuri, C. Daskalakis, R. D. Kleinberg, and H. Lin. Online bipartite perfect matching with augmentations. In INFOCOM 2009] that the total length of all shortest augmenting paths found is $O(n \log n)$. In this paper, we prove a tight $O(n \log n)$ upper bound for the total length of shortest augmenting paths for trees improving over $O(n \log^2 n)$ bound [B. Bosek, D. Leniowski, P. Sankowski, and A. Zych. Shortest augmenting paths for online matchings on trees. In WAOA 2015].",cs.DM
"The shortest augmenting path technique is one of the fundamental ideas used in maximum matching and maximum flow algorithms. Since being introduced by Edmonds and Karp in 1972, it has been widely applied in many different settings. Surprisingly, despite this extensive usage, it is still not well understood even in the simplest case: online bipartite matching problem on trees. In this problem a bipartite tree $T=(W \uplus B, E)$ is being revealed online, i.e., in apiece round one vertex from $B$ with its incident edges arrives. It was conjectured by Chaudhuri et. al. [K. Chaudhuri, C. Daskalakis, R. D. Kleinberg, and H. Lin. Online bipartite perfect matching with augmentations. In INFOCOM 2009] that the total length of all shortest augmenting paths found is $O(n \log n)$. In this paper, we prove a tight $O(n \log n)$ upper bound for the total length of shortest augmenting paths for trees improving complete $O(n \log^2 n)$ bound [B. Bosek, D. Leniowski, P. Sankowski, and A. Zych. Shortest augmenting paths for online matchings on trees. In WAOA 2015].",cs.DM
"Several authors have examined connections among restricted permutations, continued fractions, and Chebyshev polynomials of the second kind. In this paper we prove analogues of these results for involutions which avoid 3412. Our results include a recursive procedure for computing the generating function for involutions which avoid 3412 and any set of additional patterns. We use our results to give enumerations and generating functions for involutions which avoid 3412 and various sets of additional patterns. In many cases we express these generating functions in terms of Chebyshev polynomials of the second kind.",math.CO
"Several author have examined connections among restricted permutations, continued fractions, and Chebyshev polynomials of the second kind. In this paper we prove analogues of these results for involutions which avoid 3412. Our results include a recursive procedure for figure the generating function for involutions which avoid 3412 and any set of additional patterns. We use our results to give enumerations and generating functions for involutions which avoid 3412 and various sets of additional patterns. In many cases we express these generating functions in terms of Chebyshev polynomials of the second kind.",math.CO
"Dictionary learning is a branch of signal processing and machine learning that aims at finding a frame (called dictionary) in which some training data admits a sparse representation. The sparser the representation, the better the dictionary. The resulting dictionary is in general a dense matrix, and its manipulation can be computationally costly both at the learning stage and later in the usage of this dictionary, for tasks such as sparse coding. Dictionary learning is thus limited to relatively small-scale problems. In this paper, inspired by usual fast transforms, we consider a general dictionary structure that allows cheaper manipulation, and propose an algorithm to learn such dictionaries --and their fast implementation-- over training data. The approach is demonstrated experimentally with the factorization of the Hadamard matrix and with synthetic dictionary learning experiments.",cs.LG
"Dictionary learning is a branch of signal processing and machine learning that aims at discover a frame (called dictionary) in which some training data admits a sparse representation. The sparser the representation, the better the dictionary. The resulting dictionary is in general a dense matrix, and its manipulation can be computationally costly both at the learning stage and belated in the usage of this dictionary, for tasks such as sparse coding. Dictionary learning is thus limited to relatively small-scale problems. In this paper, inspired by usual fast transforms, we consider a general dictionary structure that allows cheaper manipulation, and propose an algorithm to learn such dictionaries --and their fast implementation-- over training data. The approach is demonstrated experimentally with the factorization of the Hadamard matrix and with synthetic dictionary learning experiments.",cs.LG
"We investigate a variation of the art gallery problem in which a team of mobile guards tries to track an unpredictable intruder in a simply-connected polygonal environment. In this work, we use the deployment strategy for diagonal guards originally proposed in [1]. The guards are confined to move along the diagonals of a polygon and the intruder can move freely within the environment. We define critical regions to generate event-triggered strategies for the guards. We design a hybrid automaton based on the critical regions to model the tracking problem. Based on reachability analysis, we provide necessary and sufficient conditions for tracking in terms of the maximal controlled invariant set of the hybrid system. We express these conditions in terms of the critical curves to find sufficient conditions for n/4 guards to track the mobile intruder using the reachability analysis.",cs.CG cs.RO
"We inquire a variation of the art gallery problem in which a team of mobile guards tries to track an unpredictable intruder in a simply-connected polygonal environment. In this work, we use the deployment strategy for diagonal guards originally proposed in [1]. The guards are confined to move along the diagonals of a polygon and the intruder can move freely within the environment. We define critical regions to generate event-triggered strategies for the guards. We design a hybrid automaton based on the critical regions to model the tracking problem. Based on reachability analysis, we provide necessary and sufficient conditions for tracking in terms of the maximum controlled invariant set of the hybrid system. We express these conditions in terms of the critical curves to find sufficient conditions for n/4 guards to track the mobile intruder using the reachability analysis.",cs.CG cs.RO
"GeoChemFoam is an open-source OpenFOAM-based numerical modelling toolbox that includes a range of custom packages to solve complex flow processes including multiphase transport with interface transfer, single-phase flow in multiscale porous media, and reactive transport with mineral dissolution. In this paper, we present GeoChemFoam's novel numerical model for simulation of conjugate heat transfer in micro-CT images of porous media. GeoChemFoam uses the micro-continuum approach to describe the fluid-solid interface using the volume fraction of fluid and solid in each computational cell. The velocity field is solved using Brinkman's equation with permeability calculated using the Kozeny-Carman equation which results in a near-zero permeability in the solid phase. Conjugate heat transfer is then solved with heat convection where the velocity is non-zero, and the thermal conductivity is calculated as the harmonic average of phase conductivity weighted by the phase volume fraction. Our model is validated by comparison with the standard two-medium approach for a simple 2D geometry. We then simulate conjugate heat transfer and calculate heat transfer coefficients for different flow regimes and injected fluid analogous to injection into a geothermal reservoir in a micro-CT image of Bentheimer sandstone and perform a sensitivity analysis in a porous heat exchanger with a random sphere packing.",physics.flu-dyn
"GeoChemFoam is an open-source OpenFOAM-based numerical modelling toolbox that includes a range of custom packages to solve complex flow processes including multiphase transport with interface transfer, single-phase flow in multiscale porous media, and reactive transport with mineral dissolution. In this paper, we present GeoChemFoam's novel numerical model for simulation of conjugate heat transfer in micro-CT images of porous media. GeoChemFoam uses the micro-continuum approach to describe the fluid-solid interface using the volume fraction of fluid and satisfying in each computational cell. The velocity field is solved using Brinkman's equation with permeability calculated using the Kozeny-Carman equation which results in a near-zero permeability in the satisfying phase. Conjugate heat transfer is and so solved with heat convection where the velocity is non-zero, and the thermal conductivity is calculated as the harmonic average of phase conductivity weighted by the phase volume fraction. Our model is validated by comparison with the standard two-medium approach for a simple 2D geometry. We and so simulate conjugate heat transfer and calculate heat transfer coefficients for different flow regimes and injected fluid analogous to injection into a geothermal reservoir in a micro-CT image of Bentheimer sandstone and perform a sensitivity analysis in a porous heat exchanger with a random sphere packing.",physics.flu-dyn
"We point out that with improving our present knowledge of experimental neutrino physics it will be possible to locate nuclear powered vehicles like submarines, aircraft carriers and UFOs and detect nuclear testing. Since neutrinos cannot be shielded, it will not be possible to escape these detection. In these detectors it will also be possible to perform neutrino oscillation experiments during any nuclear testing.",hep-ph
"We point out that with improving our acquaint knowledge of experimental neutrino physics it will be possible to locate nuclear power vehicles like submarines, aircraft carriers and UFOs and detect nuclear testing. Since neutrinos cannot be shielded, it will not be possible to escape these detection. In these detectors it will also be possible to perform neutrino oscillation experiments during any nuclear testing.",hep-ph
"This article proposes diffusion LMS strategies for distributed estimation over adaptive networks that are able to exploit sparsity in the underlying system model. The approach relies on convex regularization, common in compressive sensing, to enhance the detection of sparsity via a diffusive process over the network. The resulting algorithms endow networks with learning abilities and allow them to learn the sparse structure from the incoming data in real-time, and also to track variations in the sparsity of the model. We provide convergence and mean-square performance analysis of the proposed method and show under what conditions it outperforms the unregularized diffusion version. We also show how to adaptively select the regularization parameter. Simulation results illustrate the advantage of the proposed filters for sparse data recovery.",cs.DC cs.LG
"This article proposes diffusion LMS strategies for distributed estimation over adaptative networks that are able to exploit sparsity in the underlying system model. The approach relies on convex regularization, common in compressive sensing, to enhance the detection of sparsity via a diffusive process over the network. The resulting algorithms endow networks with learning abilities and allow them to learn the sparse structure from the incoming data in real-time, and also to track variations in the sparsity of the model. We provide convergence and mean-square performance analysis of the proposed method acting and show under what conditions it outperforms the unregularized diffusion version. We also show how to adaptively select the regularization parameter. Simulation results illustrate the advantage of the proposed filters for sparse data recovery.",cs.DC cs.LG
"We present a ""Chern-Simons-like"" action for the ""general massive gravity"" model propagating two spin-2 modes with independent masses in three spacetime dimensions (3D), and we use it to find a simple Hamiltonian form of this model. The number of local degrees of freedom, determined by the dimension of the physical phase space, agrees with a linearized analysis except in some limits, in particular that yielding ""new topologically massive gravity"", which therefore suffers from a linearization instability.",gr-qc hep-th
"We present a ""Chern-Simons-like"" action for the ""general massive gravity"" sit distribute two spin-2 modes with independent masses in three spacetime dimensions (3D), and we use it to find a simple Hamiltonian form of this model. The number of local degrees of freedom, determined by the dimension of the physical phase space, agrees with a linearized analysis except in some limits, in particular that yielding ""new topologically massive gravity"", which therefore suffers from a linearization instability.",gr-qc hep-th
"This paper proposes a centralized predictive flow controller to handle multi-connectivity for ultra-reliable low latency communication (URLLC) services. The prediction is based on channel state information (CSI) and buffer state reports from the system nodes. For this, we extend CSI availability to a packet data convergence protocol (PDCP) controller. The controller captures CSI in a discrete time Markov chain (DTMC). The DTMC is used to predict forwarding decisions over a finite time horizon. The novel mathematical model optimizes over finite trajectories based on a linear program. The results show performance improvements in a multi-layer small cell mobility scenario in terms of end-to-end (E2E) throughput. Furthermore, 5G new radio (NR) complaint system level simulations (SLS) and results are shown for dual connectivity as well as for the general multi-connectivity case.",cs.IT math.IT
"This paper proposes a centralized predictive flow controller to handle multi-connectivity for ultra-reliable low latency communication (URLLC) services. The prediction is based on channel state information (CSI) and buffer state reports from the system nodes. For this, we extend CSI availability to a packet data convergence protocol (PDCP) controller. The controller captures CSI in a discrete time Markov chain (DTMC). The DTMC is used to predict forwarding decisions over a finite time horizon. The novel mathematical model optimizes over finite trajectories based on a linear program. The resultant show performance improvements in a multi-layer small cell mobility scenario in terms of throughout (E2E) throughput. Furthermore, 5G new radio (NR) complaint system level simulations (SLS) and resultant are shown for dual connectivity as well as for the general multi-connectivity case.",cs.IT math.IT
We study an asymptotic behavior of the sum $\sum\limits_{n\le x}\frac{\D \tau(n)}{\D \tau(n+a)}$. Here $\tau(n)$ denotes the number of divisors of $n$ and $a\ge 1$ is a fixed integer.,math.NT
We study an asymptotic demeanour of the sum $\sum\limits_{n\le x}\frac{\D \tau(n)}{\D \tau(n+a)}$. Here $\tau(n)$ denotes the number of divisors of $n$ and $a\ge 1$ is a touch on integer.,math.NT
"Let p be an odd prime number and g $\ge$ 2 be an integer. We present an algorithm for computing explicit rational representations of isogenies between Jacobians of hyperelliptic curves of genus g over an extension K of the field of p-adic numbers Qp. It relies on an efficient resolution, with a logarithmic loss of p-adic precision, of a first order system of differential equations.",math.AG math.NT
"Let p be an odd prime number and g $\ge$ 2 be an integer. We salute an algorithm for computing explicit rational representations of isogenies between Jacobians of hyperelliptic curves of genus g over an extension K of the field of p-adic numbers Qp. It relies on an effective resolution, with a logarithmic loss of p-adic precision, of a first order system of differential equations.",math.AG math.NT
"Local versions of measurability have been around for a long time. Roughly, one splits the notion of $\mu $-completeness into pieces, and asks for a uniform ultrafilter over $\mu $ satisfying just some piece of $\mu $-completeness. Analogue local versions of weak compactness are harder to come by, since weak compactness cannot be defined by using a single ultrafilter. We deal with the problem by restricting just to a subset $P$ of all the partitions of $\mu $ into $<\mu $ classes and asking for some ultrafilter $D$ over $\mu $ such that no partition in $P$ disproves the $\mu $-completeness of $D$. By making $P$ vary in appropriate classes, one gets both measurability and weak compactness, as well as possible intermediate notions of ""weak measurability"". We systematize the above procedures and combine them to obtain variants of measurability which are at the same time weaker and local. Of particular interest is the fact that the notions thus obtained admit equivalent formulations through topological, model theoretical, combinatorial and Boolean algebraic conditions. We also hint a connection with Kat{\v{e}}tov order on filters.",math.GN math.LO
"Local versions of measurability have cost around for a long time. Roughly, one splits the notion of $\mu $-completeness into pieces, and asks for a uniform ultrafilter over $\mu $ satisfying just some piece of $\mu $-completeness. Analogue local versions of weak compactness are harder to come by, since weak compactness cannot be defined by using a single ultrafilter. We deal with the problem by restricting just to a subset $P$ of all the partitions of $\mu $ into $<\mu $ classes and asking for some ultrafilter $D$ over $\mu $ such that no partition in $P$ disproves the $\mu $-completeness of $D$. By making $P$ vary in appropriate classes, one gets both measurability and weak compactness, as well as possible intermediate notions of ""weak measurability"". We systematize the above procedures and combine them to obtain variants of measurability which are at the same time weaker and local. Of particular interest is the fact that the notions thus obtained admit equivalent formulations through topological, model theoretical, combinatorial and Boolean algebraic conditions. We also breath a connection with Kat{\v{e}}tov order on filters.",math.GN math.LO
"To identify possible spin texture contributions to thermoelectric transport, we present a detailed temperature and pressure dependence of thermopower $S$ in MnSi, as well as a low-temperature study of $S$ in a magnetic field. We find that $S/T$ reconstructs the $(p,T)$ phase diagram of MnSi encompassing the Fermi liquid, partially ordered, and non-Fermi liquid phases. Our results indicate that the latter two phases have essentially the same nature. In the partially ordered phase, $S(T)$ is strongly enhanced, which may be understood as a spiral-fluctuation-driven phase. A low temperature upturn in $S/T$ pertaining to the partial order phase persists up to the highest pressure, 24 kbar. Contrarily, a small suppression of $S(T)$ is observed in the ordered skyrmion lattice $A$ phase.",cond-mat.str-el
"To place possible spin texture contributions to thermoelectric transport, we present a detailed temperature and pressure dependence of thermopower $S$ in MnSi, as well as a low-temperature study of $S$ in a magnetic field. We find that $S/T$ reconstructs the $(p,T)$ phase diagram of MnSi encompassing the Fermi liquid, partially ordered, and non-Fermi liquid phases. Our results indicate that the latter two phases have essentially the same nature. In the partially ordered phase, $S(T)$ is strongly enhanced, which may be understood as a spiral-fluctuation-driven phase. A low temperature upturn in $S/T$ pertaining to the partial tone order phase persists up to the highest pressure, 24 kbar. Contrarily, a small suppression of $S(T)$ is observed in the ordered skyrmion lattice $A$ phase.",cond-mat.str-el
"We study the complexity of approximating solution structure of the bijective weighted sentence alignment problem of DeNero and Klein (2008). In particular, we consider the complexity of finding an alignment that has a significant overlap with an optimal alignment. We discuss ways of representing the solution for the general weighted sentence alignment as well as phrases-to-words alignment problem, and show that computing a string which agrees with the optimal sentence partition on more than half (plus an arbitrarily small polynomial fraction) positions for the phrases-to-words alignment is NP-hard. For the general weighted sentence alignment we obtain such bound from the agreement on a little over 2/3 of the bits. Additionally, we generalize the Hamming distance approximation of a solution structure to approximating it with respect to the edit distance metric, obtaining similar lower bounds.",cs.CC cs.CL cs.DS
"We study the complexity of approximating solution structure of the bijective weighted sentence coalition problem of DeNero and Klein (2008). In particular, we consider the complexity of finding an coalition that has a significant overlap with an optimal alignment. We discuss ways of representing the solution for the general weighted sentence coalition as well as phrases-to-words coalition problem, and show that computing a string which agrees with the optimal sentence partition on more than half (plus an arbitrarily small polynomial fraction) positions for the phrases-to-words coalition is NP-hard. For the general weighted sentence coalition we obtain such bound from the agreement on a little over 2/3 of the bits. Additionally, we infer the Hamming distance approximation of a solution structure to approximating it with respect to the edit distance metric, obtaining similar lower bounds.",cs.CC cs.CL cs.DS
"Quantum error correction is capable of digitizing quantum noise and increasing the robustness of qubits. Typically, error correction is designed with the target of eliminating all errors - making an error so unlikely it can be assumed that none occur. In this work, we use statistical quantum fault injection on the quantum phase estimation algorithm to test the sensitivity to quantum noise events. Our work suggests that quantum programs can tolerate non-trivial errors and still produce usable output. We show that it may be possible to reduce error correction overhead by relaxing tolerable error rate requirements. In addition, we propose using variable strength (distance) error correction, where overhead can be reduced by only protecting more sensitive parts of the quantum program with high distance codes.",quant-ph
"Quantum error discipline is capable of digitizing quantum noise and increasing the robustness of qubits. Typically, error discipline is designed with the target of eliminating all errors - making an error so unlikely it can be assumed that none occur. In this work, we use statistical quantum fault injection on the quantum phase estimation algorithm to test the sensitivity to quantum noise events. Our work suggests that quantum programs can tolerate non-trivial errors and still produce usable output. We show that it may be possible to reduce error discipline overhead by relaxing tolerable error rate requirements. In addition, we propose using variable strength (distance) error correction, where overhead can be reduced by only protecting more raw parts of the quantum program with high distance codes.",quant-ph
"We present a new method that enables the identification and analysis of both transition and metastable conformational states from atomistic or coarse-grained molecular dynamics (MD) trajectories. Our algorithm is presented and studied by using both analytical and actual examples from MD simulations of the helix-forming peptide Ala5, and of a larger system, the epidermal growth factor receptor (EGFR) protein. In all cases, our method identifies automatically the corresponding transition states and metastable conformations in an optimal way, with the input of a set of relevant coordinates, by capturing accurately the intrinsic slowest relaxation rate. Our approach provides a general and easy to implement analysis method that provides unique insight into the molecular mechanism and the rare but crucial rate limiting conformational pathways occurring in complex dynamical systems such as molecular trajectories.",physics.chem-ph q-bio.BM
"We present a new method that enables the identification and analysis of both transition and metastable conformational states from atomistic or coarse-grained molecular dynamics (MD) trajectories. Our algorithmic program is submit and studied by using both analytical and actual examples from MD simulations of the helix-forming peptide Ala5, and of a larger system, the epidermal growth factor receptor (EGFR) protein. In all cases, our method identifies automatically the corresponding transition states and metastable conformations in an optimal way, with the input of a set of relevant coordinates, by capturing accurately the intrinsic slowest relaxation rate. Our approach provides a general and easy to implement analysis method that provides unique insight into the molecular mechanism and the rare but crucial rate limiting conformational pathways occurring in complex dynamical systems such as molecular trajectories.",physics.chem-ph q-bio.BM
"Chinese dynastic histories form a large continuous linguistic space of approximately 2000 years, from the 3rd century BCE to the 18th century CE. The histories are documented in Classical (Literary) Chinese in a corpus of over 20 million characters, suitable for the computational analysis of historical lexicon and semantic change. However, there is no freely available open-source corpus of these histories, making Classical Chinese low-resource. This project introduces a new open-source corpus of twenty-four dynastic histories covered by Creative Commons license. An original list of Classical Chinese gender-specific terms was developed as a case study for analyzing the historical linguistic use of male and female terms. The study demonstrates considerable stability in the usage of these terms, with dominance of male terms. Exploration of word meanings uses keyword analysis of focus corpora created for genderspecific terms. This method yields meaningful semantic representations that can be used for future studies of diachronic semantics.",cs.CL
"Chinese dynastic histories form a large continuous linguistic space of approximately 2000 years, from the 3rd century BCE to the 18th century CE. The histories are documented in Classical (Literary) Chinese in a corpus of over 20 million characters, suitable for the computational analysis of historical lexicon and semantic change. However, there is no freely available open-source corpus of these histories, making Classical Chinese low-resource. This project introduces a new open-source corpus of twenty-four dynastic histories covered by Creative Commons license. An original list of Classical Chinese gender-specific terms was developed as a case study for analyzing the historical linguistic use of male and female terms. The study demonstrates considerable stability in the usage of these terms, with dominance of male terms. Exploration of word meaning uses keyword analysis of focus corpora created for genderspecific terms. This method soften meaningful semantic representations that can be used for future studies of diachronic semantics.",cs.CL
"Connected and automated vehicles (CAVs) are expected to yield significant improvements in safety, energy efficiency, and time utilization. However, their net effect on energy and environmental outcomes is unclear. Higher fuel economy reduces the energy required per mile of travel, but it also reduces the fuel cost of travel, incentivizing more travel and causing an energy ""rebound effect."" Moreover, CAVs are predicted to vastly reduce the time cost of travel, inducing further increases in travel and energy use. In this paper, we forecast the induced travel and rebound from CAVs using data on existing travel behavior. We develop a microeconomic model of vehicle miles traveled (VMT) choice under income and time constraints; then we use it to estimate elasticities of VMT demand with respect to fuel and time costs, with fuel cost data from the 2017 United States National Household Travel Survey (NHTS) and wage-derived predictions of travel time cost. Our central estimate of the combined price elasticity of VMT demand is -0.4, which differs substantially from previous estimates. We also find evidence that wealthier households have more elastic demand, and that households at all income levels are more sensitive to time costs than to fuel costs. We use our estimated elasticities to simulate VMT and energy use impacts of full, private CAV adoption under a range of possible changes to the fuel and time costs of travel. We forecast a 2-47% increase in travel demand for an average household. Our results indicate that backfire - i.e., a net rise in energy use - is a possibility, especially in higher income groups. This presents a stiff challenge to policy goals for reductions in not only energy use but also traffic congestion and local and global air pollution, as CAV use increases.",econ.GN q-fin.EC stat.AP
"link up and automated vehicles (CAVs) are expected to yield significant improvements in safety, energy efficiency, and time utilization. However, their net effect on energy and environmental outcomes is unclear. Higher fuel economy reduces the energy required per mile of travel, but it also reduces the fuel cost of travel, incentivizing more travel and causing an energy ""rebound effect."" Moreover, CAVs are predicted to vastly reduce the time cost of travel, inducing further increases in travel and energy use. In this paper, we forecast the induced travel and rebound from CAVs using data on existing travel behavior. We develop a microeconomic model of vehicle miles traveled (VMT) choice under income and time constraints; then we use it to estimate elasticities of VMT demand with respect to fuel and time costs, with fuel cost data from the 2017 United States National Household Travel Survey (NHTS) and wage-derived predictions of travel time cost. Our central estimate of the combined price elasticity of VMT demand is -0.4, which differs substantially from previous estimates. We also find evidence that wealthier households have more elastic demand, and that households at all income levels are more sensitive to time costs than to fuel costs. We use our estimated elasticities to simulate VMT and energy use impacts of full, private CAV adoption under a range of possible changes to the fuel and time costs of travel. We forecast a 2-47% increase in travel demand for an average household. Our results indicate that backfire - i.e., a net rise in energy use - is a possibility, especially in higher income groups. This presents a stiff challenge to policy goals for reductions in not only energy use but also traffic congestion and local anesthetic and global air pollution, as CAV use increases.",econ.GN q-fin.EC stat.AP
"In [1,2] we have developed a method (we call it the S-function method) that is successful in treating certain classes of rational second order ordinary differential equations (rational 2ODEs) that are particularly `resistant' to canonical Lie methods and to Darbouxian approaches. In this present paper, we generalize the S-function method making it capable of dealing with a class of elementary 2ODEs presenting elementary functions. Then, we apply this method to a Duffing-Van der Pol forced oscillator, obtaining an entire class of first integrals.",math-ph math.MP nlin.CD physics.class-ph
"In [1,2] we have developed a method (we bid it the S-function method) that is successful in treating certain classes of rational second order ordinary differential equations (rational 2ODEs) that are particularly `resistant' to canonical Lie method acting and to Darbouxian approaches. In this present paper, we generalize the S-function method making it capable of dealing with a class of elementary 2ODEs presenting elementary functions. Then, we apply this method to a Duffing-Van der Pol forced oscillator, obtaining an entire class of first integrals.",math-ph math.MP nlin.CD physics.class-ph
"In this paper, a framework of {w_1, w_2, R} classification for constructing the graphene nanomesh (GNM) of zigzag-edged hexagonal nanohole is systematically built. The three integer indexes w_1, w_2, and R indicate the distances between two neighboring sides of nanoholes in two directions and the nanohole size respectively, which leading to a straightforward gap opening criteria, i.e., w_1+w_2-R=3n+1,n is integer, steered via DFT band structure calculations.The guiding rule indicates that the semimetallic and semiconducting variation is consistent with a peculiar sequence ""010"" and ""100"" (""0""/""1"" represent gap closure/opening) with a period of 3 for odd and even w_1 respectively. The periodic nanoperforation induced gap sizes agreewith a linear fitting with a smaller sqrt(N_rem )/N_tot ratio, while deviates from that when (w_1+w_2)<R+1. Particularly, the {p, 1, p} and {1, q, q} structures demonstrate each unique scaling rule pertaining to the nanohole size only when n is set to zero. Furthermore, the coexistence of Dirac and flat bands is observed for {1, q, q} and {1, 1, m} structures, which is sensitive to the atomic patters",cond-mat.mtrl-sci
"In this paper, a framework of {w_1, w_2, R} assortment for constructing the graphene nanomesh (GNM) of zigzag-edged hexagonal nanohole is systematically built. The three integer indexes w_1, w_2, and R indicate the distances between two neighboring sides of nanoholes in two directions and the nanohole size respectively, which leading to a straightforward gap opening criteria, i.e., w_1+w_2-R=3n+1,n is integer, steered via DFT band structure calculations.The guiding rule indicates that the semimetallic and semiconducting variation is consistent with a peculiar sequence ""010"" and ""100"" (""0""/""1"" represent gap closure/opening) with a period of 3 for odd and even w_1 respectively. The periodic nanoperforation induced gap sizes agreewith a linear fitting with a smaller sqrt(N_rem )/N_tot ratio, while deviates from that when (w_1+w_2)<R+1. Particularly, the {p, 1, p} and {1, q, q} structures demonstrate each unique scaling rule pertaining to the nanohole size only when n is set to zero. Furthermore, the coexistence of Dirac and flatcar bands is observed for {1, q, q} and {1, 1, m} structures, which is sensitive to the atomic patters",cond-mat.mtrl-sci
"We prove a generalized version of the no-broadcasting theorem, applicable to essentially \emph{any} nonclassical finite-dimensional probabilistic model satisfying a no-signaling criterion, including ones with ``super-quantum'' correlations. A strengthened version of the quantum no-broadcasting theorem follows, and its proof is significantly simpler than existing proofs of the no-broadcasting theorem.",quant-ph
"We try a generalized version of the no-broadcasting theorem, applicable to essentially \emph{any} nonclassical finite-dimensional probabilistic model satisfying a no-signaling criterion, including ones with ``super-quantum'' correlations. A strengthened version of the quantum no-broadcasting theorem follows, and its proof is importantly simpler than existing proofs of the no-broadcasting theorem.",quant-ph
"The issue of a starburst-AGN connection in local and distant galaxies is relevant for understanding galaxy formation and evolution, the star formation and metal enrichment history of the universe, the origin of the extragalactic background at low and high energies, and the origin of nuclear activity in galaxies. Here I review some of the observational evidence recently brought forward in favor of a connection between the starburst and AGN phenomena. I conclude by raising a number of questions concerning the exact nature of this connection.",astro-ph
"The issue of a starburst-AGN connection in local and distant galaxies is relevant for understanding galaxy formation and evolution, the star formation and metal enrichment history of the universe, the origin of the extragalactic background at low and high energies, and the origin of nuclear bodily process in galaxies. Here I review some of the observational evidence recently brought forward in favor of a connection between the starburst and AGN phenomena. I conclude by kick upstairs a number of questions concerning the exact nature of this connection.",astro-ph
"We study systematically finite BRST-BFV transformations in $Sp(2)$-extended generalized Hamiltonian formalism. We present explicitly their Jacobians and the form of a solution to the compensation equation determining the functional field dependence of finite Fermionic parameters, necessary to generate arbitrary finite change of gauge-fixing functions in the path integral.",hep-th
"We study systematically finite BRST-BFV transformations in $Sp(2)$-extended infer Hamiltonian formalism. We present explicitly their Jacobians and the form of a solution to the compensation equation determining the functional field dependence of finite Fermionic parameters, requisite to generate arbitrary finite change of gauge-fixing functions in the path integral.",hep-th
"Actually Information security becomes a very important part for the organization's intangible assets, so level of confidence and stakeholder trusted are performance indicator as successes organization. Since information security has a very important role in supporting the activities of the organization, we need a standard or benchmark which regulates governance over information security. The main objective of this paper is to implement a novel practical approach framework to the development of information security management system (ISMS) assessment and monitoring software, called by I-SolFramework. System / software is expected to assist stakeholders in assessing the level of their ISO27001 compliance readiness, the software could help stakeholders understood security control or called by compliance parameters, being shorter and more structured. The case study illustrated provided to the reader with a set of guidelines, that aims easy understood and applicable as measuring tools for ISMS standards (ISO27001) compliance.",cs.CR
"Actually Information security becomes a very important part for the organization's intangible assets, so level of confidence and stakeholder trusted are performance indicator as successes organization. Since information security has a very important role in supporting the activities of the organization, we need a standard or benchmark which regulates government activity over information security. The main objective of this paper is to implement a novel practical approach framework to the development of information security management system (ISMS) assessment and monitoring software, called by I-SolFramework. System / software is expected to assist stakeholders in assessing the level of their ISO27001 compliance readiness, the software could help stakeholders understood security control or called by compliance parameters, being shorter and more structured. The case study instance provided to the reader with a set of guidelines, that aims easy understood and applicable as measuring tools for ISMS standards (ISO27001) compliance.",cs.CR
"Many theories of modified gravity, including the well studied Horndeski models, are characterized by a screening mechanism that ensures that standard gravity is recovered near astrophysical bodies. In a recently introduced class of gravitational theories that goes beyond Horndeski, it has been found that new derivative interactions lead to a partial breaking of the Vainshtein screening mechanism inside any gravitational source, although not outside. We study the impact of this new type of deviation from standard gravity on the density profile of a spherically symmetric matter distribution, in the nonrelativistic limit. For simplicity, we consider a polytropic equation of state and derive the modifications to the standard Lane-Emden equations. We also show the existence of a universal upper bound on the amplitude of this type of modified gravity, independently of the details of the equation of state.",astro-ph.CO astro-ph.SR gr-qc hep-th
"Many theories of modified gravity, including the well studied Horndeski models, are characterized by a screening mechanism that ensures that standard gravity is recovered near astrophysical bodies. In a recently introduced class of gravitational theories that goes beyond Horndeski, it has been notice that new derivative interactions lead to a partial breaking of the Vainshtein screening mechanism inside any gravitational source, although not outside. We study the impact of this new type of deviation from standard gravity on the density profile of a spherically symmetric matter distribution, in the nonrelativistic limit. For simplicity, we consider a polytropic equation of state and derive the modifications to the standard Lane-Emden equations. We also show the existence of a universal upper recoil on the amplitude of this type of modified gravity, independently of the details of the equation of state.",astro-ph.CO astro-ph.SR gr-qc hep-th
"In J.D. Jackson's Classical Electrodynamics textbook, the analysis of Dirac's charge quantization condition in the presence of a magnetic monopole has a mathematical omission and an all too brief physical argument that might mislead some students. This paper presents a detailed derivation of Jackson's main result, explains the significance of the missing term, and highlights the close connection between Jackson's findings and Dirac's original argument.",physics.class-ph
"In J.D. Jackson's Classical Electrodynamics textbook, the analysis of Dirac's charge quantization condition in the presence of a magnetic monopole has a mathematical omission and an all too legal brief physical argument that might mislead some students. This paper presents a detailed derivation of Jackson's main result, explains the significance of the missing term, and highlights the close connection between Jackson's findings and Dirac's pilot argument.",physics.class-ph
"Intuitively, an envelope of a family of curves is a curve that is tangent to a member of the family at each point. Here we use envelopes of families of circles to study objects from matrix theory and hyperbolic geometry. First we explore relationships between numerical ranges of $2\times 2$ matrices and families of circles to study the elliptical range theorem. Then we deduce a relationship between envelopes and the boundaries of families of intersecting circles and use it to find the boundaries of various families of pseudohyperbolic disks.",math.CV math.FA
"Intuitively, an envelope of a family of curves is a curve that is tangent to a member of the family at each point. Here we use envelope of families of circles to study objects from matrix theory and hyperbolic geometry. First we explore relationships between numerical ranges of $2\times 2$ matrices and families of circles to study the elliptical range theorem. Then we deduct a relationship between envelope and the boundaries of families of intersecting circles and use it to find the boundaries of various families of pseudohyperbolic disks.",math.CV math.FA
"Promoting information spreading is a booming research topic in network science community. However, the exiting studies about promoting information spreading seldom took into account the human memory, which plays an important role in the spreading dynamics. In this paper we propose a non-Markovian information spreading model on complex networks, in which every informed node contacts a neighbor by using the memory of neighbor's accumulated contact numbers in the past. We systematically study the information spreading dynamics on uncorrelated configuration networks and a group of $22$ real-world networks, and find an effective contact strategy of promoting information spreading, i.e., the informed nodes preferentially contact neighbors with small number of accumulated contacts. According to the effective contact strategy, the high degree nodes are more likely to be chosen as the contacted neighbors in the early stage of the spreading, while in the late stage of the dynamics, the nodes with small degrees are preferentially contacted. We also propose a mean-field theory to describe our model, which qualitatively agrees well with the stochastic simulations on both artificial and real-world networks.",physics.soc-ph
"Promoting information spreading is a booming research topic in network science community. However, the exiting studies about promoting information spreading seldom took into account the human memory, which plays an important role in the spreading dynamics. In this paper we propose a non-Markovian information spreading model on coordination compound networks, in which every informed node contacts a neighbor by using the memory of neighbor's accumulated contact numbers in the past. We systematically study the information spreading dynamics on uncorrelated configuration meshwork and a group of $22$ real-world networks, and find an effective contact strategy of promoting information spreading, i.e., the informed nodes preferentially contact neighbors with small number of accumulated contacts. According to the effective contact strategy, the high degree nodes are more likely to be chosen as the contacted neighbors in the early stage of the spreading, while in the late stage of the dynamics, the nodes with small degrees are preferentially contacted. We also propose a mean-field theory to describe our model, which qualitatively agrees well with the stochastic simulations on both artificial and real-world networks.",physics.soc-ph
"We consider the scattering matrix approach to quantum electron transport in meso- and nano-conductors. This approach is an alternative to the more conventional kinetic equation and Green's function approaches, and often is more efficient for coherent conductors (especially for proving general relations) and typically more transparent. We provide a description of both time-averaged quantities (for example, current-voltage characteristics) and current fluctuations in time -- noise, as well as full counting statistics of charge transport in a finite time. In addition to normal conductors, we consider contacts with superconductors and Josephson junctions.",cond-mat.mes-hall cond-mat.stat-mech cond-mat.supr-con quant-ph
"We consider the scattering intercellular substance approach to quantum electron transport in meso- and nano-conductors. This approach is an alternative to the more conventional kinetic equation and Green's function approaches, and often is more efficient for coherent conductors (especially for proving general relations) and typically more transparent. We provide a description of both time-averaged quantities (for example, current-voltage characteristics) and current fluctuations in time -- noise, as well as full counting statistic of charge transport in a finite time. In addition to normal conductors, we consider contacts with superconductors and Josephson junctions.",cond-mat.mes-hall cond-mat.stat-mech cond-mat.supr-con quant-ph
"We reply to Comment by J. Gemmer, L. Knipschild, R. Steinigeweg (arXiv:1712.02128) on our paper Phys. Rev. Lett. 119, 100601 (2017).",cond-mat.stat-mech quant-ph
"We reply to commentary by J. Gemmer, L. Knipschild, R. Steinigeweg (arXiv:1712.02128) on our report Phys. Rev. Lett. 119, 100601 (2017).",cond-mat.stat-mech quant-ph
"Engineers widely use Gaussian process regression framework to construct surrogate models aimed to replace computationally expensive physical models while exploring design space. Thanks to Gaussian process properties we can use both samples generated by a high fidelity function (an expensive and accurate representation of a physical phenomenon) and a low fidelity function (a cheap and coarse approximation of the same physical phenomenon) while constructing a surrogate model. However, if samples sizes are more than few thousands of points, computational costs of the Gaussian process regression become prohibitive both in case of learning and in case of prediction calculation. We propose two approaches to circumvent this computational burden: one approach is based on the Nystr\""om approximation of sample covariance matrices and another is based on an intelligent usage of a blackbox that can evaluate a~low fidelity function on the fly at any point of a design space. We examine performance of the proposed approaches using a number of artificial and real problems, including engineering optimization of a rotating disk shape.",stat.AP stat.ME stat.ML
"Engineers widely use Gaussian process regression framework to construct surrogate models aimed to replace computationally expensive physical models while exploring design space. Thanks to Gaussian process properties we can use both samples generated by a high fidelity function (an expensive and accurate representation of a physical phenomenon) and a low fidelity function (a cheap and coarse approximation of the same physical phenomenon) while constructing a surrogate model. However, if samples sizes are more than few thousands of points, computational costs of the Gaussian process regression go prohibitive both in case of learning and in case of prediction calculation. We propose two approaches to circumvent this computational burden: one approach is based on the Nystr\""om approximation of sample covariance matrices and another is based on an intelligent usage of a blackbox that can valuate a~low fidelity function on the fly at any point of a design space. We examine performance of the proposed approaches using a number of artificial and real problems, including engineering optimization of a rotating disk shape.",stat.AP stat.ME stat.ML
"Knock Codes are a knowledge-based unlock authentication scheme used on LG smartphones where a user enters a code by tapping or ""knocking"" a sequence on a 2x2 grid. While a lesser used authentication method, as compared to PINs or Android patterns, there is likely a large number of Knock Code users; we estimate, 700,000--2,500,000 in the US alone. In this paper, we studied Knock Codes security asking participants to select codes on mobile devices in three settings: a control treatment, a blocklist treatment, and a treatment with a larger, 2x3 grid. We find that Knock Codes are significantly weaker than other deployed authentication, e.g., PINs or Android patterns. In a simulated attacker setting, 2x3 grids offered no additional security, but blocklisting was more beneficial, making Knock Codes' security similar to Android patterns. Participants expressed positive perceptions of Knock Codes, but usability was challenged. SUS values were ""marginal"" or ""ok"" across treatments. Based on these findings, we recommend deploying blacklists for selecting a Knock Code because it improves security but has limited impact on usability perceptions.",cs.CR cs.HC
"Knock Codes are a knowledge-based unlock authentication scheme used on LG smartphones where a user enters a code by tapping or ""knocking"" a sequence on a 2x2 grid. While a lesser used authentication method, as compared to PINs or Android patterns, there is likely a large number of Knock Code users; we estimate, 700,000--2,500,000 in the US alone. In this paper, we studied Knock Codes security asking participants to select codes on mobile devices in three settings: a control treatment, a blocklist treatment, and a treatment with a larger, 2x3 grid. We find that Knock Codes are significantly weaker than other deployed authentication, e.g., PINs or Android patterns. In a simulated attacker setting, 2x3 grids offered no additional security, but blocklisting was more beneficial, making Knock Codes' security similar to Android patterns. Participants expressed positive perceptions of Knock Codes, but usability was challenged. SUS values were ""marginal"" or ""ok"" across treatments. Based on these findings, we recommend deploy shitlist for selecting a Knock Code because it improves security but has limited impact on usability perceptions.",cs.CR cs.HC
"The hilbert-space structure of quantum mechanics is related to the causal structure of space-time. The usual measurement hypotheses apparently preclude nonlinear or stochastic quantum evolution. By admitting a difference in the calculus of joint probabilities of events in space-time according to whether the separation is space-like or time-like, a relativistic nonlinear or stochastic quantum theory may be possible.",gr-qc hep-th quant-ph
"The hilbert-space structure of quantum mechanics is related to the causal structure of space-time. The usual measurement hypotheses apparently prevent nonlinear or stochastic quantum evolution. By admitting a difference in the calculus of joint chance of events in space-time according to whether the separation is space-like or time-like, a relativistic nonlinear or stochastic quantum theory may be possible.",gr-qc hep-th quant-ph
"We prove that if X is a separable infinite dimensional Banach space then its isomorphism class has infinite diameter with respect to the Banach-Mazur distance. One step in the proof is to show that if X is elastic then X contains an isomorph of c_0. We call X elastic if for some K < infinity for every Banach space Y which embeds into X, the space Y is K-isomorphic to a subspace of X. We also prove that if X is a separable Banach space such that for some K < infinity every isomorph of X is K-elastic then X is finite dimensional.",math.FA
"We prove that if X is a separable infinite dimensional Banach space and so its isomorphism grade has infinite diameter with respect to the Banach-Mazur distance. One step in the proof is to show that if X is elastic and so X contains an isomorph of c_0. We call X elastic if for some K < infinity for every Banach space Y which embeds into X, the space Y is K-isomorphic to a subspace of X. We also prove that if X is a separable Banach space such that for some K < infinity every isomorph of X is K-elastic and so X is finite dimensional.",math.FA
"We introduce RFEye, a generalized technique to locate signals independent of the waveform, using a single Unmanned Aerial Vehicle (UAV) equipped with only one omnidirectional antenna. This is achieved by acquiring signals from uncoordinated positions within a sphere of 1-meter radius at two nearby locations and formulating an asynchronous, distributed receiver beamforming at the UAV to compute the Direction of Arrival (DoA) from the unknown transmitter. The proposed method includes four steps: 1) Blind detection and extraction of unique signature in the signal to be localized, 2) Asynchronous signal acquisition and conditioning, 3) DoA calculation by creating a virtual distributed antenna array at UAV and 4) Obtaining position fix of emitter using DoA from two locations. These steps are analyzed for various sources of error, computational complexity and compared with widely used signal subspace-based DoA estimation algorithms. RFEye is implemented using an Intel-Aero UAV, equipped with a USRP B205 software-defined radio to acquire signals from a ground emitter. Practical outdoor experiments show that RFEye achieves a median accuracy of 1.03m in 2D and 2.5m in 3D for Wi-Fi, and 1.15m in 2D and 2.7m in 3D for LoRa (Long Range) waveforms, and is robust to external factors like wind and UAV position errors.",eess.SP
"We innovate RFEye, a generalized technique to locate signals independent of the waveform, using a single Unmanned Aerial Vehicle (UAV) equipped with only one omnidirectional antenna. This is achieved by acquiring signals from uncoordinated positions within a sphere of 1-meter radius at two nearby locations and formulating an asynchronous, distributed receiver beamforming at the UAV to compute the instruction of Arrival (DoA) from the unknown transmitter. The proposed method includes four steps: 1) Blind detection and extraction of unique signature in the signal to be localized, 2) Asynchronous signal acquisition and conditioning, 3) DoA calculation by creating a virtual distributed antenna array at UAV and 4) Obtaining position fix of emitter using DoA from two locations. These steps are analyzed for various sources of error, computational complexity and compared with widely used signal subspace-based DoA estimation algorithms. RFEye is implemented using an Intel-Aero UAV, equipped with a USRP B205 software-defined radio to acquire signals from a ground emitter. Practical outdoor experiments show that RFEye achieves a median accuracy of 1.03m in 2D and 2.5m in 3D for Wi-Fi, and 1.15m in 2D and 2.7m in 3D for LoRa (Long Range) waveforms, and is robust to external factors like wind and UAV position errors.",eess.SP
"With the potential for the improvements of measurement precision,the refinement of theoretical calculation on hadronic $B$ weak decays is necessary. In this paper, we study the contributions of $B$ mesonic distribution amplitude ${\Phi}_{B2}$ within the QCD factorization approach, and find that ${\Phi}_{B2}$ contributes to only the nonfactorizable annihilation amplitudes for the $B$ ${\to}$ $PP$ decays ($P$ denotes the ground $SU(3)$ pseudoscalar mesons). Although small, the ${\Phi}_{B2}$ contributions might be helpful for improving the performance of the QCD factorization approach, especially for the pure annihilation $B_{d}$ ${\to}$ $K^{+}K^{-}$ and $B_{s}$ ${\to}$ ${\pi}^{+}{\pi}^{-}$ decays.",hep-ph
"With the potential for the improvements of measuring precision,the refinement of theoretical calculation on hadronic $B$ weak decays is necessary. In this paper, we study the contributions of $B$ mesonic distribution amplitude ${\Phi}_{B2}$ within the QCD factorization approach, and observe that ${\Phi}_{B2}$ contributes to only the nonfactorizable annihilation amplitudes for the $B$ ${\to}$ $PP$ decays ($P$ denotes the ground $SU(3)$ pseudoscalar mesons). Although small, the ${\Phi}_{B2}$ contributions might be helpful for improving the performance of the QCD factorization approach, especially for the pure annihilation $B_{d}$ ${\to}$ $K^{+}K^{-}$ and $B_{s}$ ${\to}$ ${\pi}^{+}{\pi}^{-}$ decays.",hep-ph
"Given a set $S$ consisting of $n$ points in $\mathbb{R}^d$ and one or two vantage points, we study the number of orderings of $S$ induced by measuring the distance (for one vantage point) or the average distance (for two vantage points) from the vantage point(s) to the points of $S$ as the vantage points move through $\mathbb{R}^d.$ With one vantage point, a theorem of Good and Tideman \cite{MR505547} shows the maximum number of orderings is a sum of unsigned Stirling numbers of the first kind. We show that the minimum value in all dimensions is $2n-2,$ achieved by $n$ equally spaced points on a line. We investigate special configurations that achieve intermediate numbers of orderings in the one--dimensional and two--dimensional cases. We also treat the case when the points are on the sphere $S^2,$ connecting spherical and planar configurations. We briefly consider an application using weights suggested by an application to social choice theory. We conclude with several open problems that we believe deserve further study.",math.CO math.MG
"Given a set $S$ consisting of $n$ points in $\mathbb{R}^d$ and one or two vantage points, we study the number of orderings of $S$ induced by measuring the distance (for one vantage point) or the average distance (for two vantage points) from the vantage point(s) to the points of $S$ as the vantage points move through $\mathbb{R}^d.$ With one vantage point, a theorem of Good and Tideman \cite{MR505547} render the maximum number of orderings is a sum of unsigned Stirling numbers of the first kind. We show that the minimum value in all dimensions is $2n-2,$ achieved by $n$ equally spaced points on a line. We investigate special configurations that achieve intermediate numbers of orderings in the one--dimensional and two--dimensional cases. We also treat the case when the points are on the firmament $S^2,$ connecting spherical and planar configurations. We briefly consider an application using weights suggested by an application to social choice theory. We conclude with several open problems that we believe deserve further study.",math.CO math.MG
"The iron pnictide and chalcogenide compounds are a subject of intensive investigations due to their high temperature superconductivity.\cite{a-LaFeAsO} They all share the same structure, but there is significant variation in their physical properties, such as magnetic ordered moments, effective masses, superconducting gaps and T$_c$. Many theoretical techniques have been applied to individual compounds but no consistent description of the trends is available \cite{np-review}. We carry out a comparative theoretical study of a large number of iron-based compounds in both their magnetic and paramagnetic states. We show that the nature of both states is well described by our method and the trends in all the calculated physical properties such as the ordered moments, effective masses and Fermi surfaces are in good agreement with experiments across the compounds. The variation of these properties can be traced to variations in the key structural parameters, rather than changes in the screening of the Coulomb interactions. Our results provide a natural explanation of the strongly Fermi surface dependent superconducting gaps observed in experiments\cite{Ding}. We propose a specific optimization of the crystal structure to look for higher T$_c$ superconductors.",cond-mat.mtrl-sci cond-mat.str-el cond-mat.supr-con
"The iron pnictide and chalcogenide compounds are a subject of intensive investigations due to their senior high temperature superconductivity.\cite{a-LaFeAsO} They all share the same structure, but there is significant variation in their physical properties, such as magnetic ordered moments, effective masses, superconducting gaps and T$_c$. Many theoretical techniques have been applied to individual compounds but no logical description of the trends is available \cite{np-review}. We carry out a comparative theoretical study of a large number of iron-based compounds in both their magnetic and paramagnetic states. We show that the nature of both states is well described by our method and the trends in all the calculated physical properties such as the ordered moments, effective masses and Fermi surfaces are in good agreement with experiments across the compounds. The variation of these properties can be traced to variations in the key structural parameters, rather than changes in the screening of the Coulomb interactions. Our results provide a natural explanation of the strongly Fermi surface dependent superconducting gaps observed in experiments\cite{Ding}. We propose a specific optimization of the crystal structure to look for higher T$_c$ superconductors.",cond-mat.mtrl-sci cond-mat.str-el cond-mat.supr-con
"We investigate the qubit in the hierarchical environment where the first level is just one lossy cavity while the second level is the N-coupled lossy cavities. In the weak coupling regime between the qubit and the first level environment, the dynamics crossovers from the original Markovian to the new non-Markovian and from no-speedup to speedup can be realized by controlling the hierarchical environment, i.e., manipulating the number of cavities or the coupling strength between two nearest-neighbor cavities in the second level environment. And we find that the coupling strength between two nearest-neighbor cavities and the number of cavities in the second level environment have the opposite effect on the non-Markovian dynamics and speedup evolution of the qubit. In addition, in the case of strong coupling between the qubit and the first level environment, we can be surprised to find that, compared with the original non-Markovian dynamics, the added second level environment cannot play a beneficial role on the speedup of the dynamics of the system.",quant-ph
"We investigate the qubit in the hierarchical environment where the first level is just one lossy cavity while the second level is the N-coupled lossy cavities. In the weak coupling regime between the qubit and the first level environment, the dynamics crossovers from the original Markovian to the new non-Markovian and from no-speedup to speedup can be realized by operate the hierarchical environment, i.e., manipulating the number of cavities or the coupling strength between two nearest-neighbor cavities in the second level environment. And we find that the coupling strength between two nearest-neighbor cavities and the number of cavities in the second level environment have the opposite effect on the non-Markovian dynamics and speedup evolution of the qubit. In addition, in the case of strong coupling between the qubit and the first level environment, we can be storm to find that, compared with the original non-Markovian dynamics, the added second level environment cannot play a beneficial role on the speedup of the dynamics of the system.",quant-ph
"A recent signal of 750 GeV diphotons at the LHC can be explained within the framework of supersymmetric unification by the introduction of vector quarks and leptons with Yukawa couplings to a singlet S that describes the 750 GeV resonance. We study the most general set of theories that allow successful gauge coupling unification, and find that these Yukawa couplings are severely constrained by renormalization group behavior: they are independent of ultraviolet physics and flow to values at the TeV scale that we calculate precisely. As a consequence the vector quarks and leptons must be light; typically in the region of 375 GeV to 700 GeV, and in certain cases up to 1 TeV. The 750 GeV resonance may have a width less than the experimental resolution; alternatively, with the mass splitting between scalar and pseudoscalar components of S arising from one-loop diagrams involving vector fermions, we compute an apparent width of 10s of GeV.",hep-ex hep-ph
"A recent signal of 750 GeV diphotons at the LHC can be explained within the framework of supersymmetric unification by the unveiling of vector quarks and leptons with Yukawa yoke to a singlet S that describes the 750 GeV resonance. We study the most general set of theories that allow successful gauge coupling unification, and find that these Yukawa yoke are severely constrained by renormalization group behavior: they are independent of ultraviolet physics and flow to values at the TeV scale that we calculate precisely. As a consequence the vector quarks and leptons must be light; typically in the region of 375 GeV to 700 GeV, and in certain cases up to 1 TeV. The 750 GeV resonance may have a width less than the experimental resolution; alternatively, with the mass splitting between scalar and pseudoscalar components of S arising from one-loop diagrams involving vector fermions, we compute an apparent width of 10s of GeV.",hep-ex hep-ph
"We develop a theory of tubular neighborhoods for the lower strata in manifold stratified spaces with two strata. In these topologically stratified spaces, manifold approximate fibrations and teardrops play the role that fibre bundles and mapping cylinders play in smoothly stratified spaces. Applications include the classification of neighborhood germs, the construction of exotic stratifications, a multiparameter isotopy extension theorem and an h-coborsism extension theorem.",math.GT
"We develop a theory of tubular neighborhoods for the lower strata in manifold stratified spaces with two strata. In these topologically stratified spaces, manifold approximate fibrations and teardrops play the role that fibre compact and mapping cylinders play in smoothly stratified spaces. Applications let in the classification of neighborhood germs, the construction of exotic stratifications, a multiparameter isotopy extension theorem and an h-coborsism extension theorem.",math.GT
"On the basis of the Andrews--Bailey construction, we derive fermionic sum representations of Virasoro characters of non unitary minimal models ${\cal M}(k,kp+p-1)$ and ${\cal M}(k,kp+1)$. These expressions include certain expressions conjectured by the Stony Brook group as special cases.",hep-th math.QA
"On the basis of the Andrews--Bailey construction, we derive fermionic sum histrionics of Virasoro characters of non unitary minimal sit ${\cal M}(k,kp+p-1)$ and ${\cal M}(k,kp+1)$. These expressions include certain expressions conjectured by the Stony Brook group as special cases.",hep-th math.QA
"We present a numerical study of the time-dependent and time-independent Gross-Pitaevskii (GP) equation in two space dimensions, which describes the Bose-Einstein condensate of trapped bosons at ultralow temperature with both attractive and repulsive interatomic interactions. Both time-dependent and time-independent GP equations are used to study the stationary problems. In addition the time-dependent approach is used to study some evolution problems of the condensate. Specifically, we study the evolution problem where the trap energy is suddenly changed in a stable preformed condensate. In this case the system oscillates with increasing amplitude and does not remain limited between two stable configurations. Good convergence is obtained in all cases studied.",cond-mat.soft physics.comp-ph
"We present a numerical study of the time-dependent and time-independent Gross-Pitaevskii (GP) equation in two space dimensions, which describes the Bose-Einstein condensate of trapped bosons at ultralow temperature with both attractive and repulsive interatomic interactions. Both time-dependent and time-independent GP equations are used to study the stationary problems. In addition the time-dependent approach is used to study some evolution problems of the condensate. Specifically, we study the evolution problem where the trap department of energy is suddenly changed in a stable preform condensate. In this case the system oscillates with increasing amplitude and does not remain limited between two stable configurations. Good convergence is obtained in all cases studied.",cond-mat.soft physics.comp-ph
"Direct discretization of continuum kinetic equations, like the Vlasov equation, are under-utilized because the distribution function generally exists in a high-dimensional (>3D) space and computational cost increases geometrically with dimension. We propose to use high-order finite-volume techniques with block-structured adaptive mesh refinement (AMR) to reduce the computational cost. The primary complication comes from a solution state comprised of variables of different dimensions. We develop the algorithms required to extend standard single-dimension block structured AMR to the multi-dimension case. Specifically, algorithms for reduction and injection operations that transfer data between mesh hierarchies of different dimensions are explained in detail. In addition, modifications to the basic AMR algorithm that enable the use of high-order spatial and temporal discretizations are discussed. Preliminary results for a standard 1D+1V Vlasov-Poisson test problem are presented. Results indicate that there is potential for significant savings for some classes of Vlasov problems.",cs.MS physics.plasm-ph
"Direct discretization of continuum kinetic equations, like the Vlasov equation, are under-utilized because the distribution function generally exists in a high-dimensional (>3D) space and computational cost increases geometrically with dimension. We propose to use high-order finite-volume techniques with block-structured adaptive mesh refinement (AMR) to reduce the computational cost. The primary complication comes from a solution state comprised of variables of dissimilar dimensions. We develop the algorithms required to extend standard single-dimension block structured AMR to the multi-dimension case. Specifically, algorithms for reduction and injection operations that transfer data between mesh hierarchies of dissimilar dimensions are explained in detail. In addition, modifications to the basic AMR algorithm that enable the use of high-order spacial and temporal discretizations are discussed. Preliminary results for a standard 1D+1V Vlasov-Poisson test problem are presented. Results indicate that there is potential for significant savings for some classes of Vlasov problems.",cs.MS physics.plasm-ph
"The effective QCD-interaction as obtained from the front form Hamiltonian by DLCQ is Fourier transformed on the Retarded Schr\""odinger Equation for to describe the constituents of physical mesons. The crucial point is the use of a running coupling constant $\alpha_s(Q^2)$, in a manner similar but not equal to the one of Richardson in the equal usual-time quantization. Fixing the running coupling constant at the Z mass, the only parameters are the flavor masses. Without the top quark one needs thus 5 parameters to calculate the physical masses of 30 pseudoscalar and vector mesons, consistently within the same model. Applying variational methods to a caricature of the model, the biggest technical challenge is the solution of a cubic algebraic equation. -- In view of an oversimplified model and a very simple technology, the agreement with the empirical data is much too good.",hep-ph
"The effective QCD-interaction as obtained from the front form Hamiltonian by DLCQ is Fourier transformed on the Retarded Schr\""odinger Equation for to describe the constituents of physical mesons. The crucial maneuver is the use of a running coupling constant $\alpha_s(Q^2)$, in a manner similar but not equal to the one of Richardson in the equal usual-time quantization. Fixing the running coupling constant at the Z mass, the only parameters are the flavor masses. Without the top quark one need thus 5 parameters to calculate the physical masses of 30 pseudoscalar and vector mesons, consistently within the same model. Applying variational methods to a caricature of the model, the biggest technical challenge is the solution of a cubic algebraic equation. -- In view of an oversimplified model and a very simple technology, the agreement with the empirical data is much too good.",hep-ph
"Let $\sigma$ be a stability condition on the bounded derived category $D^b({\mathop{\rm Coh}\nolimits} W)$ of a Calabi-Yau threefold $W$ and $\mathcal{M}$ a moduli stack of $\sigma$-semistable objects of fixed topological type. We define generalized Donaldson-Thomas invariants which act as virtual counts of objects in $\mathcal{M}$ by generalizing the approach introduced by Kiem, Li and the author in the case of semistable sheaves. We construct an associated Deligne-Mumford stack $\widetilde{\mathcal{M}}$, called the $\mathbb{C}^\ast$-rigidified Kirwan partial desingularization of $\mathcal{M}$, with an induced semi-perfect obstruction theory of virtual dimension zero, and define the generalized Donaldson-Thomas invariant via Kirwan blowups to be the degree of the associated virtual cycle $[\widetilde{\mathcal{M}}]^{\mathrm{vir}}$. This is invariant under deformations of the complex structure of $W$. Examples of applications include Bridgeland stability, polynomial stability, Gieseker and slope stability.",hep-th math.AG
"Let $\sigma$ be a stability condition on the bounded derived category $D^b({\mathop{\rm Coh}\nolimits} W)$ of a Calabi-Yau threefold $W$ and $\mathcal{M}$ a moduli stack of $\sigma$-semistable objects of fixed topological type. We define generalized Donaldson-Thomas invariants which act as virtual counts of objects in $\mathcal{M}$ by generalizing the approach introduced by Kiem, Li and the author in the case of semistable sheaves. We construct an associated Deligne-Mumford stack $\widetilde{\mathcal{M}}$, called the $\mathbb{C}^\ast$-rigidified Kirwan partial desingularization of $\mathcal{M}$, with an induced semi-perfect impediment theory of virtual dimension zero, and define the generalized Donaldson-Thomas invariant via Kirwan blowups to be the degree of the associated virtual cycle $[\widetilde{\mathcal{M}}]^{\mathrm{vir}}$. This is invariant under deformations of the complex structure of $W$. Examples of applications include Bridgeland stability, polynomial stability, Gieseker and side stability.",hep-th math.AG
"On plane algebraic curves the so-called Weierstrass kernel plays the same role of the Cauchy kernel on the complex plane. A straightforward prescription to construct the Weierstrass kernel is known since one century. How can it be extended to the case of more general curves obtained from the intersection of hypersurfaces in a $n$ dimensional complex space? This problem is solved in this work in the case $n=3$. As an application, the correlation functions of bosonic string theories are constructed on a canonical curve of genus four.",math.AG
"On plane algebraic curves the so-called Weierstrass kernel free rein the same role of the Cauchy kernel on the complex plane. A straightforward prescription to construct the Weierstrass kernel is known since one century. How can it be extended to the case of more general curves obtained from the intersection of hypersurfaces in a $n$ dimensional complex space? This problem is resolved in this work in the case $n=3$. As an application, the correlation functions of bosonic string theories are constructed on a canonical curve of genus four.",math.AG
"Recently, with an enlighting treatment, Baskaran and Grishchuk have shown the presence and importance of the so-called ``magnetic'' components of gravitational waves (GWs), which have to be taken into account in the context of the total response functions of interferometers for GWs propagating from arbitrary directions. In this paper the analysis of the response functions for the magnetic components is generalized in its full frequency dependence, while in the work of Baskaran and Grishchuk the response functions were computed only in the approximation of wavelength much larger than the linear dimensions of the interferometer. It is also shown that the response functions to the magnetic components grow at high frequencies, differently from the values of the response functions to the well known ordinary components that decrease at high frequencies. Thus the magnetic components could in principle become the dominant part of the signal at high frequencies. This is important for a potential detection of the signal at high frequencies and confirms that the magnetic contributions must be taken into account in the data analysis. More, the fact that the response functions of the magnetic components grow at high frequencies shows that, in principle, the frequency-range of Earth-based interferometers could extend to frequencies over 10000 Hz.",gr-qc
"Recently, with an enlighting treatment, Baskaran and Grishchuk have shown the presence and importance of the so-called ``magnetic'' components of gravitational waves (GWs), which have to be lease into account in the context of the total response functions of interferometers for GWs propagating from arbitrary directions. In this newspaper publisher the analysis of the response functions for the magnetic components is generalized in its full frequency dependence, while in the work of Baskaran and Grishchuk the response functions were computed only in the approximation of wavelength much larger than the linear dimensions of the interferometer. It is also shown that the response functions to the magnetic components grow at high frequencies, differently from the values of the response functions to the well known ordinary components that decrease at high frequencies. Thus the magnetic components could in principle become the dominant part of the signal at high frequencies. This is important for a potential detection of the signal at high frequencies and confirms that the magnetic contributions must be lease into account in the data analysis. More, the fact that the response functions of the magnetic components grow at high frequencies shows that, in principle, the frequency-range of Earth-based interferometers could extend to frequencies over 10000 Hz.",gr-qc
"A $\textit{ladder}$ is a set $S \subseteq \mathbb Z^+$ such that any finite coloring of $\mathbb Z$ contains arbitrarily long monochromatic progressions with common difference in $S$. Van der Waerden's theorem famously asserts that $\mathbb Z^+$ itself is a ladder. We also discuss variants of ladders, namely $\textit{accessible}$ and $\textit{walkable}$ sets, which are sets $S$ such that any coloring of $\mathbb Z$ contains arbitrarily long (for accessible sets) or infinite (for walkable sets) monochromatic sequences with consecutive differences in $S$. We show that sets with upper density 1 are ladders and walkable. We also show that all directed graphs with infinite chromatic number are accessible, and reduce the bound on the walkability order of sparse sets from 3 to 2, making it tight.",math.CO
"A $\textit{ladder}$ is a set $S \subseteq \mathbb Z^+$ such that any finite coloring of $\mathbb Z$ contains arbitrarily long monochromatic progressions with common difference in $S$. Van der Waerden's theorem famously asserts that $\mathbb Z^+$ itself is a ladder. We also discuss chance variable of ladders, namely $\textit{accessible}$ and $\textit{walkable}$ sets, which are sets $S$ such that any coloring of $\mathbb Z$ contains arbitrarily long (for accessible sets) or infinite (for walkable sets) monochromatic sequences with consecutive differences in $S$. We show that sets with upper density 1 are ladders and walkable. We also show that all directed graphical record with infinite chromatic number are accessible, and reduce the bound on the walkability order of sparse sets from 3 to 2, making it tight.",math.CO
"We present a conjectured family of SIC-POVMs which have an additional symmetry group whose size is growing with the dimension. The symmetry group is related to Fibonacci numbers, while the dimension is related to Lucas numbers. The conjecture is supported by exact solutions for dimensions d=4,8,19,48,124,323, as well as a numerical solution for dimension d=844.",quant-ph
"We present a conjectured family of SIC-POVMs which have an additional symmetry group whose size is growing with the dimension. The symmetry group is related to Fibonacci numbers, while the dimension is related to Lucas numbers. The conjecture is supported by exact solution for dimensions d=4,8,19,48,124,323, as intimately as a numerical solution for dimension d=844.",quant-ph
"We consider the stability and dynamics of multiple dark solitons in cigar-shaped Bose-Einstein condensates (BECs). Our study is motivated by the fact that multiple matter-wave dark solitons may naturally form in such settings as per our recent work [Phys. Rev. Lett. 101, 130401 (2008)]. First, we study the dark soliton interactions and show that the dynamics of well-separated solitons (i.e., ones that undergo a collision with relatively low velocities) can be analyzed by means of particle-like equations of motion. The latter take into regard the repulsion between solitons (via an effective repulsive potential) and the confinement and dimensionality of the system (via an effective parabolic trap for each soliton). Next, based on the fact that stationary, well-separated dark multi-soliton states emerge as a nonlinear continuation of the appropriate excited eigensates of the quantum harmonic oscillator, we use a Bogoliubov-de Gennes analysis to systematically study the stability of such structures. We find that for a sufficiently large number of atoms, multiple soliton states may be dynamically stable, while for a small number of atoms, we predict a dynamical instability emerging from resonance effects between the eigenfrequencies of the soliton modes and the intrinsic excitation frequencies of the condensate. Finally we present experimental realizations of multi-soliton states including a three-soliton state consisting of two solitons oscillating around a stationary one.",cond-mat.quant-gas nlin.PS quant-ph
"We consider the stability and dynamics of multiple dark solitons in cigar-shaped Bose-Einstein condensates (BECs). Our study is motivated by the fact that multiple matter-wave dark solitons may naturally form in such settings as per our recent work [Phys. Rev. Lett. 101, 130401 (2008)]. First, we study the dark soliton interactions and show that the dynamics of well-separated solitons (i.e., ones that undergo a collision with relatively low velocities) can be analyzed by means of particle-like equations of motion. The latter take into regard the repulsion between solitons (via an effective repulsive potential) and the confinement and dimensionality of the system (via an effective parabolic trap for each soliton). Next, based on the fact that stationary, well-separated dark multi-soliton states emerge as a nonlinear continuation of the appropriate excited eigensates of the quantum harmonic oscillator, we use a Bogoliubov-de Gennes depth psychology to systematically study the stability of such structures. We find that for a sufficiently large number of atoms, multiple soliton states may be dynamically stable, while for a small number of atoms, we predict a dynamical instability emerging from resonance result between the eigenfrequencies of the soliton modes and the intrinsic excitation frequencies of the condensate. Finally we present experimental realizations of multi-soliton states including a three-soliton state consisting of two solitons oscillating around a stationary one.",cond-mat.quant-gas nlin.PS quant-ph
"The estimated brightness of the Cygnus loop supernova remnant (SNR) at 2720, 1420, 820, 408 and 34.5 MHz are presented. The observations of the continuum radio emission are used to calculate the mean brightness temperatures and surface brightnesses of this loop at the five frequencies in wide spectral range, using the method we have previously developed for large radio loops. The spectrum for mean temperatures versus frequency between the five frequencies is estimated and the spectral index of Cygnus loop is also obtained. Also, from our results can be concluded that Cygnus loop evolves in the low density environment and the initial energy of supernova explosion was relatively low. The obtained results confirm non-thermal origin of the Cygnus radio loop and show that our method is applicable to almost all remnants.",astro-ph.GA
"The estimated brightness of the Cygnus loop supernova remnant (SNR) at 2720, 1420, 820, 408 and 34.5 MHz are presented. The observations of the continuum radio emanation are used to calculate the mean brightness temperatures and surface brightnesses of this loop at the five frequencies in wide spectral range, using the method we have previously developed for large radio loops. The spectrum for mean temperatures versus absolute frequency between the five frequencies is estimated and the spectral index of Cygnus loop is also obtained. Also, from our results can be concluded that Cygnus loop evolves in the low density environment and the initial energy of supernova explosion was relatively low. The obtained results confirm non-thermal origin of the Cygnus radio loop and show that our method is applicable to almost all remnants.",astro-ph.GA
"On September 14, 2015, the Laser Interferometer Gravitational-wave Observatory (LIGO) detected a gravitational-wave transient (GW150914); we characterize the properties of the source and its parameters. The data around the time of the event were analyzed coherently across the LIGO network using a suite of accurate waveform models that describe gravitational waves from a compact binary system in general relativity. GW150914 was produced by a nearly equal mass binary black hole of $36^{+5}_{-4} M_\odot$ and $29^{+4}_{-4} M_\odot$; for each parameter we report the median value and the range of the 90% credible interval. The dimensionless spin magnitude of the more massive black hole is bound to be $<0.7$ (at 90% probability). The luminosity distance to the source is $410^{+160}_{-180}$ Mpc, corresponding to a redshift $0.09^{+0.03}_{-0.04}$ assuming standard cosmology. The source location is constrained to an annulus section of $610$ deg$^2$, primarily in the southern hemisphere. The binary merges into a black hole of $62^{+4}_{-4} M_\odot$ and spin $0.67^{+0.05}_{-0.07}$. This black hole is significantly more massive than any other inferred from electromagnetic observations in the stellar-mass regime.",astro-ph.HE gr-qc
"On September 14, 2015, the Laser Interferometer Gravitational-wave Observatory (LIGO) detected a gravitational-wave transient (GW150914); we characterize the properties of the source and its parameters. The data around the time of the event were analyzed coherently across the LIGO network using a suite of accurate waveform models that describe gravitational waves from a compact binary system in general relativity. GW150914 was produced by a nearly peer mass binary black hole of $36^{+5}_{-4} M_\odot$ and $29^{+4}_{-4} M_\odot$; for each parameter we report the median value and the image of the 90% credible interval. The dimensionless spin magnitude of the more massive black hole is bound to be $<0.7$ (at 90% probability). The luminosity distance to the source is $410^{+160}_{-180}$ Mpc, corresponding to a redshift $0.09^{+0.03}_{-0.04}$ assuming standard cosmology. The source location is constrained to an annulus section of $610$ deg$^2$, primarily in the southern hemisphere. The binary merges into a black hole of $62^{+4}_{-4} M_\odot$ and spin $0.67^{+0.05}_{-0.07}$. This black hole is significantly more massive than any other inferred from electromagnetic observations in the stellar-mass regime.",astro-ph.HE gr-qc
"I discuss open theoretical questions pertaining to the modified dynamics (MOND)--a proposed alternative to dark matter, which posits a breakdown of Newtonian dynamics in the limit of small accelerations. In particular, I point the reasons for thinking that MOND is an effective theory--perhaps, despite appearance, not even in conflict with GR. I then contrast the two interpretations of MOND as modified gravity and as modified inertia. I describe two mechanical models that are described by potential theories similar to (non-relativistic) MOND: a potential-flow model, and a membrane model. These might shed some light on a possible origin of MOND. The possible involvement of vacuum effects is also speculated on.",astro-ph gr-qc hep-ph
"I discuss open theoretical questions pertaining to the modified dynamics (MOND)--a proposed choice to dark matter, which posits a breakdown of Newtonian dynamics in the limit of small accelerations. In particular, I point the reasons for thinking that MOND is an effective theory--perhaps, despite appearance, not even in conflict with GR. I then contrast the two interpretations of MOND as modified gravity and as modified inertia. I describe two mechanical models that are described by potential theories similar to (non-relativistic) MOND: a potential-flow model, and a membrane model. These might shed more or less light on a possible origin of MOND. The possible involvement of vacuum effects is also speculated on.",astro-ph gr-qc hep-ph
"The continuous increase of hospital noise levels has become a vital challenge for society. The complex soundscapes in the hospital produce unpleasant noise, which may exceed the prescribed noise level for the patients and healthcare professionals. Previous studies have reported that extended exposure to loud noise may cause auditory and nonauditory disorders in healthcare professionals, medical staff, and patients. Therefore, there is an increased interest for the design and fabrication of effective noise barriers for the hospital premises. Herein, we have performed the thorough experimental investigations on the acoustical performances for PVC coated polyester fabrics and 100 % pure PVC sheets. The performances of these potential acoustic curtains have found to be superior to that of existing acoustic curtains for hospitals. Also, the results showed that the sound transmission class rating of PVC curtains are much higher than the existing commercial acoustic curtains.",physics.app-ph
"The continuous increase of hospital noise levels has become a vital challenge for society. The complex soundscapes in the hospital produce unpleasant noise, which may exceed the prescribed noise level for the patients and healthcare professionals. Previous studies have reported that extended exposure to gaudy noise may cause auditory and nonauditory disorders in healthcare professionals, medical staff, and patients. Therefore, in that respect is an increased interest for the design and fabrication of effective noise barriers for the hospital premises. Herein, we have performed the thorough experimental investigations on the acoustical performances for PVC coated polyester fabrics and 100 % pure PVC sheets. The performances of these potential acoustic curtains have found to be superior to that of existing acoustic curtains for hospitals. Also, the results showed that the sound transmission class rating of PVC curtains are much higher than the existing commercial acoustic curtains.",physics.app-ph
"We review the construction of Galileon interactions involving a single two-column mixed-symmetry tensor of arbitrary degree in flat spacetime of arbitrary dimensions, in a reverse engineering spirit. By defining an appropriate Riemann-like tensor for each of these tensor gauge fields, we show that the theories constructed in the spirit of Lovelock's theory of Gravity correspond to the well-known Galileon theories from the literature.",hep-th
"We review the construction of Galileon interactions involving a single two-column mixed-symmetry tensor of arbitrary degree in flat spacetime of arbitrary dimensions, in a reverse engineering spirit. By defining an appropriate Riemann-like tensor for for each one of these tensor gauge fields, we show that the theories constructed in the inspirit of Lovelock's theory of Gravity correspond to the well-known Galileon theories from the literature.",hep-th
"Feature selection is a standard approach to understanding and modeling high-dimensional classification data, but the corresponding statistical methods hinge on tuning parameters that are difficult to calibrate. In particular, existing calibration schemes in the logistic regression framework lack any finite sample guarantees. In this paper, we introduce a novel calibration scheme for $\ell_1$-penalized logistic regression. It is based on simple tests along the tuning parameter path and is equipped with optimal guarantees for feature selection. It is also amenable to easy and efficient implementations, and it rivals or outmatches existing methods in simulations and real data applications.",math.ST stat.ME stat.ML stat.TH
"Feature selection is a standard approach to understanding and modeling high-dimensional classification data, but the corresponding statistical method hinge on tuning parameters that are difficult to calibrate. In particular, existing calibration schemes in the logistic regression framework lack any finite sample guarantees. In this paper, we introduce a novel calibration scheme for $\ell_1$-penalized logistic regression. It is based on mere tests along the tuning parameter path and is equipped with optimal guarantees for feature selection. It is also amenable to easy and efficient implementations, and it rivals or outmatches existing method in simulations and real data applications.",math.ST stat.ME stat.ML stat.TH
"We claim that there is a one to one correspondence between $NAdS_2$ spacetimes and dilatonic $AdS_2$ black holes. We show that these have the same thermodynamics and can be described by the same states of 1D CFTs with the same central charge. In addition, we show that these are actually the same set of solutions since a field redefinition in the Schwarzian theory transforms its equation of motion into the time independent part of the bulk Einstein equation. The deformations of the $AdS_2$ boundary as a function of the boundary time are exactly the conformal factor of the $AdS_2$ black hole metric as a function of the radial bulk coordinate.",hep-th
"We claim that there is a one to one correspondence betwixt $NAdS_2$ spacetimes and dilatonic $AdS_2$ black holes. We show that these have the same thermodynamics and can be described by the same states of 1D CFTs with the same central charge. In addition, we show that these are actually the same set of solutions since a field redefinition in the Schwarzian theory transforms its equation of motion into the time self-governing part of the bulk Einstein equation. The deformations of the $AdS_2$ boundary as a function of the boundary time are exactly the conformal factor of the $AdS_2$ black hole metric as a function of the radial bulk coordinate.",hep-th
"In order to improve dynamic characteristics of the power system with high-proportion renewable energy sources (RESs), it is necessary for the voltage source converter (VSC), interfaces of RESs, to provide inertial and frequency regulation. In practical applications, VSCs are better to be controlled as a current source due to its weak overcurrent capacity. According to the characteristic, a dual synchronous theory is proposed to analyze the synchronization between current sources in this paper. Based on dual synchronous idea, a dual synchronous generator (DSG) control is applied in VSC to form inertial current source. In addition, a braking control is embedded in DSG control to improve the transient stability of VSC. Finally, experimental results verify the effectiveness of the theory and the control method.",cs.SY eess.SY
"In order to improve dynamic characteristics of the power system with high-proportion renewable energy sources (RESs), it is necessary for the voltage source converter (VSC), interface of RESs, to provide inertial and frequency regulation. In practical applications, VSCs are better to be controlled as a current source due to its weak overcurrent capacity. According to the characteristic, a dual synchronous theory is purpose to analyze the synchronization between current sources in this paper. Based on dual synchronous idea, a dual synchronous generator (DSG) control is applied in VSC to form inertial current source. In addition, a braking control is embedded in DSG control to improve the transient stability of VSC. Finally, experimental results verify the effectiveness of the theory and the control method.",cs.SY eess.SY
"A wide variety of (fixed-point) iterative methods for the solution of nonlinear equations (in Hilbert spaces) exists. In many cases, such schemes can be interpreted as iterative local linearization methods, which, as will be shown, can be obtained by applying a suitable preconditioning operator to the original (nonlinear) equation. Based on this observation, we will derive a unified abstract framework which recovers some prominent iterative schemes. In particular, for Lipschitz continuous and strongly monotone operators, we derive a general convergence analysis. Furthermore, in the context of numerical solution schemes for nonlinear partial differential equations, we propose a combination of the iterative linearization approach and the classical Galerkin discretization method, thereby giving rise to the so-called iterative linearization Galerkin (ILG) methodology. Moreover, still on an abstract level, based on two different elliptic reconstruction techniques, we derive a posteriori error estimates which separately take into account the discretization and linearization errors. Furthermore, we propose an adaptive algorithm, which provides an efficient interplay between these two effects. In addition, the ILG approach will be applied to the specific context of finite element discretizations of quasilinear elliptic equations, and some numerical experiments will be performed.",cs.NA math.NA
"A wide variety of (fixed-point) iterative methods for the solvent of nonlinear equations (in Hilbert spaces) exists. In many cases, such schemes can be interpreted as iterative local linearization methods, which, as will be shown, can be obtained by applying a suitable preconditioning operator to the original (nonlinear) equation. Based on this observation, we will derive a unified abstract framework which recovers some big iterative schemes. In particular, for Lipschitz continuous and strongly monotone operators, we derive a general convergence analysis. Furthermore, in the context of numerical solvent schemes for nonlinear partial differential equations, we propose a combination of the iterative linearization approach and the classical Galerkin discretization method, thereby giving rise to the so-called iterative linearization Galerkin (ILG) methodology. Moreover, still on an abstract level, based on two different elliptic reconstruction techniques, we derive a posteriori error estimates which separately take into account the discretization and linearization errors. Furthermore, we propose an adaptive algorithm, which provides an efficient interplay between these two effects. In addition, the ILG approach will be applied to the specific context of finite element discretizations of quasilinear elliptic equations, and some numerical experiments will be performed.",cs.NA math.NA
"We prove that pseudo-differential operators with symbols in the class $S_{1,\delta}^0$ ($0<\delta<1$) are not always bounded on the modulation space $M^{p,q}$ ($q\neq2$).",math.AP math.FA
"We prove that pseudo-differential operators with symbolisation in the class $S_{1,\delta}^0$ ($0<\delta<1$) are not always border on the modulation space $M^{p,q}$ ($q\neq2$).",math.AP math.FA
"Three versions of the quark-meson coupling (QMC) model are applied to describe properties of nuclear matter and finite nuclei. The models differ in the treatment of the bag constant and in terms of nonlinear scalar self-interactions. As a consequence opposite predictions for the medium modifications of the internal nucleon structure arise. After calibrating the model parameters at equilibrium nuclear matter density, binding energies, charge radii, single-particle spectra and density distributions of spherical nuclei are analyzed and compared with QHD calculations. For the models which predict a decreasing size of the nucleon in the nuclear environment, unrealistic features of the nuclear shapes arise.",nucl-th
"Three versions of the quark-meson sexual union (QMC) model are applied to describe properties of nuclear matter and finite nuclei. The models differ in the treatment of the bag constant and in terms of nonlinear scalar self-interactions. As a consequence opposite predictions for the medium modifications of the internal nucleon structure arise. After calibrating the model parameters at equilibrium nuclear matter density, binding energies, charge radii, single-particle spectra and denseness distributions of spherical nuclei are analyzed and compared with QHD calculations. For the models which predict a decreasing size of the nucleon in the nuclear environment, unrealistic features of the nuclear shapes arise.",nucl-th
"This chapter discusses the need of security and privacy protection mechanisms in aggregation protocols used in wireless sensor networks (WSN). It presents a comprehensive state of the art discussion on the various privacy protection mechanisms used in WSNs and particularly focuses on the CPDA protocols proposed by He et al. (INFOCOM 2007). It identifies a security vulnerability in the CPDA protocol and proposes a mechanism to plug that vulnerability. To demonstrate the need of security in aggregation process, the chapter further presents various threats in WSN aggregation mechanisms. A large number of existing protocols for secure aggregation in WSN are discussed briefly and a protocol is proposed for secure aggregation which can detect false data injected by malicious nodes in a WSN. The performance of the protocol is also presented. The chapter concludes while highlighting some future directions of research in secure data aggregation in WSNs.",cs.CR cs.NI
"This chapter discusses the need of protection and privacy protection mechanisms in aggregation protocols used in wireless sensor networks (WSN). It presents a comprehensive state of the art discussion on the various privacy protection mechanisms used in WSNs and particularly focuses on the CPDA protocols proposed by He et al. (INFOCOM 2007). It identifies a protection vulnerability in the CPDA protocol and proposes a mechanism to plug that vulnerability. To demonstrate the need of protection in aggregation process, the chapter further presents various threats in WSN aggregation mechanisms. A large number of existing protocols for secure aggregation in WSN are discussed briefly and a protocol is proposed for secure aggregation which can detect false data injected by malicious guest in a WSN. The performance of the protocol is also presented. The chapter concludes while highlighting some future directions of research in secure data aggregation in WSNs.",cs.CR cs.NI
"We confront exact analytical predictions for the finite-volume scaling of the chiral condensate with data from quenched lattice gauge theory simulations. Using staggered fermions in both the fundamental and adjoint representations, and gauge groups SU(2) and SU(3), we are able to test simultaneously all of the three chiral universality classes. With overlap fermions we also test the predictions for gauge field sectors of non-zero topological charge. Excellent agreement is found in most cases, and the deviations are understood in the others.",hep-lat
"We confront exact analytical predictions for the finite-volume scaling of the chiral condensate with data from quenched lattice gauge theory simulations. Using staggered fermions in both the fundamental and adjoint representations, and gauge groups SU(2) and SU(3), we are able to psychometric test simultaneously all of the three chiral universality classes. With lap fermions we also psychometric test the predictions for gauge field sectors of non-zero topological charge. Excellent agreement is found in most cases, and the deviations are understood in the others.",hep-lat
"A new energy and enstrophy conserving scheme is evaluated using a suite of test cases over the global spherical domain or bounded domains. The evaluation is organized around a set of pre-defined properties: accuracy of individual opeartors, accuracy of the whole scheme, conservation, control of the divergence variable, representation of the energy and enstrophy spectra, and simulation of nonlinear dynamics. The results confirm that the scheme is between the first and second order accurate, and conserves the total energy and potential enstrophy up to the time truncation errors. The scheme is capable of producing more physically realistic energy and enstrophy spectra, indicating that the new scheme can help prevent the unphysical energy cascade towards the finest resolvable scales. With an optimal representation of the dispersive wave relations, the scheme is able to keep the flow close to being non-divergent, maintain the geostrophically balanced structures with large-scale geophysical flows over long-term simulations.",cs.NA math.NA physics.ao-ph physics.geo-ph
"A new energy and enstrophy conserving scheme is evaluated using a suite of test cases over the global spherical domain or bounded domains. The evaluation is organized around a set of pre-defined properties: accuracy of single opeartors, accuracy of the whole scheme, conservation, control of the divergence variable, representation of the energy and enstrophy spectra, and simulation of nonlinear dynamics. The results confirm that the scheme is between the first and second order accurate, and conserves the total energy and potential enstrophy up to the time truncation errors. The scheme is capable of producing more physically realistic energy and enstrophy spectra, indicating that the new scheme can help prevent the unphysical energy cascade towards the finest resolvable scales. With an optimal representation of the dispersive wave relations, the scheme is able to keep the flow close to being non-divergent, assert the geostrophically balanced structures with large-scale geophysical flows over long-term simulations.",cs.NA math.NA physics.ao-ph physics.geo-ph
Let k be an algebraically closed field of arbitrary characteristic. First we give explicit bases for the highest weight vectors for the action of GL_r x GL_s on the coordinate ring k[Mat_{rs}^m] of m-tuples of r x s-matrices. It turns out that this is done most conveniently by giving an explicit good GL_r x GL_s-filtration on k[Mat_{rs}^m]. Then we deduce from this result explicit spanning sets of the k[Mat_n]^{GL_n}-modules of highest weight vectors in the coordinate ring k[Mat_n] under the conjugation action of GL_n.,math.RT
Let k be an algebraically closed field of arbitrary characteristic. First we give denotative bases for the highest weight vectors for the action of GL_r x GL_s on the coordinate ring k[Mat_{rs}^m] of m-tuples of r x s-matrices. It move around out that this is done most conveniently by giving an denotative good GL_r x GL_s-filtration on k[Mat_{rs}^m]. Then we deduce from this result denotative spanning sets of the k[Mat_n]^{GL_n}-modules of highest weight vectors in the coordinate ring k[Mat_n] under the conjugation action of GL_n.,math.RT
"Deciding whether a diagram of a knot can be untangled with a given number of moves (as a part of the input) is known to be NP-complete. In this paper we determine the parameterized complexity of this problem with respect to a natural parameter called defect. Roughly speaking, it measures the efficiency of the moves used in the shortest untangling sequence of Reidemeister moves. We show that the II- moves in a shortest untangling sequence can be essentially performed greedily. Using that, we show that this problem belongs to W[P] when parameterized by the defect. We also show that this problem is W[P]-hard by a reduction from Minimum axiom set.",cs.CC cs.CG math.GT
"Deciding whether a diagram of a knot can be untangled with a give number of moves (as a set off of the input) is known to be NP-complete. In this paper we determine the parameterized complexity of this problem with respect to a natural parameter called defect. Roughly speaking, it measures the efficiency of the moves used in the shortest untangling sequence of Reidemeister moves. We show that the II- moves in a shortest untangling sequence can be essentially performed greedily. Using that, we show that this problem belongs to W[P] when parameterized by the defect. We also show that this problem is W[P]-hard by a reduction from Minimum axiom set.",cs.CC cs.CG math.GT
"In previous publications [arXiv:1608.08430, arXiv:1704.06502], the authors have proposed Debye-H\""uckel-approximate free-energy functionals of the pair distribution functions for one-component fluid and two-component plasmas. These functionals yield the corresponding Debye-H\""uckel integral equations when they are minimized with respect to the pair distribution functions, lead to correct thermodynamic relations and fulfill the virial theorem. In the present addendum, we update our results by providing simpler functionals that have the same properties. We relate these functionals to the approaches of Lado [Phys. Rev. A 8:2548, 1973] and of Olivares and McQuarrie [J. Chem. Phys. 65:3604, 1976]. We also discuss briefly the non-uniqueness issue that is raised by these results.",physics.chem-ph physics.plasm-ph
"In previous publications [arXiv:1608.08430, arXiv:1704.06502], the authors have proposed Debye-H\""uckel-approximate free-energy functionals of the pair distribution functions for one-component fluid and two-component plasmas. These functionals ease up the corresponding Debye-H\""uckel integral par when they are minimized with respect to the pair distribution functions, lead to correct thermodynamic relations and fulfill the virial theorem. In the present addendum, we update our results by providing simpler functionals that have the same properties. We relate these functionals to the approaches of Lado [Phys. Rev. A 8:2548, 1973] and of Olivares and McQuarrie [J. Chem. Phys. 65:3604, 1976]. We also discuss briefly the non-uniqueness issue that is raised by these results.",physics.chem-ph physics.plasm-ph
"A number of studies of WMAP and Planck have highlighted that the power at the low multipoles in CMB power spectrum are lower than their theoretically predicted values. Possible angular correlation between the orientations of these low multipoles have also been claimed. It is important to investigate the possibility that the power deficiency at low multipoles may not be of primordial origin and is only an observation artifact coming from the scan procedure adapted in the WMAP or Planck satellites. Therefore, its always important to investigate all the observational artifacts that can mimic them. The CMB dipole which is almost 550 times higher than the quadrupole can leak to the higher multipoles due to the non-symmetric beam shape of the WMAP. In this paper a formalism has been developed and simulations are carried out to study the effect of the non-symmetric beam on this power transfer. It is interesting to observed that a small but non-negligible amount of power from the dipole can get transferred to the quadrupole and the higher multipoles due to the non-symmetric beam. It is shown that in case of WMAP scan strategy the shape of the quadrupole coming due to this power leakage is very much similar to the observed quadrupole from WMAP data. Simulations have also been carried out for Planck scan strategy. It is seen that for Planck scan strategy the power transfer is not only limited to the quadrupole but also to a few higher low multipoles. Since the actual beam shapes of Planck are not publicly available we present results in terms of upper limits on asymmetric beam parameters that would contaminate of the quadrupole power at the level of $1\mu K$.",astro-ph.CO
"A act of studies of WMAP and Planck have highlighted that the power at the low multipoles in CMB power spectrum are lower than their theoretically predicted values. Possible angular correlation between the orientations of these low multipoles have too been claimed. It is important to investigate the possibility that the power deficiency at low multipoles may not be of primordial origin and is only an observation artifact coming from the scan procedure adapted in the WMAP or Planck satellites. Therefore, its always important to investigate all the observational artifacts that can mimic them. The CMB dipole which is almost 550 times higher than the quadrupole can leak to the higher multipoles due to the non-symmetric beam shape of the WMAP. In this paper a formalism has been developed and simulations are carried out to study the effect of the non-symmetric beam on this power transfer. It is interesting to observed that a small but non-negligible amount of power from the dipole can get transferred to the quadrupole and the higher multipoles due to the non-symmetric beam. It is shown that in case of WMAP scan strategy the shape of the quadrupole coming due to this power leakage is very much similar to the observed quadrupole from WMAP data. Simulations have too been carried out for Planck scan strategy. It is seen that for Planck scan strategy the power transfer is not only limited to the quadrupole but too to a few higher low multipoles. Since the actual beam shapes of Planck are not publicly available we present results in terms of upper limits on asymmetric beam parameters that would contaminate of the quadrupole power at the level of $1\mu K$.",astro-ph.CO
We construct a Stratonovich-Weyl correspondence for each generic representation of a Heisenberg motion group by using the Weyl calculus on the Fock space.,math.RT
We construct a Stratonovich-Weyl correspondence for each generic mental representation of a Heisenberg motion group by using the Weyl concretion on the Fock space.,math.RT
"In this paper a new distribution is proposed. This new model provides more flexibility to modeling data with upside-down bathtub hazard rate function. A significant account of mathematical properties of the new distribution is presented. The maximum likelihood estimators for the parameters in the presence of complete and censored data are presented. Two corrective approaches are considered to derive modified estimators that are bias-free to second order. A numerical simulation is carried out to examine the efficiency of the bias correction. Finally, an application using a real data set is presented in order to illustrate our proposed distribution.",math.ST stat.TH
"In this paper a new distribution is proposed. This new model provides more flexibility to modeling data with upside-down bathtub hazard rate function. A significant account of mathematical properties of the new distribution is presented. The maximum likelihood estimator for the parameters in the presence of complete and censored data are presented. Two corrective approach path are considered to derive modified estimator that are bias-free to second order. A numerical simulation is carried out to examine the efficiency of the bias correction. Finally, an application using a real data set is presented in order to illustrate our proposed distribution.",math.ST stat.TH
"A procedure is introduced for deriving a coarse-grained dissipative particle dynamics from molecular dynamics. The rules of the dissipative particle dynamics are derived from the underlying molecular interactions, and a Langevin equation is obtained that describes the forces experienced by the dissipative particles and specifies the associated canonical Gibbs distribution for the system.",cond-mat.soft cond-mat.stat-mech
"A procedure is premise for deriving a coarse-grained dissipative particle dynamics from molecular dynamics. The rules of the dissipative particle dynamics are derived from the underlying molecular interactions, and a Langevin equation is obtained that describes the forces experienced by the dissipative particles and specifies the associated canonical Gibbs statistical distribution for the system.",cond-mat.soft cond-mat.stat-mech
"For a product of Hadamard spaces $X=X_1\times X_2$ on which some group $G\subset Is(X_1)\times Is(X_2)$ acting, G. Link arXiv:1107.3755v1 introduced the growth rate $\delta_{\theta}$ of slope $\theta$ to construct a $G-$invariant $(b,\theta)$-density. First, we show that $\delta_{\theta}$ is continuous in the slope $\theta$ as the above group action with some mild condition. Second, we give a negative answer to a question raised by G. Link in \cite{1} in general. And further results about the question are discussed. In the end, we can extent the $(b,\theta)$-densities in some reasonable condition.",math.GR
"For a product of Hadamard spaces $X=X_1\times X_2$ on which some group $G\subset Is(X_1)\times Is(X_2)$ acting, G. Link arXiv:1107.3755v1 introduced the growth rate $\delta_{\theta}$ of slope $\theta$ to construct a $G-$invariant $(b,\theta)$-density. First, we show that $\delta_{\theta}$ is continuous in the slope $\theta$ as the above group action with some mild condition. Second, we give a negative answer to a question get up by G. Link in \cite{1} in general. And further solution about the question are discussed. In the end, we can extent the $(b,\theta)$-densities in some reasonable condition.",math.GR
"A graph G is (a:b)-colorable if there exists an assignment of b-element subsets of {1,...,a} to vertices of G such that sets assigned to adjacent vertices are disjoint. We show that every planar graph without cycles of length 4 or 5 is (11:3)-colorable, a weakening of recently disproved Steinberg's conjecture. In particular, each such graph with n vertices has an independent set of size at least 3n/11.",math.CO
"A graphical record G is (a:b)-colorable if there exists an assignment of b-element subsets of {1,...,a} to vertices of G such that sets assigned to adjacent vertices are disjoint. We show that every planar graphical record without cycles of length 4 or 5 is (11:3)-colorable, a countermine of recently disproved Steinberg's conjecture. In particular, each such graphical record with n vertices has an independent set of size at least 3n/11.",math.CO
"We analyze the parametric structure of Twin Higgs (TH) theories and assess the gain in fine tuning which they enable compared to extensions of the Standard Model with colored top partners. Estimates show that, at least in the simplest realizations of the TH idea, the separation between the mass of new colored particles and the electroweak scale is controlled by the coupling strength of the underlying UV theory, and that a parametric gain is achieved only for strongly-coupled dynamics. Motivated by this consideration we focus on one of these simple realizations, namely composite TH theories, and study how well such constructions can reproduce electroweak precision data. The most important effect of the Twin states is found to be the infrared contribution to the Higgs quartic coupling, while direct corrections to electroweak observables are sub-leading and negligible. We perform a careful fit to the electroweak data including the leading-logarithmic corrections to the Higgs quartic up to three loops. Our analysis shows that agreement with electroweak precision tests can be achieved with only a moderate amount of tuning, in the range 5-10\%, in theories where colored states have mass of order 3-5 TeV and are thus out of reach of the LHC. For these levels of tuning, larger masses are excluded by a perturbativity bound, which makes these theories possibly discoverable, hence falsifiable, only at a future 100 TeV collider.",hep-ph
"We analyze the parametric structure of Twin Higgs (TH) theories and assess the gain in fine tuning which they enable compared to extensions of the Standard Model with colored top partners. Estimates evidence that, at least in the simplest realizations of the TH idea, the separation between the mass of new colored particles and the electroweak scale is controlled by the coupling strength of the underlying UV theory, and that a parametric gain is achieved only for strongly-coupled dynamics. Motivated by this consideration we focus on one of these simple realizations, namely composite TH theories, and study how well such constructions can reproduce electroweak precision data. The near important effect of the Twin states is found to be the infrared contribution to the Higgs quartic coupling, while direct corrections to electroweak observables are sub-leading and negligible. We perform a careful fit to the electroweak data including the leading-logarithmic corrections to the Higgs quartic up to three loops. Our analysis shows that agreement with electroweak precision tests can be achieved with only a moderate amount of tuning, in the range 5-10\%, in theories where colored states have mass of order 3-5 TeV and are thus out of reach of the LHC. For these levels of tuning, larger masses are excluded by a perturbativity bound, which makes these theories possibly discoverable, hence falsifiable, only at a future 100 TeV collider.",hep-ph
"We have made an 8.7 GHz image of a sky region with a resolution of 8 arcmin and high brightness sensitivity using the Australia Telescope Compact Array (ATCA). in an ultra compact configuration. The foreground discrete-source confusion was estimated from observations with higher resolution at the same frequency and in a scaled array at a lower frequency. Following the subtraction of the foreground confusion, the field shows no features in excess of the instrument noise. This limits the CMB anisotropy flat-band power to Q_flat < 23.6 microK with 95 per cent confidence; the ATCA filter function F_l in multipole l-space peaks at l_eff = 4700 and has half maximum values at l = 3350 and 6050.",astro-ph
"We have made an 8.7 GHz look-alike of a sky region with a resolution of 8 arcmin and high brightness sensitivity using the Australia Telescope Compact Array (ATCA). in an ultra compact configuration. The foreground discrete-source confusion was estimated from observations with higher resolution at the same frequency and in a scaled array at a lower frequency. Following the subtraction of the foreground confusion, the field of study shows no features in excess of the instrument noise. This limits the CMB anisotropy flat-band power to Q_flat < 23.6 microK with 95 per cent confidence; the ATCA filter function F_l in multipole l-space peaks at l_eff = 4700 and has half maximum values at l = 3350 and 6050.",astro-ph
"The Local Volume dwarf galaxy DDO 68, from the spectroscopy of its two brightest HII regions (Knots 1 and 2) was designated as the second most metal-poor star-forming galaxy [12+log(O/H)=7.14]. In the repeated spectral observations in 2008 January with the 6-m telescope (BTA) of the HII region Knot 3 [having 12+log(O/H)=7.10+-0.06], we find a strong evidence of a transient event related to a massive star evolution. From the follow-up observation with the higher spectral resolution in 2008 February, we confirm this phenomenon, and give parameters of its emission-line spectrum comprising of Balmer HI and HeI lines. The luminosities of the strongest transient lines (Ha, Hb) are of a few 10^36 erg s^-1. We also detected an additional continuum component in the new spectrum of Knot 3, which displays the spectral energy distribution raising to ultraviolet. The estimate of the flux of this continuum leads us to its absolute V-band magnitude of ~-7.1. Based on the spectral properties of this transient component, we suggest that it is related to an evolved massive star of luminous blue variable type with Z=Zo/36. We briefly discuss observational constraints on parameters of this unique (in the aspect of the record low metallicity of the progenitor massive star) event and propose several lines of its study.",astro-ph
"The Local Volume dwarf galaxy DDO 68, from the spectroscopy of its two brightest HII regions (Knots 1 and 2) was designated as the second most metal-poor star-forming galaxy [12+log(O/H)=7.14]. In the repeated spectral observation in 2008 January with the 6-m telescope (BTA) of the HII region Knot 3 [having 12+log(O/H)=7.10+-0.06], we find a strong evidence of a transient event related to a massive star evolution. From the follow-up observation with the higher spectral resolution in 2008 February, we confirm this phenomenon, and give parameters of its emission-line spectrum comprising of Balmer HI and HeI lines. The luminosities of the strongest transient lines (Ha, Hb) are of a few 10^36 erg s^-1. We also detected an additional continuum component in the new spectrum of Knot 3, which displays the spectral energy distribution raising to ultraviolet. The estimate of the flux of this continuum leads us to its absolute V-band magnitude of ~-7.1. Based on the spectral properties of this transient component, we suggest that it is related to an evolved massive star of luminous blue variable type with Z=Zo/36. We briefly discourse observational constraints on parameters of this unique (in the aspect of the record low metallicity of the progenitor massive star) event and propose several lines of its study.",astro-ph
"This paper presents an interactive implementation which makes the link between a human operator and a system of a administration of a relational databases MySQL. This application conceived as a multimedia presentations is illustrative for the way in which the transfer and the remaking of the information between the human operator, the module of data processing and the database which stores the informations can be solved (with help of the PHP language and the web use).",cs.HC
"This paper demo an interactive implementation which pretend the link between a human operator and a system of a administration of a relational databases MySQL. This application conceived as a multimedia presentations is illustrative for the way in which the transfer and the remaking of the information between the human operator, the module of data processing and the database which stores the informations can be solved (with help of the PHP language and the web use).",cs.HC
"We present a system exhibiting giant proximity effects which parallel observations in superfluid helium (Perron et al, Nature Physics V. 6, 499 (2010)) and give a theoretical explanation of these phenomena based on the mesoscopic picture of phase coexistence in finite systems. Our theory is confirmed by MC simulation studies. Our work demonstrates that such action-at-a-distance can occur in classical systems involving simple or complex fluids, such as colloid-polymer mixtures, or ferromagnets.",cond-mat.soft cond-mat.stat-mech
"We present a system exhibiting giant proximity effects which parallel observations in superfluid helium (Perron et al, Nature Physics V. 6, 499 (2010)) and give a theoretical explanation of these phenomena based on the mesoscopic picture of phase coexistence in finite systems. Our theory is substantiate by MC simulation studies. Our put to work demonstrates that such action-at-a-distance can occur in classical systems involving simple or complex fluids, such as colloid-polymer mixtures, or ferromagnets.",cond-mat.soft cond-mat.stat-mech
"We briefly review the current status of standard oscillations of atmospheric neutrinos in schemes with two, three, and four flavor mixing. It is shown that, although the pure \nu_\mu-->\nu_\tau channel provides an excellent 2\nu fit to the data, one cannot exclude, at present, the occurrence of additional subleading \nu_\mu-->\nu_e oscillations (3\nu schemes) or of sizable \nu_\mu-->\nu_s oscillations (4\nu schemes). It is also shown that the wide dynamical range of energy and pathlength probed by the Super-Kamiokande experiment puts severe constraints on nonstandard explanations of the atmospheric neutrino data, with a few notable exceptions.",hep-ph
"We briefly review the current status of standard oscillations of atmospheric neutrinos in schemes with two, three, and four flavor mixing. It is shown that, although the pure \nu_\mu-->\nu_\tau channel provides an excellent 2\nu fit to the data, one cannot exclude, at present, the natural event of additional subleading \nu_\mu-->\nu_e oscillations (3\nu schemes) or of sizable \nu_\mu-->\nu_s oscillations (4\nu schemes). It is likewise shown that the wide dynamical range of energy and pathlength probed by the Super-Kamiokande experiment puts severe constraints on nonstandard explanations of the atmospheric neutrino data, with a few notable exceptions.",hep-ph
"Conditions for the existence of flows with non-null shear-free and expansion-free velocities in spaces with affine connections and metrics are found. On their basis, generalized Weyl's spaces with shear-free and expansion-free conformal Killing vectors as velocity's vectors of spinless test particles moving in a Weyl's space are considered. The necessary and sufficient conditions are found under which a free spinless test particle could move in spaces with affine connections and metrics on a curve described by means of an auto-parallel equation. In Weyl's spaces with Weyl's covector, constructed by the use of a dilaton field, the dilaton field appears as a scaling factor for the rest mass density of the test particle. PACS numbers: 02.40.Ky, 04.20.Cv, 04.50.+h, 04.90.+e",gr-qc
"Conditions for the existence of flows with non-null shear-free and expansion-free velocities in spaces with affine connections and metrics are found. On their basis, generalized Weyl's spaces with shear-free and expansion-free conformal Killing vectors as velocity's vectors of spinless test particles proceed in a Weyl's space are considered. The necessary and sufficient conditions are found under which a spare spinless test particle could move in spaces with affine connections and metrics on a curve described by means of an auto-parallel equation. In Weyl's spaces with Weyl's covector, constructed by the use of a dilaton field, the dilaton field appears as a scaling factor for the rest mass density of the test particle. PACS numbers: 02.40.Ky, 04.20.Cv, 04.50.+h, 04.90.+e",gr-qc
"We consider an old question of Slaman and Steel: whether Turing equivalence is an increasing union of Borel equivalence relations none of which contain a uniformly computable infinite sequence. We show this question is deeply connected to problems surrounding Martin's conjecture, and also in countable Borel equivalence relations. In particular, if Slaman and Steel's question has a positive answer, it implies there is a universal countable Borel equivalence which is not uniformly universal, and that there is a $(\equiv_T,\equiv_m)$-invariant function which is not uniformly invariant on any pointed perfect set.",math.LO
"We consider an old question of Slaman and Steel: whether Turing equivalence is an increasing union of Borel equivalence relations none of which contain a uniformly computable infinite sequence. We show this question is deeply connected to problem surrounding Martin's conjecture, and besides in countable Borel equivalence relations. In particular, if Slaman and Steel's question has a positive answer, it implies there is a universal countable Borel equivalence which is not uniformly universal, and that there is a $(\equiv_T,\equiv_m)$-invariant function which is not uniformly invariant on any pointed perfect set.",math.LO
"The general expression of the angular distance between two point sources as measured by an arbitrary observer is given. The modelling presented here is rigorous, covariant and valid in any space-time. The sources of light may be located at a finite distance from the observer. The aberration and the gravitational deflection of light are treated in a unified way. Assuming the gravitational field to be weak, an explicit expansion of the angular separation within the post-post-Minkowskian approximation is carried out. The angular separation within the post-Newtonian approximation truncated at the order $1/c^3$ is straightforwardly derived.",gr-qc
"The world-wide expression of the angular distance between two point sources as measured by an arbitrary observer is given. The modelling presented here is rigorous, covariant and valid in any space-time. The sources of light may be located at a finite distance from the observer. The aberration and the gravitational deflection of light are treated in a unified way. Assuming the gravitational field to be weak, an explicit expanding upon of the angular separation within the post-post-Minkowskian approximation is carried out. The angular separation within the post-Newtonian approximation truncated at the order $1/c^3$ is straightforwardly derived.",gr-qc
"Many recent observations give restrictions to the equation of state (EOS) for high-density matter. Theoretical studies are needed to try to elucidate these EOSs at high density and/or temperature. With the many known rapidly rotating neutron stars, e.g., pulsars, several theoretical studies have tried to take into account the effects of rotation. In our study of these systems, we find that one of our EOSs is consistent with recent observation, whereas the other is inconsistent.",astro-ph.HE
"Many recent observations give restrictions to the equation of state (EOS) for high-density matter. Theoretical studies are needed to try to elucidate these EOSs at high density and/or temperature. With the many known rapidly rotating neutron stars, e.g., pulsars, various theoretic studies have tried to take into account the effects of rotation. In our study of these systems, we find that one of our EOSs is consistent with recent observation, whereas the other is inconsistent.",astro-ph.HE
"We present Spitzer infrared, GALEX UV, and SDSS and SARA optical images of the peculiar interacting galaxy pair Arp 285 (NGC 2856/4), and compare with a new numerical model of the interaction. We estimate the ages of clumps of star formation in these galaxies using population synthesis models, carefully considering the uncertainties on these ages. This system contains a striking example of `beads on a string': a series of star formation complexes ~1 kpc apart. These `beads' are found in a tail-like feature that is perpendicular to the disk of NGC 2856, which implies that it was formed from material accreted from the companion NGC 2854. The extreme blueness of the optical/UV colors and redness of the mid-infrared colors implies very young stellar ages (~4 - 20 Myrs) for these star forming regions. Spectral decomposition of these `beads' shows excess emission above the modeled stellar continuum in the 3.6 micron and 4.5 micron bands, indicating either contributions from interstellar matter to these fluxes or a second older stellar population. These clumps have -12.0 < M(B) < -10.6, thus they are less luminous than most dwarf galaxies. Our model suggests that bridge material falling into the potential of the companion overshoots the companion. The gas then piles up at apo-galacticon before falling back onto the companion, and star formation occurs in the pile-up. A luminous (M(B) ~ -13.6) extended (FWHM ~ 1.3 kpc) `bright spot' is visible at the northwestern edge of the NGC 2856 disk, with an intermediate stellar population (400 - 1500 Myrs). Our model suggests that this feature is part of a expanding ripple-like `arc' created by an off-center ring-galaxy-like collision between the two disks.",astro-ph
"We present Spitzer infrared, GALEX UV, and SDSS and SARA optical images of the peculiar interacting galaxy pair Arp 285 (NGC 2856/4), and compare with a new numerical model of the interaction. We estimate the ages of clumps of star formation in these galaxies using population synthesis models, carefully considering the uncertainties on these ages. This system contains a striking example of `beads on a string': a series of star formation complexes ~1 kpc apart. These `beads' are found in a tail-like feature that is perpendicular to the disk of NGC 2856, which implies that it was formed from material accreted from the companion NGC 2854. The extreme blueness of the optical/UV colors and redness of the mid-infrared colors implies very young stellar ages (~4 - 20 Myrs) for these star forming regions. Spectral decomposition of these `beads' shows excess emission above the modeled stellar continuum in the 3.6 micron and 4.5 micron bands, indicating either contributions from interstellar matter to these fluxes or a second older stellar population. These clumps possess -12.0 < M(B) < -10.6, thus they are less luminous than most dwarf galaxies. Our model suggests that bridge material falling into the potential of the companion overshoots the companion. The gas then passel up at apo-galacticon before falling back onto the companion, and star formation occurs in the pile-up. A luminous (M(B) ~ -13.6) extended (FWHM ~ 1.3 kpc) `bright spot' is visible at the northwestern edge of the NGC 2856 disk, with an intermediate stellar population (400 - 1500 Myrs). Our model suggests that this feature is part of a expanding ripple-like `arc' created by an off-center ring-galaxy-like collision between the two disks.",astro-ph
"Natural structural materials, such as bone and wood, can autonomously adapt their mechanical properties in response to loading to prevent failure. They smartly control the addition of material in locations of high stress by utilizing locally available resources guided by biological signals. On the contrary, synthetic structural materials have unchanging mechanical properties limiting their mechanical performance and service life. Here, a material system that autonomously adapts its mechanical properties in response to mechanical loading is reported inspired by the mineralization process of bone. It is observed that charges from piezoelectric scaffolds can induce mineralization from media with mineral ions. The material system adapts to mechanical loading by inducing mineral deposition in proportion to the magnitude of the loading and the resulting piezoelectric charges. Moreover, the mechanism allows a simple one-step route for making graded materials by controlling stress distribution along the scaffold. The findings can pave the way for a new class of self-adaptive materials that reinforce the region of high stress or induce deposition of minerals on the damaged areas from the increase in stress to prevent/mitigate failure. They can also contribute to addressing the current challenges of synthetic materials for load-bearing applications from self-adaptive capabilities.",cond-mat.mtrl-sci cond-mat.soft nlin.AO physics.app-ph
"Natural structural materials, such as bone and wood, can autonomously adapt their mechanical properties in reply to loading to prevent failure. They smartly control the addition of material in locations of high stress by utilizing locally available resources guided by biological signals. On the contrary, synthetic structural materials have unchanging mechanical properties limiting their mechanical performance and service life. Here, a material system that autonomously adapts its mechanical properties in reply to mechanical loading is reported inspired by the mineralization process of bone. It is observed that charges from piezoelectric scaffolds can induce mineralization from media with mineral ions. The material system adapts to mechanical loading by inducing mineral deposit in proportion to the magnitude of the loading and the resulting piezoelectric charges. Moreover, the mechanism allows a simple one-step route for making graded materials by controlling stress distribution along the scaffold. The findings can pave the way for a new class of self-adaptive materials that reinforce the region of high stress or induce deposit of minerals on the damaged areas from the increase in stress to prevent/mitigate failure. They can also contribute to addressing the current challenges of synthetic materials for load-bearing applications from self-adaptive capabilities.",cond-mat.mtrl-sci cond-mat.soft nlin.AO physics.app-ph
"Results on the Prandtl-Blasius type kinetic and thermal boundary layer thicknesses in turbulent Rayleigh-B\'enard convection in a broad range of Prandtl numbers are presented. By solving the laminar Prandtl-Blasius boundary layer equations, we calculate the ratio of the thermal and kinetic boundary layer thicknesses, which depends on the Prandtl number Pr only. It is approximated as $0.588Pr^{-1/2}$ for $Pr\ll Pr^*$ and as $0.982 Pr^{-1/3}$ for $Pr^*\ll\Pr$, with $Pr^*= 0.046$. Comparison of the Prandtl--Blasius velocity boundary layer thickness with that evaluated in the direct numerical simulations by Stevens, Verzicco, and Lohse (J. Fluid Mech. 643, 495 (2010)) gives very good agreement. Based on the Prandtl--Blasius type considerations, we derive a lower-bound estimate for the minimum number of the computational mesh nodes, required to conduct accurate numerical simulations of moderately high (boundary layer dominated) turbulent Rayleigh-B\'enard convection, in the thermal and kinetic boundary layers close to bottom and top plates. It is shown that the number of required nodes within each boundary layer depends on Nu and Pr and grows with the Rayleigh number Ra not slower than $\sim\Ra^{0.15}$. This estimate agrees excellently with empirical results, which were based on the convergence of the Nusselt number in numerical simulations.",physics.flu-dyn
"Results on the Prandtl-Blasius type kinetic and thermal boundary layer thicknesses in riotous Rayleigh-B\'enard convection in a broad range of Prandtl numbers are presented. By solving the laminar Prandtl-Blasius boundary layer equations, we calculate the ratio of the thermal and kinetic boundary layer thicknesses, which depends on the Prandtl number Pr only. It is approximated as $0.588Pr^{-1/2}$ for $Pr\ll Pr^*$ and as $0.982 Pr^{-1/3}$ for $Pr^*\ll\Pr$, with $Pr^*= 0.046$. Comparison of the Prandtl--Blasius velocity boundary layer thickness with that evaluated in the direct numerical simulations by Stevens, Verzicco, and Lohse (J. Fluid Mech. 643, 495 (2010)) gives very good agreement. Based on the Prandtl--Blasius type considerations, we derive a lower-bound estimate for the minimum number of the computational mesh nodes, required to conduct accurate numerical simulations of somewhat high (boundary layer dominated) riotous Rayleigh-B\'enard convection, in the thermal and kinetic boundary layers close to bottom and top plates. It is shown that the number of required nodes within each boundary layer depends on Nu and Pr and grows with the Rayleigh number Ra not slower than $\sim\Ra^{0.15}$. This estimate agrees excellently with empirical results, which were based on the convergence of the Nusselt number in numerical simulations.",physics.flu-dyn
"We review in these notes the dynamics of extended condensed matter systesm, such as vortex lattices in type-II superconductors and charge density waves in anisotropic metals, driven over quenched disorder. We focus in particular on the case of strong disorder, where topological defects are generated in the driven lattice. In this case the repsonse is plastic and the depinning transition may become discontinuous and hysteretic.",cond-mat.soft
"We review in these notes the dynamics of extended condensed count systesm, such as vortex lattices in type-II superconductors and charge density waves in anisotropic metals, driven concluded quenched disorder. We focus in particular on the case of strong disorder, where topological defects are generated in the driven lattice. In this case the repsonse is plastic and the depinning transition may become discontinuous and hysteretic.",cond-mat.soft
"General relativity has two fundamental problems that render it unsuitable for tackling the gravitational field's quantization. The first problem is the lack of a genuine gravitational variable representing gravitation only, inertial forces apart. The second problem is its incompatibility with quantum mechanics, a problem inherited from the more fundamental conflict of special relativity with quantum mechanics. A procedure to overcome these difficulties is outlined, which amounts to replacing general relativity with its teleparallel equivalent and the Poincar\'e-invariant special relativity with the de Sitter-invariant special relativity. Those replacements give rise to the de Sitter-modified teleparallel gravity, which does not have the two mentioned problems. It can thus be considered an improved alternative approach to quantum gravity.",gr-qc
"General relativity has two central problems that render it unsuitable for tackling the gravitational field's quantization. The first problem is the lack of a genuine gravitational variable representing gravitation only, inertial forces apart. The second problem is its incompatibility with quantum mechanics, a problem inherited from the more central conflict of special relativity with quantum mechanics. A procedure to overcome these difficulties is outlined, which amounts to replacing general relativity with its teleparallel equivalent and the Poincar\'e-invariant special relativity with the de Sitter-invariant special relativity. Those replacing give rise to the de Sitter-modified teleparallel gravity, which does not have the two mentioned problems. It can thus be considered an improved alternative approach to quantum gravity.",gr-qc
"The big data era is swamping areas including data analysis, machine/deep learning, signal processing, statistics, scientific computing, and cloud computing. The multidimensional feature and huge volume of big data put urgent requirements to the development of multilinear modeling tools and efficient algorithms. In this paper, we build a novel multilinear tensor space that supports useful algorithms such as SVD and QR, while generalizing the matrix space to fourth-order tensors was believed to be challenging. Specifically, given any multidimensional discrete transform, we show that fourth-order tensors are bilinear operators on a space of matrices. First, we take a transform-based approach to construct a new tensor space by defining a new multiplication operation and tensor products, and accordingly the analogous concepts: identity, inverse, transpose, linear combinations, and orthogonality. Secondly, we define the $\mathcal{L}$-SVD for fourth-order tensors and present an efficient algorithm, where the tensor case requires a stronger condition for unique decomposition than the matrix case. Thirdly, we define the tensor $\mathcal{L}$-QR decomposition and propose a Householder QR algorithm to avoid the catastrophic cancellation problem associated with the conventional Gram-Schmidt process. Finally, we validate our schemes on video compression and one-shot face recognition. For video compression, compared with the existing tSVD, the proposed $\mathcal{L}$-SVD achieves $3\sim 10$dB gains in RSE, while the running time is reduced by about $50\%$ and $87.5\%$, respectively. For one-shot face recognition, the recognition rate is increased by about $10\% \sim 20\%$.",cs.IT cs.NA math.IT
"The big data era is swamping areas including data analysis, machine/deep learning, signal processing, statistics, scientific computing, and cloud computing. The multidimensional feature and huge volume of big data put urgent requirements to the development of multilinear modeling tools and efficient algorithms. In this paper, we build a novel multilinear tensor space that supports utile algorithms such as SVD and QR, while generalizing the matrix space to fourth-order tensors was believed to be challenging. Specifically, given any multidimensional discrete transform, we show that fourth-order tensors are bilinear operators on a space of matrices. First, we take a transform-based approach to construct a new tensor space by defining a new multiplication operation and tensor products, and accordingly the analogous concepts: identity, inverse, transpose, linear combinations, and orthogonality. Secondly, we delimitate the $\mathcal{L}$-SVD for fourth-order tensors and present an efficient algorithm, where the tensor case requires a stronger condition for unique decomposition than the matrix case. Thirdly, we delimitate the tensor $\mathcal{L}$-QR decomposition and propose a Householder QR algorithm to avoid the catastrophic cancellation problem associated with the conventional Gram-Schmidt process. Finally, we validate our schemes on video compression and one-shot face recognition. For video compression, compared with the existing tSVD, the proposed $\mathcal{L}$-SVD achieves $3\sim 10$dB gains in RSE, while the running time is reduced by about $50\%$ and $87.5\%$, respectively. For one-shot face recognition, the recognition rate is increased by about $10\% \sim 20\%$.",cs.IT cs.NA math.IT
"We introduce a modification in the relativistic hamiltonian in such a way that (1) the relativistic Schr\""odinger equations can always be based on an underlying L\'evy process, (2) several families of particles with different rest masses can be selected, and finally (3) the corresponding Feynman diagrams are convergent when we have at least three different masses.",hep-ph math.PR quant-ph
"We introduce a modification in the relativistic hamiltonian in such a way that (1) the relativistic Schr\""odinger equations can always be based on an underlying L\'evy process, (2) several families of particles with different rest masses can be selected, and finally (3) the correspond richard feynman diagrams are convergent when we have at least three different masses.",hep-ph math.PR quant-ph
"Part segmentations provide a rich and detailed part-level description of objects, but their annotation requires an enormous amount of work. In this paper, we introduce CGPart, a comprehensive part segmentation dataset that provides detailed annotations on 3D CAD models, synthetic images, and real test images. CGPart includes $21$ 3D CAD models covering $5$ vehicle categories, each with detailed per-mesh part labeling. The average number of parts per category is $24$, which is larger than any existing datasets for part segmentation on vehicle objects. By varying the rendering parameters, we make $168,000$ synthetic images from these CAD models, each with automatically generated part segmentation ground-truth. We also annotate part segmentations on $200$ real images for evaluation purposes. To illustrate the value of CGPart, we apply it to image part segmentation through unsupervised domain adaptation (UDA). We evaluate several baseline methods by adapting top-performing UDA algorithms from related tasks to part segmentation. Moreover, we introduce a new method called Geometric-Matching Guided domain adaptation (GMG), which leverages the spatial object structure to guide the knowledge transfer from the synthetic to the real images. Experimental results demonstrate the advantage of our new algorithm and reveal insights for future improvement. We will release our data and code.",cs.CV
"Part segmentations provide a rich and detailed part-level description of objects, but their annotation requires an enormous amount of work. In this paper, we introduce CGPart, a comprehensive part segmentation dataset that provides detailed annotations on 3D CAD models, synthetic images, and real test images. CGPart includes $21$ 3D CAD models covering $5$ vehicle categories, each with detailed per-mesh part labeling. The average number of parts per category is $24$, which is larger than any existing datasets for part segmentation on vehicle objects. By varying the rendering parameters, we make $168,000$ synthetic images from these CAD models, each with automatically generated part segmentation ground-truth. We also annotate part segmentations on $200$ real images for evaluation purposes. To illustrate the value of CGPart, we apply it to image part segmentation through unsupervised domain adaptation (UDA). We evaluate several baseline methods by adapting top-performing UDA algorithmic program from related tasks to part segmentation. Moreover, we introduce a new method called Geometric-Matching Guided domain adaptation (GMG), which leverages the spatial object structure to guide the knowledge transfer from the synthetic to the real images. Experimental results demonstrate the advantage of our new algorithm and reveal insights for next improvement. We will release our data and code.",cs.CV
"Large-scale storage cluster systems need to manage a vast amount of data locations. A naive data locations management maintains pairs of data ID and nodes storing the data in tables. However, it is not practical when the number of pairs is too large. To solve this problem, management using data distribution algorithms, rather than management using tables, has been proposed in recent research. It can distribute data by determining the node for storing the data based on the datum ID. Such data distribution algorithms require the ability to handle the addition or removal of nodes, short calculation time and uniform data distribution in the capacity of each node. This paper proposes a data distribution algorithm called ASURA (Advanced Scalable and Uniform storage by Random number Algorithm) that satisfies these requirements. It achieves following four characteristics: 1) minimum data movement to maintain data distribution according to node capacity when nodes are added or removed, even if data are replicated, 2) roughly sub-micro-seconds calculation time, 3) much lower than 1% maximum variability between nodes in data distribution, and 4) data distribution according to the capacity of each node. The evaluation results show that ASURA is qualitatively and quantitatively competitive against major data distribution algorithms such as Consistent Hashing, Weighted Rendezvous Hashing and Random Slicing. The comparison results show benefits of each algorithm; they show that ASURA has advantage in large scale-out storage clusters.",cs.DC
"Large-scale storage cluster systems pauperism to manage a vast amount of data locations. A naive data locations management maintains pairs of data ID and nodes storing the data in tables. However, it is not practical when the number of pairs is too large. To solve this problem, management using data distribution algorithms, rather than management using tables, has been proposed in recent research. It can distribute data by determining the node for storing the data based on the datum ID. Such data distribution algorithms require the ability to handle the addition or removal of nodes, short calculation time and uniform data distribution in the capability of each node. This paper proposes a data distribution algorithm called ASURA (Advanced Scalable and Uniform storage by Random number Algorithm) that satisfies these requirements. It achieves following four characteristics: 1) minimum data movement to maintain data distribution according to node capability when nodes are added or removed, even if data are replicated, 2) roughly sub-micro-seconds calculation time, 3) much lower than 1% maximum variability between nodes in data distribution, and 4) data distribution according to the capability of each node. The evaluation results show that ASURA is qualitatively and quantitatively competitive against major data distribution algorithms such as Consistent Hashing, Weighted Rendezvous Hashing and Random Slicing. The comparison results show benefits of each algorithm; they show that ASURA has advantage in large scale-out storage clusters.",cs.DC
"A theory of light propagation through one-dimensional photonic crystals and deterministic aperiodic structures, including quasicrystals, based on doped quantum-well structures has been developed. The resonant Bragg condition, leading to the superradiant regime and formation of the widest optical reflection spectrum, has been formulated. The expressions for band gap edges for light waves in the Bragg structures have been obtained. The reflection and absorption spectra of such systems are calculated. The optical properties of the doped multiple-quantum-well structure are compared with the properties of undoped ones.",cond-mat.mes-hall cond-mat.mtrl-sci
"A theory of light propagation through one-dimensional photonic lechatelierite and deterministic aperiodic structures, including quasicrystals, based on doped quantum-well structures has been developed. The resonant Bragg condition, leading to the superradiant regime and formation of the widest optical reflection spectrum, has been formulated. The expressions for band gap edges for light waves in the Bragg structures have been obtained. The reflection and absorption spectra of such systems are calculated. The optical holding of the doped multiple-quantum-well structure are compared with the holding of undoped ones.",cond-mat.mes-hall cond-mat.mtrl-sci
"We investigate the stochastic resonance phenomena in the field-driven Ising model on small-world networks. The response of the magnetization to an oscillating magnetic field is examined by means of Monte Carlo dynamic simulations, with the rewiring probability varied. At any finite value of the rewiring probability, the system is found to undergo a dynamic phase transition at a finite temperature, giving rise to double resonance peaks. While the peak in the ferromagnetic phase grows with the rewiring probability, that in the paramagnetic phase tends to reduce, indicating opposite effects of the long-range interactions on the resonance in the two phases.",cond-mat.dis-nn
"We investigate the stochastic resonance phenomena in the field-driven Ising model on small-world networks. The response of the magnetic induction to an oscillating charismatic field is examined by means of Monte Carlo dynamic simulations, with the rewiring probability varied. At any finite value of the rewiring probability, the system is found to undergo a dynamic phase transition at a finite temperature, giving rise to double resonance peaks. While the peak in the ferromagnetic phase grows with the rewiring probability, that in the paramagnetic phase tends to reduce, indicating opposite effects of the long-range interactions on the resonance in the two phases.",cond-mat.dis-nn
"We study a generic ensemble of deep belief networks which is parametrized by the distribution of energy levels of the hidden states of each layer. We show that, within a random energy approach, statistical dependence can propagate from the visible to deep layers only if each layer is tuned close to the critical point during learning. As a consequence, efficiently trained learning machines are characterised by a broad distribution of energy levels. The analysis of Deep Belief Networks and Restricted Boltzmann Machines on different datasets confirms these conclusions.",cond-mat.dis-nn cs.LG stat.ML
"We study a generic ensemble of deep belief networks which is parametrized by the distribution of energy levels of the hidden states of each layer. We show that, within a random energy approach, statistical dependence can propagate from the visible to deep layers only if each layer is tuned close to the critical breaker point during learning. As a consequence, efficiently trained learning machines are characterised by a large-minded distribution of energy levels. The analysis of Deep Belief Networks and Restricted Boltzmann Machines on different datasets confirms these conclusions.",cond-mat.dis-nn cs.LG stat.ML
"We put forward ideas to a novel string field theory based on making some ""objects"" that essentially describe ""liberated"" left- and right- mover fields $X^{\mu}_{L}(\tau + \sigma)$ and $X^{\mu}_{R}(\tau - \sigma)$ on the string. The main progress is that we manage to make our novel string field theory provide the correct mass square spectrum for the string. An interesting detail is that we have to dispense of a species doubler caused by the discretization we introduced in our string field theory of the string right- and left- mover variables. We finally suggest how to obtain the Veneziano amplitude in our model.",hep-th
"We put frontward musical theme to a novel string field theory based on making some ""objects"" that essentially describe ""liberated"" left- and right- mover fields $X^{\mu}_{L}(\tau + \sigma)$ and $X^{\mu}_{R}(\tau - \sigma)$ on the string. The main progress is that we manage to make our novel string field theory provide the correct mass square spectrum for the string. An interesting detail is that we have to dispense of a species doubler caused by the discretization we introduced in our string field theory of the string right- and left- mover variables. We finally suggest how to obtain the Veneziano amplitude in our model.",hep-th
"We show that quasi-one-dimensional (1D) quantum wires can be written onto the surface of magnetic topological insulator (MTI) thin films by gate arrays. When the MTI is in a quantum anomalous Hall (QAH) state, MTI$/$superconductor quantum wires have especially broad stability regions for both topological and non-topological states, facilitating creation and manipulation of Majorana particles on the MTI surface.",cond-mat.mes-hall
"We show that quasi-one-dimensional (1D) quantum wires can be written onto the surface of magnetic topological insulator (MTI) thin films by logic gate arrays. When the MTI is in a quantum anomalous Hall (QAH) state, MTI$/$superconductor quantum wires have especially broad stability part for both topological and non-topological states, facilitating creation and manipulation of Majorana particles on the MTI surface.",cond-mat.mes-hall
"The perturbation of the free rigid rotator by the trigonometric Scarf potential is shown to conserve its energy excitation patterns and change only the wave functions towards spherical harmonics rescaled by a function of an unspecified parity, or mixtures of such rescaled harmonics of equal magnetic quantum numbers and different angular momenta. In effect, no parity can be assigned to the states of the rotational bands emerging in this exotic way, and the electric dipole operator is allowed to acquire non-vanishing expectation values.",hep-ph nucl-th quant-ph
"The perturbation of the free rigid rotator by the trigonometric Scarf potential is establish to conserve its energy excitation patterns and change only the wave functions towards spherical harmonics rescaled by a function of an unspecified parity, or mixtures of such rescaled harmonics of equal magnetic quantum numbers game and different angular momenta. In effect, no parity can be assigned to the states of the rotational bands emerging in this exotic way, and the electric dipole operator is allowed to acquire non-vanishing expectation values.",hep-ph nucl-th quant-ph
"This work presents the first integral field spectroscopy of the Homunculus nebula around Eta Carinae in the near-infrared spectral region (J band). We confirmed the presence of a hole on the polar region of each lobe, as indicated by previous near-IR long-slit spectra and mid-IR images. The holes can be described as a cylinder of height (i.e. the thickness of the lobe) and diameter of 6.5 and 6.0x10^{16} cm, respectively. We also mapped the blue-shifted component of He I 10830 seen towards the NW lobe. Contrary to previous works, we suggested that this blue-shifted component is not related to the Paddle but it is indeed in the equatorial disc. We confirmed the claim of Smith (2005) and showed that the spatial extent of the Little Homunculus matches remarkably well the radio continuum emission at 3 cm, indicating that the Little Homunculus can be regarded as a small HII region. Therefore, we used the optically-thin 1.3 mm radio flux to derive a lower limit for the number of Lyman-continuum photons of the central source in Eta Car. In the context of a binary system, and assuming that the ionising flux comes entirely from the hot companion star, the lower limit for its spectral type and luminosity class ranges from O5.5 III to O7 I. Moreover, we showed that the radio peak at 1.7 arcsec NW from the central star is in the same line-of-sight of the `Sr-filament' but they are obviously spatially separated, while the blue-shifted component of He I 10830 may be related to the radio peak and can be explained by the ultraviolet radiation from the companion star.",astro-ph
"This work presents the first integral field spectroscopy of the Homunculus nebula around Eta Carinae in the near-infrared spectral region (J band). We confirmed the presence of a hole on the polar region of each lobe, as indicated by previous near-IR long-slit spectra and mid-IR images. The holes can be described as a cylinder of height (i.e. the thickness of the lobe) and diameter of 6.5 and 6.0x10^{16} cm, respectively. We also mapped the blue-shifted component of He I 10830 seen towards the NW lobe. Contrary to previous works, we suggested that this blue-shifted component is not related to the Paddle but it is so in the equatorial disc. We confirmed the claim of Smith (2005) and showed that the spatial extent of the Little Homunculus matches remarkably well the radio continuum emission at 3 cm, indicating that the Little Homunculus can be regarded as a small HII region. Therefore, we used the optically-thin 1.3 mm radio flux to derive a lower limit for the number of Lyman-continuum photons of the central source in Eta Car. In the context of a binary system, and assuming that the ionize flux comes entirely from the hot companion star, the lower limit for its spectral type and luminosity class ranges from O5.5 III to O7 I. Moreover, we showed that the radio peak at 1.7 arcsec NW from the central star is in the same line-of-sight of the `Sr-filament' but they are obviously spatially separated, while the blue-shifted component of He I 10830 may be related to the radio peak and can be explained by the ultraviolet radiation from the companion star.",astro-ph
"In recent years, with the growth of online services and IoT devices, software log anomaly detection has become a significant concern for both academia and industry. However, at the time of writing this paper, almost all contributions to the log anomaly detection task, follow the same traditional architecture based on parsing, vectorizing, and classifying. This paper proposes OneLog, a new approach that uses a large deep model based on instead of multiple small components. OneLog utilizes a character-based convolutional neural network (CNN) originating from traditional NLP tasks. This allows the model to take advantage of multiple datasets at once and take advantage of numbers and punctuations, which were removed in previous architectures. We evaluate OneLog using four open data sets Hadoop Distributed File System (HDFS), BlueGene/L (BGL), Hadoop, and OpenStack. We evaluate our model with single and multi-project datasets. Additionally, we evaluate robustness with synthetically evolved datasets and ahead-of-time anomaly detection test that indicates capabilities to predict anomalies before occurring. To the best of our knowledge, our multi-project model outperforms state-of-the-art methods in HDFS, Hadoop, and BGL datasets, respectively setting getting F1 scores of 99.99, 99.99, and 99.98. However, OneLog's performance on the Openstack is unsatisfying with F1 score of only 21.18. Furthermore, Onelogs performance suffers very little from noise showing F1 scores of 99.95, 99.92, and 99.98 in HDFS, Hadoop, and BGL.",cs.LG cs.SE
"In recent years, with the growth of online services and IoT devices, software log anomaly detection has become a significant concern for both academia and industry. However, at the time of writing this paper, almost all contributions to the log anomaly detection task, follow the same traditional architecture based on parsing, vectorizing, and classifying. This paper proposes OneLog, a new approach that uses a large deep model based on instead of multiple small components. OneLog utilizes a character-based convolutional neural network (CNN) originating from traditional NLP tasks. This allows the model to take advantage of multiple datasets at once and take advantage of numbers and punctuations, which were removed in previous architectures. We evaluate OneLog using four open data sets Hadoop Distributed File System (HDFS), BlueGene/L (BGL), Hadoop, and OpenStack. We evaluate our model with single and multi-project datasets. Additionally, we evaluate robustness with synthetically evolved datasets and ahead-of-time anomaly detection test that indicates capability to predict anomalies before occurring. To the best of our knowledge, our multi-project model outperforms state-of-the-art methods in HDFS, Hadoop, and BGL datasets, respectively setting getting F1 scores of 99.99, 99.99, and 99.98. However, OneLog's performance on the Openstack is unsatisfying with F1 score of only 21.18. Furthermore, Onelogs performance suffers very little from noise testify F1 scores of 99.95, 99.92, and 99.98 in HDFS, Hadoop, and BGL.",cs.LG cs.SE
"Using the Landau-Zener-St\""uckelberg-Majorana-type (LZSM) semiclassical approach, we study both graphene and a thin film of a Weyl semimetal subjected to a strong AC electromagnetic field. The spectrum of quasi energies in the Weyl semimetal turns out to be similar to that of a graphene sheet. Earlier it has been predicted qualitatively that the transport properties of strongly-irradiated graphene oscillate as a function of the radiation intensity [S.V. Syzranov et al., Phys. Rev. B 88, 241112 (2013)]. Here we obtain rigorous quantitative results for a driven linear conductance of graphene and a thin film of a Weyl semimetal. The exact quantitative structure of oscillations exhibits two contributions. The first one is a manifestation of the Ramsauer-Townsend effect, while the second contribution is a consequence of the LZSM interference defining the spectrum of quasienergies.",cond-mat.mes-hall
"Using the Landau-Zener-St\""uckelberg-Majorana-type (LZSM) semiclassical approach, we study both graphene and a thin film of a Weyl semimetal subjected to a strong AC electromagnetic field. The spectrum of quasi energies in the Weyl semimetal turns out to be standardized to that of a graphene sheet. Earlier it has been predicted qualitatively that the transport properties of strongly-irradiated graphene oscillate as a function of the radiation intensity [S.V. Syzranov et al., Phys. Rev. B 88, 241112 (2013)]. Here we obtain rigorous quantitative results for a driven linear conductance of graphene and a thin film of a Weyl semimetal. The exact quantitative structure of oscillations exhibits two contributions. The first one is a manifestation of the Ramsauer-Townsend effect, patch the second contribution is a consequence of the LZSM interference defining the spectrum of quasienergies.",cond-mat.mes-hall
"We consider two variations on the Mandelbrot fractal percolation model. In the k-fractal percolation model, the d-dimensional unit cube is divided in N^d equal subcubes, k of which are retained while the others are discarded. The procedure is then iterated inside the retained cubes at all smaller scales. We show that the (properly rescaled) percolation critical value of this model converges to the critical value of ordinary site percolation on a particular d-dimensional lattice as N tends to infinity. This is analogous to the result of Falconer and Grimmett that the critical value for Mandelbrot fractal percolation converges to the critical value of site percolation on the same d-dimensional lattice. In the fat fractal percolation model, subcubes are retained with probability p_n at step n of the construction, where (p_n) is a non-decreasing sequence with \prod p_n > 0. The Lebesgue measure of the limit set is positive a.s. given non-extinction. We prove that either the set of connected components larger than one point has Lebesgue measure zero a.s. or its complement in the limit set has Lebesgue measure zero a.s.",math.PR
"We consider two magnetic variation on the Mandelbrot fractal percolation model. In the k-fractal percolation model, the d-dimensional unit cube is divided in N^d equal subcubes, k of which are retained while the others are discarded. The procedure is then iterated inside the retained cubes at all smaller scales. We show that the (properly rescaled) percolation critical value of this model converges to the critical value of ordinary site percolation on a particular d-dimensional lattice as N tends to infinity. This is analogous to the result of Falconer and Grimmett that the critical value for Mandelbrot fractal percolation converges to the critical value of site percolation on the same d-dimensional lattice. In the fat fractal percolation model, subcubes are retained with probability p_n at step n of the construction, where (p_n) is a non-decreasing sequence with \prod p_n > 0. The Lebesgue measure of the limit set is positive a.s. give way non-extinction. We prove that either the set of connected components larger than one point has Lebesgue measure zero a.s. or its complement in the limit set has Lebesgue measure zero a.s.",math.PR
"The fifth generation wireless networks focus on the design of low latency, high data rate, high reliability, and massive connectivity communications. Non-orthogonal multiple access (NOMA) is an essential enabling technology to accommodate the wide range of communication requirements. By coordinating the massive devices within the same resource block on power domain, frequency domain or code domain, NOMA is superior to conventional orthogonal multiple access in terms of the network connectivity, the throughputs of system and etc. Sparse code multiple access (SCMA) is a kind of multi-carrier code domain NOMA and has been studied extensively. The challenges for designing a high quality SCMA system is to seek the feasible encoding and decoding schemes to meet the desired requirements. In this article, we present some recent progresses towards the design of multi-dimensional codebooks, the practical low complexity decoder, as well as the Grant-Free multiple access for SCMA system. In particular, we show how the SCMA codebooks construction are motived by the combined design of multi-dimensional constellation and factor graphs. In addition, various low complexity SCMA decoders are also reviewed with a special focus on sphere decoding. Moreover, based on the framework of belief propagation, the SCMA Grant-Free transmission is introduced and the problem of collision resolution is also discussed.",eess.SP
"The fifth part generation wireless networks focus on the design of low latency, high data rate, high reliability, and massive connectivity communications. Non-orthogonal multiple access (NOMA) is an essential enabling technology to accommodate the wide range of communication requirements. By coordinating the massive devices within the same resource block on power domain, frequency domain or code domain, NOMA is superior to conventional orthogonal multiple access in terms of the network connectivity, the throughputs of system and etc. Sparse code multiple access (SCMA) is a kind of multi-carrier code domain NOMA and has been studied extensively. The challenges for designing a high quality SCMA system is to seek the feasible encoding and decoding schemes to meet the desired requirements. In this article, we present some recent progresses towards the design of multi-dimensional codebooks, the practical low complexness decoder, as well as the Grant-Free multiple access for SCMA system. In particular, we show how the SCMA codebooks construction are motived by the combined design of multi-dimensional constellation and factor graphs. In addition, various low complexness SCMA decoders are also reviewed with a special focus on sphere decoding. Moreover, based on the framework of belief propagation, the SCMA Grant-Free transmission is introduced and the problem of collision resolution is also discussed.",eess.SP
"It is shown that the resonance Kondo tunneling through a double quantum dot (DQD) with even occupation and singlet ground state may arise at a strong bias, which compensates the energy of singlet/triplet excitation. Using the renormalization group technique we derive scaling equations and calculate the differential conductance as a function of an auxiliary dc-bias for parallel DQD described by SO(4) symmetry. We analyze the decoherence effects associated with the triplet/singlet relaxation in DQD and discuss the shape of differential conductance line as a function of dc-bias and temperature.",cond-mat
"It is record that the resonance Kondo tunneling through a double quantum dot (DQD) with even occupation and singlet ground state may arise at a strong bias, which compensates the energy of singlet/triplet excitation. Using the renormalization group technique we infer scaling equations and calculate the differential conductance as a function of an auxiliary dc-bias for parallel DQD described by SO(4) symmetry. We analyze the decoherence effects associated with the triplet/singlet relaxation in DQD and discuss the shape of differential conductance line as a function of dc-bias and temperature.",cond-mat
"Phase separation in mixtures of polymers and alkanes is investigated with the aid of a recently developed lattice model, based on the Born-Green-Yvon (BGY) integral equation approach to fluids. The system-dependent parameters of the BGY lattice model for binary mixtures are deduced from those of its pure components, which in turn are determined from a comparison with experimental data. The lower critical solution temperatures (LCST's) for polyethylene in various n-alkanes were predicted from the BGY lattice model and compared with experimental data. While the model underestimates the LCST's for the smaller alkanes it reproduces the experimental values very well for the higher alkanes (decane through tridecane). The effect of the chain length of the polymer on the solubility is investigated for the case of decane as a solvent.",cond-mat.soft cond-mat.stat-mech
"phase angle separation in mixtures of polymers and alkanes is investigated with the aid of a recently developed fretwork model, based on the Born-Green-Yvon (BGY) integral equation approach to fluids. The system-dependent parameters of the BGY fretwork model for binary mixtures are deduced from those of its pure components, which in turn are determined from a comparison with experimental data. The lower critical solution temperatures (LCST's) for polyethylene in various n-alkanes were predicted from the BGY fretwork model and compared with experimental data. While the model underestimates the LCST's for the smaller alkanes it reproduces the experimental values very well for the higher alkanes (decane through tridecane). The effect of the chain length of the polymer on the solubility is investigated for the case of decane as a solvent.",cond-mat.soft cond-mat.stat-mech
"In this review, we outline the expected tests of gravity that will be achieved at cosmological scales in the upcoming decades. We focus mainly on constraints on phenomenologically parameterized deviations from general relativity, which allow to test gravity in a model-independent way, but also review some of the expected constraints obtained with more physically motivated approaches. After reviewing the state-of-the-art for such constraints, we outline the expected improvement that future cosmological surveys will achieve, focusing mainly on future large-scale structures and cosmic microwave background surveys but also looking into novel probes on the nature of gravity. We will also highlight the necessity of overcoming accuracy issues in our theoretical predictions, issues that become relevant due to the expected sensitivity of future experiments.",astro-ph.CO
"In this review, we outline the expected tests of gravity that will be achieved at cosmological scales in the approaching decades. We focus mainly on constraints on phenomenologically parameterized deviations from superior general relativity, which allow to test gravity in a model-independent way, but also review some of the expected constraints obtained with more physically motivated approaches. After reviewing the state-of-the-art for such constraints, we outline the expected improvement that future cosmological surveys will achieve, focusing mainly on future large-scale structures and cosmic microwave background surveys but also looking into novel probes on the nature of gravity. We will also highlight the necessity of overcoming accuracy issues in our theoretical predictions, issues that become relevant due to the expected sensitivity of future experiments.",astro-ph.CO
"The Chow variety of polynomials that decompose as a product of linear forms has been studied for more than 100 years. Finding equations in the ideal of secant varieties of Chow varieties would enable one to measure the complexity the permanent to prove Valiant's conjecture $\mathbf{VP\neq VNP}$. In this article, I use the method of prolongation to obtain equations for secant varieties of Chow varieties as $GL(V)$-modules.",cs.CC math.AG
"The Chow variety of polynomials that decompose as a product of linear forms has been studied for more than 100 years. happen equations in the nonesuch of secant varieties of Chow varieties would enable one to measure the complexity the permanent to prove Valiant's conjecture $\mathbf{VP\neq VNP}$. In this article, I use the method of prolongation to obtain equations for secant varieties of Chow varieties as $GL(V)$-modules.",cs.CC math.AG
"We propose a method to determine the isoscalar \bar K N scattering length on the lattice. Our method represents the generalization of L\""uscher's approach in the presence of inelastic channels (complex scattering length). In addition, the proposed approach allows one to find the position of the S-matrix pole corresponding the the Lambda(1405) resonance.",hep-lat hep-ph nucl-th
"We propose a method to determine the isoscalar \bar K N scattering length on the lattice. Our method represents the generalization of L\""uscher's approach in the presence of inelastic channels (complex scattering length). In addition, the proposed approach allows one to obtain the spot of the S-matrix pole corresponding the the Lambda(1405) resonance.",hep-lat hep-ph nucl-th
"We analyzed several basic correlations between structural parameters of galaxies. The data were taken from various samples in different passbands which are available in the literature. We discuss disc scaling relations as well as some debatable issues concerning the so-called Photometric Plane for bulges and elliptical galaxies in different forms and various versions of the famous Kormendy relation. We show that some of the correlations under discussion are artificial (self-correlations), while others truly reveal some new essential details of the structural properties of galaxies. Our main results are as follows: (1) At present, we can not conclude that faint stellar discs are, on average, more thin than discs in high surface brightness galaxies. The ``central surface brightness -- thickness'' correlation appears only as a consequence of the transparent exponential disc model to describe real galaxy discs. (2) The Photometric Plane appears to have no independent physical sense. Various forms of this plane are merely sophisticated versions of the Kormendy relation or of the self-relation involving the central surface brightness of a bulge/elliptical galaxy and the Sersic index n. (3) The Kormendy relation is a physical correlation presumably reflecting the difference in the origin of bright and faint ellipticals and bulges. We present arguments that involve creating artificial samples to prove our main idea.",astro-ph.GA
"We analyzed several basic correlations between structural parameters of galaxies. The data were taken from various samples in different passbands which are available in the literature. We discuss disc scaling relations as well as some debatable issues concerning the so-called Photometric Plane for bulges and elliptical galaxies in different forms and various versions of the famous Kormendy relation. We show that some of the correlations under discussion are artificial (self-correlations), while others truly reveal some new essential details of the structural properties of galaxies. Our main results are as follows: (1) At present, we can not conclude that faint stellar discs are, on average, more thin than discs in high airfoil brightness galaxies. The ``central airfoil brightness -- thickness'' correlation appears only as a consequence of the transparent exponential disc model to describe real galaxy discs. (2) The Photometric Plane appears to have no independent physical sense. Various forms of this plane are merely sophisticated versions of the Kormendy carnal knowledge or of the self-relation involving the central airfoil brightness of a bulge/elliptical galaxy and the Sersic index n. (3) The Kormendy carnal knowledge is a physical correlation presumably reflecting the difference in the origin of bright and faint ellipticals and bulges. We present arguments that involve creating artificial samples to prove our main idea.",astro-ph.GA
"Recently Menard et al. detected a subtle but systematic change in the mean color of quasars as a function of their projected separation from foreground galaxies, extending to comoving separations of ~10Mpc/h, which they interpret as a signature of reddening by intergalactic dust. We present theoretical models of this remarkable observation, using SPH cosmological simulations of a (50Mpc/h)^3 volume. Our primary model uses a simulation with galactic winds and assumes that dust traces the intergalactic metals. The predicted galaxy-dust correlation function is similar in form to the galaxy-mass correlation function, and reproducing the MSFR data requires a dust-to-metal mass ratio of 0.24, about half the value in the Galactic ISM. Roughly half of the reddening arises in dust that is more than 100Kpc/h from the nearest massive galaxy. We also examine a simulation with no galactic winds, which predicts a much smaller fraction of intergalactic metals (3% vs. 35%) and therefore requires an unphysical dust-to-metal ratio of 2.18 to reproduce the MSFR data. In both models, the signal is dominated by sightlines with E(g-i)=0.001-0.1. The no-wind simulation can be reconciled with the data if we also allow reddening to arise in galaxies up to several x 10^10 Msun. The wind model predicts a mean visual extinction of A_V ~0.0133 mag out to z=0.5, with a sightline-to-sightline dispersion similar to the mean, which could be significant for future supernova cosmology studies. Reproducing the MSFR results in these simulations requires that a large fraction of ISM dust survive its expulsion from galaxies and its residence in the intergalactic medium. Future observational studies that provide higher precision and measure the dependence on galaxy type and environment will allow detailed tests for models of enriched galactic outflows and the survival of IG dust.",astro-ph.CO
"Recently Menard et al. detected a subtle but systematic change in the mean color of quasars as a function of their projected separation from foreground galaxies, extending to comoving separations of ~10Mpc/h, which they interpret as a signature of reddening by intergalactic dust. We present theoretic models of this remarkable observation, using SPH cosmological simulations of a (50Mpc/h)^3 volume. Our primary model uses a simulation with galactic winds and assumes that dust traces the intergalactic metals. The predicted galaxy-dust correlation function is similar in form to the galaxy-mass correlation function, and reproducing the MSFR datum requires a dust-to-metal mass ratio of 0.24, about half the value in the Galactic ISM. Roughly half of the reddening arises in dust that is more than 100Kpc/h from the nearest massive galaxy. We also examine a simulation with no galactic winds, which predicts a much smaller fraction of intergalactic metals (3% vs. 35%) and therefore requires an unphysical dust-to-metal ratio of 2.18 to reproduce the MSFR data. In both models, the signal is dominated by sightlines with E(g-i)=0.001-0.1. The no-wind simulation can be reconciled with the datum if we also allow reddening to arise in galaxies up to several x 10^10 Msun. The wind model predicts a mean visual extinction of A_V ~0.0133 mag out to z=0.5, with a sightline-to-sightline dispersion similar to the mean, which could be significant for future supernova cosmology studies. Reproducing the MSFR results in these simulations requires that a large fraction of ISM dust survive its expulsion from galaxies and its residence in the intergalactic medium. Future observational studies that provide higher precision and measure the dependence on galaxy type and environment will allow detailed tests for models of enriched galactic outflows and the survival of IG dust.",astro-ph.CO
"We are developing a new research based assessment (RBA) focused on quantitative reasoning -- rather than conceptual understanding -- in physics contexts. We rapidly moved administration of the RBA online in Spring 2020 due to the COVID-19 pandemic. We present our experiences with online, unproctored administration of an RBA in development to students enrolled in a large-enrollment, calculus-based, introductory physics course. We describe our attempts to adhere to best practices on a limited time frame, and present a preliminary analysis of the results, comparing results from the online administration to earlier results from in-person, proctored administration. We include discussion of online administration of multiple-choice/multiple-response (MCMR) items, which we use on the instrument as a way to probe multiple facets of student reasoning. Our initial comparison indicates little difference between online and paper administrations of the RBA, consistent with previous work by other researchers.",physics.ed-ph
"We are acquire a new research based assessment (RBA) focused on quantitative reasoning -- rather than conceptual understanding -- in physics contexts. We rapidly moved administration of the RBA online in Spring 2020 due to the COVID-19 pandemic. We present our experiences with online, unproctored administration of an RBA in development to students enrolled in a large-enrollment, calculus-based, introductory physics course. We describe our attempts to adhere to best practices on a limited time frame, and present a preliminary analysis of the results, comparing results from the online administration to earlier results from in-person, proctor administration. We include discussion of online administration of multiple-choice/multiple-response (MCMR) items, which we use on the instrument as a way to probe multiple facets of student reasoning. Our initial comparison indicates little difference between online and paper administrations of the RBA, consistent with previous work by other researchers.",physics.ed-ph
"We analyze a discontinuous Galerkin FEM-BEM scheme for a second order elliptic transmission problem posed in the three-dimensional space. The symmetric variational formulation is discretized by nonconforming Raviart-Thomas finite elements on a general partition of the interior domain coupled with discontinuous boundary elements on an independent quasi-uniform mesh of the transmission interface. We prove (almost) quasi-optimal convergence of the method and confirm the theory by a numerical experiment. In addition, we consider the case when continuous rather than discontinuous boundary elements are used.",math.NA
"We analyze a discontinuous Galerkin FEM-BEM scheme for a second order ovate transmission problem posed in the three-dimensional space. The symmetric variational formulation is discretized by nonconforming Raviart-Thomas finite elements on a general partition of the interior domain coupled with discontinuous boundary elements on an independent quasi-uniform mesh of the transmission interface. We prove (almost) quasi-optimal convergence of the method and confirm the theory by a mathematical experiment. In addition, we consider the case when continuous rather than discontinuous boundary elements are used.",math.NA
"For a matroid $M$ having $m$ rank-one flats, the density $d(M)$ is $\tfrac{m}{r(M)}$ unless $m = 0$, in which case $d(M)= 0$. A matroid is density-critical if all of its proper minors of non-zero rank have lower density. By a 1965 theorem of Edmonds, a matroid that is minor-minimal among simple matroids that cannot be covered by $k$ independent sets is density-critical. It is straightforward to show that $U_{1,k+1}$ is the only minor-minimal loopless matroid with no covering by $k$ independent sets. We prove that there are exactly ten minor-minimal simple obstructions to a matroid being able to be covered by two independent sets. These ten matroids are precisely the density-critical matroids $M$ such that $d(M) > 2$ but $d(N) \le 2$ for all proper minors $N$ of $M$. All density-critical matroids of density less than $2$ are series-parallel networks. For $k \ge 2$, although finding all density-critical matroids of density at most $k$ does not seem straightforward, we do solve this problem for $k=\tfrac{9}{4}$.",math.CO
"For a matroid $M$ having $m$ rank-one flats, the density $d(M)$ is $\tfrac{m}{r(M)}$ unless $m = 0$, in which case $d(M)= 0$. A matroid is density-critical if all of its proper minors of non-zero rank have lower density. By a 1965 theorem of Edmonds, a matroid that is minor-minimal among simple matroids that cannot be covered by $k$ independent sets is density-critical. It is straightforward to show that $U_{1,k+1}$ is the only minor-minimal loopless matroid with no covering by $k$ independent sets. We prove that there are exactly ten minor-minimal simple obstructions to a matroid being able to be covered by two independent sets. These ten matroids are precisely the density-critical matroids $M$ such that $d(M) > 2$ but $d(N) \le 2$ for all proper minors $N$ of $M$. All density-critical matroids of density to a lesser extent than $2$ are series-parallel networks. For $k \ge 2$, although finding all density-critical matroids of density at most $k$ does not seem straightforward, we do work out this problem for $k=\tfrac{9}{4}$.",math.CO
"The classical Prandtl-Batchelor theorem (Prandtl 1904; Batchelor 1956) states that in the regions of steady 2D flow where viscous forces are small and streamlines are closed, the vorticity is constant. In this paper, we extend this theorem to recirculating flows with quasi-periodic time dependence using ergodic and geometric analysis of Lagrangian dynamics. In particular, we show that 2D quasi-periodic viscous flows, in the limit of zero viscosity, cannot converge to recirculating inviscid flows with non-uniform vorticity distribution. A corollary of this result is that if the vorticity contours form a family of closed curves in a quasi-periodic viscous flow, then at the limit of zero viscosity, vorticity is constant in the area enclosed by those curves at all times.",physics.flu-dyn
"The classical Prandtl-Batchelor theorem (Prandtl 1904; Batchelor 1956) states that in the regions of steady 2D flow where viscous forces are small and streamline are closed, the vorticity is constant. In this paper, we extend this theorem to recirculating flows with quasi-periodic time dependence using ergodic and geometric analysis of Lagrangian dynamics. In particular, we show that 2D quasi-periodic viscous flows, in the circumscribe of zero viscosity, cannot converge to recirculating inviscid flows with non-uniform vorticity distribution. A corollary of this result is that if the vorticity contours form a family of closed curves in a quasi-periodic viscous flow, then at the circumscribe of zero viscosity, vorticity is constant in the area enclosed by those curves at all times.",physics.flu-dyn
"We use the clustering of galaxies around distant AGN to show with ~90% confidence that fainter AGN are longer lived. Our argument is simple: since the measured galaxy-AGN cross-correlation length r_0 ~ 5h^-1 Mpc does not vary significantly over a 10 magnitude range in AGN optical luminosity, faint and bright AGN must reside in dark matter halos with similar masses. The halos that host bright and faint AGN therefore have similar intrinsic abundances, and the large observed variation in AGN number density with luminosity reflects a change in duty cycle.",astro-ph
"We use the clustering of galaxies around distant AGN to show with ~90% confidence that fainter AGN are longer lived. Our argument is simple: since the measured galaxy-AGN cross-correlation length r_0 ~ 5h^-1 Mpc does not vary significantly over a 10 magnitude range in AGN optical luminosity, faint and bright AGN must reside in dark matter halos with similar masses. The halos that innkeeper bright and faint AGN therefore have similar intrinsic abundances, and the large observed magnetic declination in AGN number density with luminosity reflects a change in duty cycle.",astro-ph
"We report the first lattice QCD calculation of the hadronic vacuum polarization disconnected contribution to the muon anomalous magnetic moment at physical pion mass. The calculation uses a refined noise-reduction technique which enabled the control of statistical uncertainties at the desired level with modest computational effort. Measurements were performed on the $48^3 \times 96$ physical-pion-mass lattice generated by the RBC and UKQCD collaborations. We find $a_\mu^{\rm HVP~(LO)~DISC} = -9.6(3.3)(2.3)\times 10^{-10}$, where the first error is statistical and the second systematic.",hep-lat hep-ph
"We report the first fretwork QCD calculation of the hadronic vacuum polarization disordered contribution to the muon anomalous magnetic moment at physical pion mass. The calculation uses a refined noise-reduction technique which enabled the control of statistical uncertainties at the desired level with modest computational effort. Measurements were performed on the $48^3 \times 96$ physical-pion-mass fretwork generated by the RBC and UKQCD collaborations. We find $a_\mu^{\rm HVP~(LO)~DISC} = -9.6(3.3)(2.3)\times 10^{-10}$, where the first error is statistical and the second systematic.",hep-lat hep-ph
"Deep learning has dramatically improved the performance of sounds recognition. However, learning acoustic models directly from the raw waveform is still challenging. Current waveform-based models generally use time-domain convolutional layers to extract features. The features extracted by single size filters are insufficient for building discriminative representation of audios. In this paper, we propose multi-scale convolution operation, which can get better audio representation by improving the frequency resolution and learning filters cross all frequency area. For leveraging the waveform-based features and spectrogram-based features in a single model, we introduce two-phase method to fuse the different features. Finally, we propose a novel end-to-end network called WaveMsNet based on the multi-scale convolution operation and two-phase method. On the environmental sounds classification datasets ESC-10 and ESC-50, the classification accuracies of our WaveMsNet achieve 93.75% and 79.10% respectively, which improve significantly from the previous methods.",cs.SD eess.AS
"Deep learning has dramatically improved the performance of sounds recognition. However, learning acoustic models directly from the raw waveform is still challenging. Current waveform-based models generally use time-domain convolutional layers to extract features. The features extracted by single size filters are insufficient for building judicial representation of audios. In this paper, we propose multi-scale convolution operation, which can get better audio representation by improving the frequency resolution and learning filters cross all frequency area. For leveraging the waveform-based features and spectrogram-based features in a single model, we introduce two-phase method to fuse the different features. Finally, we propose a novel end-to-end network called WaveMsNet based on the multi-scale convolution operation and two-phase method. On the environmental sounds classification datasets ESC-10 and ESC-50, the classification accuracies of our WaveMsNet achieve 93.75% and 79.10% respectively, which meliorate significantly from the previous methods.",cs.SD eess.AS
"In this paper, we first prove the weak intermittency, and in particular the sharp exponential order $C\lambda^4t$ of the second moment of the exact solution of the stochastic heat equation with multiplicative noise and periodic boundary condition, where $\lambda>0$ denotes the level of the noise. In order to inherit numerically these intrinsic properties of the original equation, we introduce a fully discrete scheme, whose spatial direction is based on the finite difference method and temporal direction is based on the $\theta$-scheme. We prove that the second moment of numerical solutions of both spatially semi-discrete and fully discrete schemes grows at least as $\exp\{C\lambda^2t\}$ and at most as $\exp\{C\lambda^4t\}$ for large $t$ under natural conditions, which implies the weak intermittency of these numerical solutions. Moreover, a renewal approach is applied to show that both of the numerical schemes could preserve the sharp exponential order $C\lambda^4t$ of the second moment of the exact solution for large spatial partition number.",cs.NA math.NA math.PR
"In this paper, we first prove the weak intermittency, and in particular the sharp exponential order $C\lambda^4t$ of the second moment of the exact solution of the stochastic heat equation with multiplicative noise and periodic boundary condition, where $\lambda>0$ denotes the level of the noise. In order to inherit numerically these intrinsic properties of the original equation, we introduce a fully discrete scheme, whose spatial direction is based on the finite difference of opinion method and temporal direction is based on the $\theta$-scheme. We prove that the second moment of numerical solutions of both spatially semi-discrete and fully discrete schemes grows at least as $\exp\{C\lambda^2t\}$ and at most as $\exp\{C\lambda^4t\}$ for large $t$ under natural conditions, which implies the weak intermittency of these numerical solutions. Moreover, a renewal approach is applied to show that both of the numerical schemes could bear on the sharp exponential order $C\lambda^4t$ of the second moment of the exact solution for large spatial partition number.",cs.NA math.NA math.PR
"Boundary value problems for linear stationary dispersive equations of order $2l+1$, $l\in \mathbb{N}$ have been considered on finite intervals $(0,L)$. The existence and uniqueness of regular solutions have been established for general linear boundary conditions.",math.AP
"Boundary value problems for linear stationary dispersive equations of order $2l+1$, $l\in \mathbb{N}$ have been considered on finite intervals $(0,L)$. The existence and uniqueness of regular solution have been show for general linear boundary conditions.",math.AP
"With the advent of deep optical-to-near-infrared extragalactic imaging on the degree scale, samples of high-redshift sources are being selected that contain both bright star-forming (SF) galaxies and faint active galactic nuclei (AGN). In this study we investigate the transition between SF and AGN-dominated systems at $z \simeq 4$ in the rest-frame UV. We find a rapid transition to AGN-dominated sources bright-ward of $M_{\rm UV} \simeq -23.2$. The effect is observed in the rest-frame UV morphology and size-luminosity relation, where extended clumpy systems become point-source dominated, and also in the available spectra for the sample. These results allow us to derive the rest-frame UV luminosity function for the SF and AGN-dominated sub-samples. We find the SF-dominated LF is best fit with a double-power law, with a lensed Schechter function being unable to explain the existence of extremely luminous SF galaxies at $M_{\rm UV} \simeq -23.5$. If we identify AGN-dominated sources according to a point-source morphology criterion we recover the relatively flat faint-end slope of the AGN LF determined in previous studies. If we instead separate the LF according to the current spectroscopic AGN fraction, we find a steeper faint-end slope of $\alpha = -1.83 \pm 0.11$. Using a simple model to predict the rest-frame AGN LF from the $z = 4 $ galaxy LF we find that the increasing impact of host galaxy light on the measured morphology of faint AGN can explain our observations.",astro-ph.GA
"With the advent of deep optical-to-near-infrared extragalactic imaging on the degree scale, sample of high-redshift sources are being selected that contain both bright star-forming (SF) galaxies and faint active galactic nuclei (AGN). In this study we investigate the transition between SF and AGN-dominated systems at $z \simeq 4$ in the rest-frame UV. We find a rapid transition to AGN-dominated sources bright-ward of $M_{\rm UV} \simeq -23.2$. The effect is observed in the rest-frame UV morphology and size-luminosity relation, where extended clumpy systems become point-source dominated, and also in the available spectra for the sample. These results allow us to derive the rest-frame UV luminosity function for the SF and AGN-dominated sub-samples. We find the SF-dominated LF is best fit with a double-power law, with a lensed Schechter function being unable to explain the existence of extremely luminous SF galaxies at $M_{\rm UV} \simeq -23.5$. If we identify AGN-dominated sources according to a point-source morphology criterion we recoup the relatively flat faint-end slope of the AGN LF determined in previous studies. If we instead separate the LF according to the current spectroscopic AGN fraction, we find a steeper faint-end slope of $\alpha = -1.83 \pm 0.11$. Using a simple model to predict the rest-frame AGN LF from the $z = 4 $ galaxy LF we find that the increasing impact of host galaxy light on the measured morphology of faint AGN can explain our observations.",astro-ph.GA
"We report on the discovery of a hydrogen-deficient compact binary (CXOGBS J175107.6-294037) belonging to the AM CVn class in the Galactic Bulge Survey. Deep archival X-ray observations constrain the X-ray positional uncertainty of the source to 0.57 arcsec, and allow us to uniquely identify the optical and UV counterpart. Optical spectroscopic observations reveal the presence of broad, shallow He i absorption lines while no sign of hydrogen is present, consistent with a high state system. We present the optical lightcurve from Optical Gravitational Lensing Experiment monitoring, spanning 15 years. It shows no evidence for outbursts; variability is present at the 0.2 mag level on timescales ranging from hours to weeks. A modulation on a timescale of years is also observed. A Lomb-Scargle analysis of the optical lightcurves shows two significant periodicities at 22.90 and 23.22 min. Although the physical interpretation is uncertain, such timescales are in line with expectations for the orbital and superhump periods. We estimate the distance to the source to be between 0.5 - 1.1 kpc. Spectroscopic follow-up observations are required to establish the orbital period, and to determine whether this source can serve as a verification binary for the eLISA gravitational wave mission.",astro-ph.HE
"We report on the discovery of a hydrogen-deficient compact binary (CXOGBS J175107.6-294037) belonging to the AM CVn class in the Galactic Bulge Survey. Deep archival X-ray observations constrain the X-ray positional uncertainty of the source to 0.57 arcsec, and allow us to uniquely identify the optical and UV counterpart. Optical spectroscopic observations reveal the presence of broad, shallow He i absorption lines while no sign of hydrogen is present, consistent with a high state system. We present the optical lightcurve from Optical gravitative Lensing Experiment monitoring, sweep 15 years. It shows no evidence for outbursts; variability is present at the 0.2 mag level on timescales ranging from hours to weeks. A modulation on a timescale of years is also observed. A Lomb-Scargle analysis of the optical lightcurves shows two significant periodicities at 22.90 and 23.22 min. Although the physical interpretation is uncertain, such timescales are in line with expectations for the orbital and superhump periods. We estimate the distance to the source to be between 0.5 - 1.1 kpc. Spectroscopic follow-up observations are required to establish the orbital period, and to determine whether this source can serve as a verification binary for the eLISA gravitational wave mission.",astro-ph.HE
"We study dispersions of Fermi arcs in the Weyl semimetal phase by constructing a simple effective model. We calculate how the surface Fermi-arc dispersions for the top- and bottom surfaces merge into the bulk Dirac cones in the Weyl semimetal at both ends of the arcs, and show that they have opposite velocities. This result is also confirmed by a calculation using a tight-binding model. Furthermore, by changing a parameter in the system while preserving time-reversal symmetry, we show that two Fermi arcs evolve into a surface Dirac cone when the system transits from the Weyl semimetal to the topological insulator phase. We also demonstrate that choices of surface terminations affect the pairing of Weyl nodes, from which the Fermi arcs are formed.",cond-mat.mes-hall cond-mat.other
"We study dispersions of Fermi arcs in the Weyl semimetal phase by constructing a simple effective model. We calculate how the surface Fermi-arc dispersions for the top- and bottom surfaces merge into the bulk Dirac cones in the Weyl semimetal at both ends of the arcs, and bear witness that they have opposite velocities. This result is besides confirmed by a calculation using a tight-binding model. Furthermore, by changing a parameter in the system while preserving time-reversal symmetry, we bear witness that two Fermi arcs evolve into a surface Dirac cone when the system transits from the Weyl semimetal to the topological insulator phase. We besides demonstrate that choices of surface terminations affect the pairing of Weyl nodes, from which the Fermi arcs are formed.",cond-mat.mes-hall cond-mat.other
"The Vlasov-Maxwell-Boltzmann system is a fundamental model to describe the dynamics of dilute charged particles, where particles interact via collisions and through their self-consistent electromagnetic field. We prove the existence of global in time classical solutions to the Cauchy problem near Maxwellians.",math.AP
"The Vlasov-Maxwell-Boltzmann system is a fundamental model to describe the dynamic of dilute charged particles, where particles interact via collisions and through their self-consistent electromagnetic field. We prove the existence of global in time classical music solutions to the Cauchy problem near Maxwellians.",math.AP
